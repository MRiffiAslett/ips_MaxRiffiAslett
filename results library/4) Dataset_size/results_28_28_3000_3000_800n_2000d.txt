Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 4,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': False,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train Epoch: 1 
task: majority, mean loss: 2.35159, accuracy: 0.09750, task: max, mean loss: 2.09108, accuracy: 0.24400, task: top, mean loss: 2.34829, accuracy: 0.09050, task: multi, mean loss: 0.67042, multilabel_accuracy: 0.00150, avg. loss over tasks: 1.86534, lr: 0.0001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
Test Epoch: 1 
task: majority, mean loss: 2.32046, accuracy: 0.09400, task: max, mean loss: 1.88347, accuracy: 0.27400, task: top, mean loss: 2.31530, accuracy: 0.09900, task: multi, mean loss: 0.60558, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78120
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 2 
task: majority, mean loss: 2.32812, accuracy: 0.10500, task: max, mean loss: 1.86019, accuracy: 0.25100, task: top, mean loss: 2.32015, accuracy: 0.10200, task: multi, mean loss: 0.60741, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77897, lr: 0.0002
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 2 
task: majority, mean loss: 2.32959, accuracy: 0.08900, task: max, mean loss: 1.88189, accuracy: 0.27400, task: top, mean loss: 2.32548, accuracy: 0.09200, task: multi, mean loss: 0.60147, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78461
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 3 
task: majority, mean loss: 2.32835, accuracy: 0.09900, task: max, mean loss: 1.84858, accuracy: 0.26300, task: top, mean loss: 2.32829, accuracy: 0.10800, task: multi, mean loss: 0.60553, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77769, lr: 0.0003
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 3 
task: majority, mean loss: 2.32004, accuracy: 0.09000, task: max, mean loss: 1.86025, accuracy: 0.27400, task: top, mean loss: 2.33174, accuracy: 0.09900, task: multi, mean loss: 0.60134, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77834
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 4 
task: majority, mean loss: 2.33035, accuracy: 0.09650, task: max, mean loss: 1.84786, accuracy: 0.24650, task: top, mean loss: 2.33209, accuracy: 0.10050, task: multi, mean loss: 0.60543, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77893, lr: 0.0004
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 4 
task: majority, mean loss: 2.34607, accuracy: 0.08900, task: max, mean loss: 1.85776, accuracy: 0.27400, task: top, mean loss: 2.31390, accuracy: 0.09700, task: multi, mean loss: 0.60268, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78010
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 5 
task: majority, mean loss: 2.30462, accuracy: 0.12650, task: max, mean loss: 1.83732, accuracy: 0.27250, task: top, mean loss: 2.32072, accuracy: 0.10700, task: multi, mean loss: 0.60496, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76691, lr: 0.0005
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 5 
task: majority, mean loss: 2.47708, accuracy: 0.10600, task: max, mean loss: 1.91486, accuracy: 0.16500, task: top, mean loss: 2.43072, accuracy: 0.11400, task: multi, mean loss: 0.60509, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.85694
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 6 
task: majority, mean loss: 2.26604, accuracy: 0.15250, task: max, mean loss: 1.77654, accuracy: 0.32550, task: top, mean loss: 2.30529, accuracy: 0.12950, task: multi, mean loss: 0.60016, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73701, lr: 0.0006
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 6 
task: majority, mean loss: 2.27680, accuracy: 0.11300, task: max, mean loss: 1.86985, accuracy: 0.21300, task: top, mean loss: 2.30262, accuracy: 0.10400, task: multi, mean loss: 0.59502, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76107
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 7 
task: majority, mean loss: 2.24943, accuracy: 0.16050, task: max, mean loss: 1.74385, accuracy: 0.32850, task: top, mean loss: 2.29362, accuracy: 0.13350, task: multi, mean loss: 0.59350, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72010, lr: 0.0007
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 7 
task: majority, mean loss: 2.32830, accuracy: 0.10000, task: max, mean loss: 1.94472, accuracy: 0.21300, task: top, mean loss: 2.31352, accuracy: 0.10000, task: multi, mean loss: 0.60893, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79887
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 8 
task: majority, mean loss: 2.24937, accuracy: 0.14750, task: max, mean loss: 1.75385, accuracy: 0.32650, task: top, mean loss: 2.28457, accuracy: 0.13850, task: multi, mean loss: 0.59287, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72016, lr: 0.0008
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 8 
task: majority, mean loss: 2.50183, accuracy: 0.12100, task: max, mean loss: 1.92371, accuracy: 0.26800, task: top, mean loss: 2.35324, accuracy: 0.11500, task: multi, mean loss: 0.61209, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.84772
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 9 
task: majority, mean loss: 2.23251, accuracy: 0.15750, task: max, mean loss: 1.73014, accuracy: 0.33050, task: top, mean loss: 2.27294, accuracy: 0.14450, task: multi, mean loss: 0.58902, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70615, lr: 0.0009
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 9 
task: majority, mean loss: 2.49527, accuracy: 0.10700, task: max, mean loss: 2.33312, accuracy: 0.22000, task: top, mean loss: 2.35138, accuracy: 0.11100, task: multi, mean loss: 0.62694, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.95168
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 10 
task: majority, mean loss: 2.22039, accuracy: 0.17650, task: max, mean loss: 1.67852, accuracy: 0.35600, task: top, mean loss: 2.25374, accuracy: 0.15850, task: multi, mean loss: 0.58524, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68448, lr: 0.001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 10 
task: majority, mean loss: 2.22100, accuracy: 0.15600, task: max, mean loss: 1.69194, accuracy: 0.35200, task: top, mean loss: 2.23577, accuracy: 0.15900, task: multi, mean loss: 0.58471, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68336
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 11 
task: majority, mean loss: 2.17119, accuracy: 0.19600, task: max, mean loss: 1.57973, accuracy: 0.41400, task: top, mean loss: 2.21651, accuracy: 0.17850, task: multi, mean loss: 0.57396, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.63535, lr: 0.0009996957180960382
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 11 
task: majority, mean loss: 2.18721, accuracy: 0.17400, task: max, mean loss: 1.72802, accuracy: 0.35700, task: top, mean loss: 2.22139, accuracy: 0.16000, task: multi, mean loss: 0.56854, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.67629
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 12 
task: majority, mean loss: 2.13077, accuracy: 0.21050, task: max, mean loss: 1.57216, accuracy: 0.41100, task: top, mean loss: 2.20620, accuracy: 0.17250, task: multi, mean loss: 0.57221, multilabel_accuracy: 0.00050, avg. loss over tasks: 1.62034, lr: 0.0009987832431047822
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 12 
task: majority, mean loss: 2.08867, accuracy: 0.23200, task: max, mean loss: 1.51433, accuracy: 0.44300, task: top, mean loss: 2.13636, accuracy: 0.21600, task: multi, mean loss: 0.55964, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.57475
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 13 
task: majority, mean loss: 2.10177, accuracy: 0.22650, task: max, mean loss: 1.50526, accuracy: 0.43450, task: top, mean loss: 2.16177, accuracy: 0.19650, task: multi, mean loss: 0.56667, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.58387, lr: 0.0009972636867364526
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 13 
task: majority, mean loss: 2.31618, accuracy: 0.16200, task: max, mean loss: 1.56194, accuracy: 0.40100, task: top, mean loss: 2.26446, accuracy: 0.14400, task: multi, mean loss: 0.59117, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68344
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 14 
task: majority, mean loss: 2.11349, accuracy: 0.22750, task: max, mean loss: 1.47474, accuracy: 0.44050, task: top, mean loss: 2.16797, accuracy: 0.17800, task: multi, mean loss: 0.56556, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.58044, lr: 0.0009951389003364144
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 14 
task: majority, mean loss: 2.55308, accuracy: 0.09500, task: max, mean loss: 2.29979, accuracy: 0.18800, task: top, mean loss: 2.51843, accuracy: 0.09600, task: multi, mean loss: 0.64140, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.00317
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 15 
task: majority, mean loss: 2.08560, accuracy: 0.21850, task: max, mean loss: 1.44292, accuracy: 0.44750, task: top, mean loss: 2.14996, accuracy: 0.20000, task: multi, mean loss: 0.56349, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.56049, lr: 0.000992411472629598
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 15 
task: majority, mean loss: 2.32573, accuracy: 0.12500, task: max, mean loss: 1.78191, accuracy: 0.31400, task: top, mean loss: 2.32572, accuracy: 0.12900, task: multi, mean loss: 0.59587, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.75731
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 16 
task: majority, mean loss: 2.08014, accuracy: 0.23200, task: max, mean loss: 1.42736, accuracy: 0.46250, task: top, mean loss: 2.13860, accuracy: 0.20450, task: multi, mean loss: 0.56188, multilabel_accuracy: 0.00050, avg. loss over tasks: 1.55200, lr: 0.000989084726566536
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 16 
task: majority, mean loss: 2.27393, accuracy: 0.15500, task: max, mean loss: 1.93096, accuracy: 0.27800, task: top, mean loss: 2.22359, accuracy: 0.13500, task: multi, mean loss: 0.58898, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75436
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 17 
task: majority, mean loss: 2.04527, accuracy: 0.25350, task: max, mean loss: 1.40605, accuracy: 0.45900, task: top, mean loss: 2.10444, accuracy: 0.21000, task: multi, mean loss: 0.55870, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.52861, lr: 0.00098516271527486
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 17 
task: majority, mean loss: 2.18616, accuracy: 0.17600, task: max, mean loss: 1.47915, accuracy: 0.42800, task: top, mean loss: 2.15947, accuracy: 0.19600, task: multi, mean loss: 0.56479, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59739
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 18 
task: majority, mean loss: 2.03998, accuracy: 0.25600, task: max, mean loss: 1.35825, accuracy: 0.48100, task: top, mean loss: 2.09447, accuracy: 0.22650, task: multi, mean loss: 0.55390, multilabel_accuracy: 0.00050, avg. loss over tasks: 1.51165, lr: 0.0009806502171211902
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 18 
task: majority, mean loss: 2.12106, accuracy: 0.21300, task: max, mean loss: 1.46991, accuracy: 0.41600, task: top, mean loss: 2.10825, accuracy: 0.21700, task: multi, mean loss: 0.56475, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.56599
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 19 
task: majority, mean loss: 2.02355, accuracy: 0.26700, task: max, mean loss: 1.38493, accuracy: 0.47250, task: top, mean loss: 2.08175, accuracy: 0.23350, task: multi, mean loss: 0.55681, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.51176, lr: 0.0009755527298894293
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 19 
task: majority, mean loss: 2.53996, accuracy: 0.15600, task: max, mean loss: 1.67712, accuracy: 0.34300, task: top, mean loss: 2.27322, accuracy: 0.18400, task: multi, mean loss: 0.62066, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.77774
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 20 
task: majority, mean loss: 1.97357, accuracy: 0.28850, task: max, mean loss: 1.32852, accuracy: 0.49600, task: top, mean loss: 2.04446, accuracy: 0.25400, task: multi, mean loss: 0.54692, multilabel_accuracy: 0.00050, avg. loss over tasks: 1.47337, lr: 0.0009698764640825613
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 20 
task: majority, mean loss: 1.94856, accuracy: 0.30400, task: max, mean loss: 1.35804, accuracy: 0.47900, task: top, mean loss: 2.00573, accuracy: 0.26900, task: multi, mean loss: 0.54019, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.46313
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 21 
task: majority, mean loss: 1.93641, accuracy: 0.29350, task: max, mean loss: 1.33750, accuracy: 0.49450, task: top, mean loss: 1.98998, accuracy: 0.26300, task: multi, mean loss: 0.54583, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.45243, lr: 0.0009636283353561103
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 21 
task: majority, mean loss: 1.93225, accuracy: 0.30600, task: max, mean loss: 1.35755, accuracy: 0.47900, task: top, mean loss: 1.98061, accuracy: 0.27900, task: multi, mean loss: 0.53657, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.45175
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 22 
task: majority, mean loss: 1.86518, accuracy: 0.32500, task: max, mean loss: 1.25836, accuracy: 0.52750, task: top, mean loss: 1.95328, accuracy: 0.27350, task: multi, mean loss: 0.53559, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.40310, lr: 0.0009568159560924791
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 22 
task: majority, mean loss: 2.12720, accuracy: 0.23200, task: max, mean loss: 1.63826, accuracy: 0.38200, task: top, mean loss: 2.15861, accuracy: 0.22300, task: multi, mean loss: 0.57885, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.62573
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 23 
task: majority, mean loss: 1.76341, accuracy: 0.35650, task: max, mean loss: 1.20578, accuracy: 0.55250, task: top, mean loss: 1.88729, accuracy: 0.29250, task: multi, mean loss: 0.52617, multilabel_accuracy: 0.00850, avg. loss over tasks: 1.34566, lr: 0.000949447626126434
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 23 
task: majority, mean loss: 2.00961, accuracy: 0.28400, task: max, mean loss: 1.40151, accuracy: 0.49200, task: top, mean loss: 2.06599, accuracy: 0.25400, task: multi, mean loss: 0.53972, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.50421
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 24 
task: majority, mean loss: 1.77466, accuracy: 0.34800, task: max, mean loss: 1.22162, accuracy: 0.54250, task: top, mean loss: 1.87394, accuracy: 0.31250, task: multi, mean loss: 0.52463, multilabel_accuracy: 0.00450, avg. loss over tasks: 1.34871, lr: 0.000941532322633034
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 24 
task: majority, mean loss: 1.93048, accuracy: 0.32800, task: max, mean loss: 1.30753, accuracy: 0.52900, task: top, mean loss: 1.97320, accuracy: 0.31000, task: multi, mean loss: 0.52471, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.43398
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 25 
task: majority, mean loss: 1.70301, accuracy: 0.35750, task: max, mean loss: 1.13913, accuracy: 0.57450, task: top, mean loss: 1.82203, accuracy: 0.31950, task: multi, mean loss: 0.51190, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.29402, lr: 0.0009330796891903273
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 25 
task: majority, mean loss: 1.89139, accuracy: 0.32600, task: max, mean loss: 1.46429, accuracy: 0.47300, task: top, mean loss: 1.96969, accuracy: 0.29400, task: multi, mean loss: 0.54107, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.46661
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 26 
task: majority, mean loss: 1.62925, accuracy: 0.39950, task: max, mean loss: 1.11025, accuracy: 0.58050, task: top, mean loss: 1.76570, accuracy: 0.34750, task: multi, mean loss: 0.50365, multilabel_accuracy: 0.00550, avg. loss over tasks: 1.25221, lr: 0.0009241000240301347
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 26 
task: majority, mean loss: 1.79393, accuracy: 0.34000, task: max, mean loss: 1.33370, accuracy: 0.50700, task: top, mean loss: 1.87379, accuracy: 0.31000, task: multi, mean loss: 0.51215, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.37839
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 27 
task: majority, mean loss: 1.60668, accuracy: 0.40650, task: max, mean loss: 1.10233, accuracy: 0.58450, task: top, mean loss: 1.73379, accuracy: 0.37450, task: multi, mean loss: 0.50281, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.23640, lr: 0.0009146042674912433
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 27 
task: majority, mean loss: 2.89512, accuracy: 0.16600, task: max, mean loss: 1.77427, accuracy: 0.35800, task: top, mean loss: 2.55448, accuracy: 0.22800, task: multi, mean loss: 0.61502, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.95972
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 28 
task: majority, mean loss: 1.51706, accuracy: 0.45550, task: max, mean loss: 1.01333, accuracy: 0.63200, task: top, mean loss: 1.63531, accuracy: 0.42750, task: multi, mean loss: 0.48779, multilabel_accuracy: 0.00950, avg. loss over tasks: 1.16337, lr: 0.0009046039886902862
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 28 
task: majority, mean loss: 2.99013, accuracy: 0.14700, task: max, mean loss: 2.26077, accuracy: 0.25700, task: top, mean loss: 2.65460, accuracy: 0.17900, task: multi, mean loss: 0.64435, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.13746
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 29 
task: majority, mean loss: 1.40986, accuracy: 0.50350, task: max, mean loss: 0.92647, accuracy: 0.66750, task: top, mean loss: 1.57745, accuracy: 0.45050, task: multi, mean loss: 0.47014, multilabel_accuracy: 0.01850, avg. loss over tasks: 1.09598, lr: 0.0008941113714265576
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 29 
task: majority, mean loss: 2.15222, accuracy: 0.30700, task: max, mean loss: 1.48132, accuracy: 0.51600, task: top, mean loss: 1.97085, accuracy: 0.33800, task: multi, mean loss: 0.53563, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.53501
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 30 
task: majority, mean loss: 1.33507, accuracy: 0.52200, task: max, mean loss: 0.79744, accuracy: 0.71200, task: top, mean loss: 1.49855, accuracy: 0.48450, task: multi, mean loss: 0.44854, multilabel_accuracy: 0.03400, avg. loss over tasks: 1.01990, lr: 0.0008831391993379295
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 30 
task: majority, mean loss: 1.96282, accuracy: 0.34300, task: max, mean loss: 1.15183, accuracy: 0.60100, task: top, mean loss: 1.88671, accuracy: 0.39100, task: multi, mean loss: 0.50844, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.37745
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 31 
task: majority, mean loss: 1.22661, accuracy: 0.55550, task: max, mean loss: 0.69292, accuracy: 0.76150, task: top, mean loss: 1.40152, accuracy: 0.52700, task: multi, mean loss: 0.42310, multilabel_accuracy: 0.04250, avg. loss over tasks: 0.93604, lr: 0.0008717008403259585
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 31 
task: majority, mean loss: 2.01062, accuracy: 0.33600, task: max, mean loss: 1.17116, accuracy: 0.62300, task: top, mean loss: 1.77304, accuracy: 0.43600, task: multi, mean loss: 0.47997, multilabel_accuracy: 0.03600, avg. loss over tasks: 1.35869
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 32 
task: majority, mean loss: 1.21977, accuracy: 0.56750, task: max, mean loss: 0.70498, accuracy: 0.75600, task: top, mean loss: 1.32401, accuracy: 0.56000, task: multi, mean loss: 0.41812, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.91672, lr: 0.0008598102302691562
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 32 
task: majority, mean loss: 1.41698, accuracy: 0.51300, task: max, mean loss: 0.89912, accuracy: 0.68900, task: top, mean loss: 1.59653, accuracy: 0.48800, task: multi, mean loss: 0.43255, multilabel_accuracy: 0.05500, avg. loss over tasks: 1.08629
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 33 
task: majority, mean loss: 1.05897, accuracy: 0.62200, task: max, mean loss: 0.60710, accuracy: 0.78600, task: top, mean loss: 1.24915, accuracy: 0.57650, task: multi, mean loss: 0.39798, multilabel_accuracy: 0.06550, avg. loss over tasks: 0.82830, lr: 0.0008474818560442692
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 33 
task: majority, mean loss: 2.14404, accuracy: 0.33300, task: max, mean loss: 1.42307, accuracy: 0.54800, task: top, mean loss: 1.85229, accuracy: 0.40200, task: multi, mean loss: 0.50541, multilabel_accuracy: 0.03400, avg. loss over tasks: 1.48121
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 34 
task: majority, mean loss: 1.03124, accuracy: 0.63950, task: max, mean loss: 0.60279, accuracy: 0.78250, task: top, mean loss: 1.13044, accuracy: 0.62200, task: multi, mean loss: 0.38353, multilabel_accuracy: 0.07600, avg. loss over tasks: 0.78700, lr: 0.0008347307378762497
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 34 
task: majority, mean loss: 1.35416, accuracy: 0.52200, task: max, mean loss: 0.88551, accuracy: 0.70500, task: top, mean loss: 1.41644, accuracy: 0.54400, task: multi, mean loss: 0.39305, multilabel_accuracy: 0.06500, avg. loss over tasks: 1.01229
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 35 
task: majority, mean loss: 0.91179, accuracy: 0.67600, task: max, mean loss: 0.55389, accuracy: 0.80300, task: top, mean loss: 0.99045, accuracy: 0.67250, task: multi, mean loss: 0.36729, multilabel_accuracy: 0.08850, avg. loss over tasks: 0.70585, lr: 0.0008215724110384265
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 35 
task: majority, mean loss: 1.47890, accuracy: 0.55000, task: max, mean loss: 0.89363, accuracy: 0.71300, task: top, mean loss: 1.48188, accuracy: 0.57000, task: multi, mean loss: 0.39938, multilabel_accuracy: 0.09400, avg. loss over tasks: 1.06345
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 36 
task: majority, mean loss: 0.82661, accuracy: 0.71350, task: max, mean loss: 0.51374, accuracy: 0.81150, task: top, mean loss: 0.90780, accuracy: 0.70600, task: multi, mean loss: 0.35308, multilabel_accuracy: 0.11250, avg. loss over tasks: 0.65031, lr: 0.0008080229069251663
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 36 
task: majority, mean loss: 1.09181, accuracy: 0.63100, task: max, mean loss: 0.93205, accuracy: 0.69300, task: top, mean loss: 1.32718, accuracy: 0.60700, task: multi, mean loss: 0.38661, multilabel_accuracy: 0.07800, avg. loss over tasks: 0.93441
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 37 
task: majority, mean loss: 0.70557, accuracy: 0.75100, task: max, mean loss: 0.45741, accuracy: 0.83600, task: top, mean loss: 0.82787, accuracy: 0.73600, task: multi, mean loss: 0.33647, multilabel_accuracy: 0.11550, avg. loss over tasks: 0.58183, lr: 0.0007940987335200903
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 37 
task: majority, mean loss: 2.02321, accuracy: 0.41400, task: max, mean loss: 1.12106, accuracy: 0.67200, task: top, mean loss: 1.55828, accuracy: 0.54600, task: multi, mean loss: 0.41692, multilabel_accuracy: 0.10900, avg. loss over tasks: 1.27987
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 38 
task: majority, mean loss: 0.64273, accuracy: 0.77450, task: max, mean loss: 0.45786, accuracy: 0.83700, task: top, mean loss: 0.74716, accuracy: 0.75600, task: multi, mean loss: 0.32626, multilabel_accuracy: 0.14600, avg. loss over tasks: 0.54350, lr: 0.0007798168552836382
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 38 
task: majority, mean loss: 2.00670, accuracy: 0.39200, task: max, mean loss: 0.98252, accuracy: 0.66600, task: top, mean loss: 1.55726, accuracy: 0.56200, task: multi, mean loss: 0.43399, multilabel_accuracy: 0.09200, avg. loss over tasks: 1.24512
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 39 
task: majority, mean loss: 0.62276, accuracy: 0.78800, task: max, mean loss: 0.39915, accuracy: 0.84800, task: top, mean loss: 0.66290, accuracy: 0.79000, task: multi, mean loss: 0.31487, multilabel_accuracy: 0.16300, avg. loss over tasks: 0.49992, lr: 0.0007651946724844859
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 39 
task: majority, mean loss: 1.11399, accuracy: 0.61900, task: max, mean loss: 0.89284, accuracy: 0.73100, task: top, mean loss: 1.20857, accuracy: 0.64300, task: multi, mean loss: 0.35529, multilabel_accuracy: 0.15200, avg. loss over tasks: 0.89267
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 40 
task: majority, mean loss: 0.51695, accuracy: 0.81100, task: max, mean loss: 0.38760, accuracy: 0.85850, task: top, mean loss: 0.56736, accuracy: 0.81500, task: multi, mean loss: 0.30262, multilabel_accuracy: 0.18350, avg. loss over tasks: 0.44363, lr: 0.00075025
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 40 
task: majority, mean loss: 1.33557, accuracy: 0.59800, task: max, mean loss: 0.91298, accuracy: 0.70900, task: top, mean loss: 1.39671, accuracy: 0.62400, task: multi, mean loss: 0.35059, multilabel_accuracy: 0.15500, avg. loss over tasks: 0.99896
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 41 
task: majority, mean loss: 0.50002, accuracy: 0.82900, task: max, mean loss: 0.39141, accuracy: 0.86800, task: top, mean loss: 0.56615, accuracy: 0.81750, task: multi, mean loss: 0.29622, multilabel_accuracy: 0.20550, avg. loss over tasks: 0.43845, lr: 0.0007350010456115524
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 41 
task: majority, mean loss: 1.37710, accuracy: 0.57300, task: max, mean loss: 1.06816, accuracy: 0.68500, task: top, mean loss: 1.28505, accuracy: 0.64500, task: multi, mean loss: 0.40375, multilabel_accuracy: 0.12800, avg. loss over tasks: 1.03351
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 42 
task: majority, mean loss: 0.43801, accuracy: 0.84200, task: max, mean loss: 0.34919, accuracy: 0.87350, task: top, mean loss: 0.53350, accuracy: 0.83100, task: multi, mean loss: 0.28465, multilabel_accuracy: 0.23200, avg. loss over tasks: 0.40134, lr: 0.0007194663878211441
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 42 
task: majority, mean loss: 1.04290, accuracy: 0.69400, task: max, mean loss: 0.99386, accuracy: 0.70400, task: top, mean loss: 1.18778, accuracy: 0.67500, task: multi, mean loss: 0.34112, multilabel_accuracy: 0.20300, avg. loss over tasks: 0.89142
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 43 
task: majority, mean loss: 0.35557, accuracy: 0.87550, task: max, mean loss: 0.29750, accuracy: 0.89750, task: top, mean loss: 0.41966, accuracy: 0.86850, task: multi, mean loss: 0.26528, multilabel_accuracy: 0.26650, avg. loss over tasks: 0.33450, lr: 0.0007036649532163622
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 43 
task: majority, mean loss: 1.72377, accuracy: 0.54200, task: max, mean loss: 0.95632, accuracy: 0.73000, task: top, mean loss: 1.67024, accuracy: 0.60200, task: multi, mean loss: 0.37736, multilabel_accuracy: 0.15800, avg. loss over tasks: 1.18192
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 44 
task: majority, mean loss: 0.34114, accuracy: 0.87900, task: max, mean loss: 0.28477, accuracy: 0.89900, task: top, mean loss: 0.38580, accuracy: 0.88050, task: multi, mean loss: 0.25482, multilabel_accuracy: 0.28650, avg. loss over tasks: 0.31663, lr: 0.0006876159934112482
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 44 
task: majority, mean loss: 0.83951, accuracy: 0.75400, task: max, mean loss: 0.79477, accuracy: 0.78100, task: top, mean loss: 1.10118, accuracy: 0.70700, task: multi, mean loss: 0.28346, multilabel_accuracy: 0.26400, avg. loss over tasks: 0.75473
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 45 
task: majority, mean loss: 0.32209, accuracy: 0.88900, task: max, mean loss: 0.26964, accuracy: 0.90750, task: top, mean loss: 0.34860, accuracy: 0.88250, task: multi, mean loss: 0.25204, multilabel_accuracy: 0.32000, avg. loss over tasks: 0.29809, lr: 0.0006713390615911716
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 45 
task: majority, mean loss: 0.97405, accuracy: 0.69500, task: max, mean loss: 0.93025, accuracy: 0.75700, task: top, mean loss: 1.18166, accuracy: 0.69800, task: multi, mean loss: 0.29951, multilabel_accuracy: 0.27100, avg. loss over tasks: 0.84637
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 46 
task: majority, mean loss: 0.24780, accuracy: 0.91700, task: max, mean loss: 0.22753, accuracy: 0.92250, task: top, mean loss: 0.28661, accuracy: 0.91450, task: multi, mean loss: 0.23467, multilabel_accuracy: 0.33300, avg. loss over tasks: 0.24915, lr: 0.0006548539886902863
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 46 
task: majority, mean loss: 0.74215, accuracy: 0.76300, task: max, mean loss: 0.91126, accuracy: 0.77200, task: top, mean loss: 1.13593, accuracy: 0.70200, task: multi, mean loss: 0.28137, multilabel_accuracy: 0.30200, avg. loss over tasks: 0.76768
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 47 
task: majority, mean loss: 0.19861, accuracy: 0.93100, task: max, mean loss: 0.18333, accuracy: 0.93800, task: top, mean loss: 0.23418, accuracy: 0.92000, task: multi, mean loss: 0.22290, multilabel_accuracy: 0.37250, avg. loss over tasks: 0.20975, lr: 0.0006381808592305911
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 47 
task: majority, mean loss: 1.29219, accuracy: 0.63600, task: max, mean loss: 1.45092, accuracy: 0.69100, task: top, mean loss: 1.47088, accuracy: 0.66500, task: multi, mean loss: 0.35933, multilabel_accuracy: 0.21600, avg. loss over tasks: 1.14333
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 48 
task: majority, mean loss: 0.21331, accuracy: 0.92300, task: max, mean loss: 0.17689, accuracy: 0.94550, task: top, mean loss: 0.22361, accuracy: 0.92850, task: multi, mean loss: 0.22246, multilabel_accuracy: 0.37050, avg. loss over tasks: 0.20907, lr: 0.0006213399868520341
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 48 
task: majority, mean loss: 1.48431, accuracy: 0.60600, task: max, mean loss: 1.56879, accuracy: 0.67200, task: top, mean loss: 1.49785, accuracy: 0.66000, task: multi, mean loss: 0.40823, multilabel_accuracy: 0.17100, avg. loss over tasks: 1.23980
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 49 
task: majority, mean loss: 0.22960, accuracy: 0.91950, task: max, mean loss: 0.19412, accuracy: 0.93250, task: top, mean loss: 0.26491, accuracy: 0.91850, task: multi, mean loss: 0.22372, multilabel_accuracy: 0.37300, avg. loss over tasks: 0.22809, lr: 0.0006043518895634708
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 49 
task: majority, mean loss: 0.86638, accuracy: 0.74100, task: max, mean loss: 0.75479, accuracy: 0.81200, task: top, mean loss: 1.15277, accuracy: 0.73400, task: multi, mean loss: 0.27132, multilabel_accuracy: 0.33300, avg. loss over tasks: 0.76132
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 50 
task: majority, mean loss: 0.16584, accuracy: 0.94400, task: max, mean loss: 0.16245, accuracy: 0.94300, task: top, mean loss: 0.17445, accuracy: 0.94150, task: multi, mean loss: 0.20597, multilabel_accuracy: 0.41750, avg. loss over tasks: 0.17718, lr: 0.0005872372647446318
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 50 
task: majority, mean loss: 1.31134, accuracy: 0.63400, task: max, mean loss: 0.89673, accuracy: 0.77400, task: top, mean loss: 1.38427, accuracy: 0.69400, task: multi, mean loss: 0.30564, multilabel_accuracy: 0.27700, avg. loss over tasks: 0.97449
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 51 
task: majority, mean loss: 0.12295, accuracy: 0.96000, task: max, mean loss: 0.13733, accuracy: 0.95650, task: top, mean loss: 0.13487, accuracy: 0.95800, task: multi, mean loss: 0.19861, multilabel_accuracy: 0.42400, avg. loss over tasks: 0.14844, lr: 0.0005700169639295527
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 51 
task: majority, mean loss: 0.91516, accuracy: 0.72500, task: max, mean loss: 0.94067, accuracy: 0.77500, task: top, mean loss: 1.28729, accuracy: 0.71500, task: multi, mean loss: 0.27804, multilabel_accuracy: 0.32400, avg. loss over tasks: 0.85529
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 52 
task: majority, mean loss: 0.15299, accuracy: 0.94400, task: max, mean loss: 0.12478, accuracy: 0.96050, task: top, mean loss: 0.15576, accuracy: 0.95100, task: multi, mean loss: 0.19947, multilabel_accuracy: 0.41700, avg. loss over tasks: 0.15825, lr: 0.0005527119674021931
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 52 
task: majority, mean loss: 0.69954, accuracy: 0.79100, task: max, mean loss: 0.85028, accuracy: 0.79800, task: top, mean loss: 1.24103, accuracy: 0.72000, task: multi, mean loss: 0.26628, multilabel_accuracy: 0.34400, avg. loss over tasks: 0.76428
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 53 
task: majority, mean loss: 0.13447, accuracy: 0.95400, task: max, mean loss: 0.11718, accuracy: 0.95750, task: top, mean loss: 0.13989, accuracy: 0.95350, task: multi, mean loss: 0.18717, multilabel_accuracy: 0.44450, avg. loss over tasks: 0.14468, lr: 0.0005353433586351906
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 53 
task: majority, mean loss: 0.60542, accuracy: 0.82000, task: max, mean loss: 0.86055, accuracy: 0.78900, task: top, mean loss: 1.14127, accuracy: 0.75100, task: multi, mean loss: 0.25702, multilabel_accuracy: 0.33800, avg. loss over tasks: 0.71606
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 54 
task: majority, mean loss: 0.10325, accuracy: 0.96300, task: max, mean loss: 0.10226, accuracy: 0.97150, task: top, mean loss: 0.09686, accuracy: 0.96850, task: multi, mean loss: 0.18692, multilabel_accuracy: 0.45300, avg. loss over tasks: 0.12232, lr: 0.0005179322986028993
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 54 
task: majority, mean loss: 0.52895, accuracy: 0.83300, task: max, mean loss: 0.84938, accuracy: 0.80700, task: top, mean loss: 1.05306, accuracy: 0.75800, task: multi, mean loss: 0.24545, multilabel_accuracy: 0.36800, avg. loss over tasks: 0.66921
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 55 
task: majority, mean loss: 0.12113, accuracy: 0.95550, task: max, mean loss: 0.09789, accuracy: 0.97100, task: top, mean loss: 0.10325, accuracy: 0.96950, task: multi, mean loss: 0.17507, multilabel_accuracy: 0.48550, avg. loss over tasks: 0.12434, lr: 0.0005004999999999999
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 55 
task: majority, mean loss: 0.63484, accuracy: 0.80000, task: max, mean loss: 0.89544, accuracy: 0.80800, task: top, mean loss: 1.16273, accuracy: 0.73700, task: multi, mean loss: 0.26322, multilabel_accuracy: 0.37300, avg. loss over tasks: 0.73906
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 56 
task: majority, mean loss: 0.10858, accuracy: 0.96800, task: max, mean loss: 0.07737, accuracy: 0.97850, task: top, mean loss: 0.11732, accuracy: 0.96300, task: multi, mean loss: 0.17881, multilabel_accuracy: 0.46850, avg. loss over tasks: 0.12052, lr: 0.00048306770139710083
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 56 
task: majority, mean loss: 0.81641, accuracy: 0.76800, task: max, mean loss: 0.85025, accuracy: 0.79500, task: top, mean loss: 1.24212, accuracy: 0.73300, task: multi, mean loss: 0.25992, multilabel_accuracy: 0.36300, avg. loss over tasks: 0.79218
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 57 
task: majority, mean loss: 0.07824, accuracy: 0.97400, task: max, mean loss: 0.05562, accuracy: 0.98750, task: top, mean loss: 0.07506, accuracy: 0.97700, task: multi, mean loss: 0.16579, multilabel_accuracy: 0.50650, avg. loss over tasks: 0.09368, lr: 0.0004656566413648094
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 57 
task: majority, mean loss: 0.67328, accuracy: 0.79800, task: max, mean loss: 0.85543, accuracy: 0.80300, task: top, mean loss: 1.21406, accuracy: 0.73900, task: multi, mean loss: 0.25137, multilabel_accuracy: 0.37700, avg. loss over tasks: 0.74853
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 58 
task: majority, mean loss: 0.07817, accuracy: 0.97300, task: max, mean loss: 0.06284, accuracy: 0.97800, task: top, mean loss: 0.06292, accuracy: 0.98500, task: multi, mean loss: 0.16001, multilabel_accuracy: 0.51800, avg. loss over tasks: 0.09099, lr: 0.0004482880325978072
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 58 
task: majority, mean loss: 0.49042, accuracy: 0.84300, task: max, mean loss: 0.80479, accuracy: 0.81400, task: top, mean loss: 1.11124, accuracy: 0.75900, task: multi, mean loss: 0.23089, multilabel_accuracy: 0.41600, avg. loss over tasks: 0.65933
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 59 
task: majority, mean loss: 0.07350, accuracy: 0.97500, task: max, mean loss: 0.05901, accuracy: 0.98100, task: top, mean loss: 0.06562, accuracy: 0.98000, task: multi, mean loss: 0.15741, multilabel_accuracy: 0.52750, avg. loss over tasks: 0.08888, lr: 0.0004309830360704473
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 59 
task: majority, mean loss: 0.53534, accuracy: 0.83700, task: max, mean loss: 0.83655, accuracy: 0.82000, task: top, mean loss: 1.13288, accuracy: 0.76300, task: multi, mean loss: 0.23382, multilabel_accuracy: 0.42700, avg. loss over tasks: 0.68465
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 60 
task: majority, mean loss: 0.05069, accuracy: 0.98300, task: max, mean loss: 0.04706, accuracy: 0.98900, task: top, mean loss: 0.03822, accuracy: 0.98900, task: multi, mean loss: 0.14704, multilabel_accuracy: 0.54450, avg. loss over tasks: 0.07075, lr: 0.00041376273525536844
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 60 
task: majority, mean loss: 0.74192, accuracy: 0.80300, task: max, mean loss: 1.02082, accuracy: 0.79200, task: top, mean loss: 1.30962, accuracy: 0.73400, task: multi, mean loss: 0.27367, multilabel_accuracy: 0.37200, avg. loss over tasks: 0.83651
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 61 
task: majority, mean loss: 0.05287, accuracy: 0.98450, task: max, mean loss: 0.04238, accuracy: 0.98600, task: top, mean loss: 0.05649, accuracy: 0.98600, task: multi, mean loss: 0.14722, multilabel_accuracy: 0.55600, avg. loss over tasks: 0.07474, lr: 0.00039664811043652916
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 61 
task: majority, mean loss: 0.54702, accuracy: 0.83500, task: max, mean loss: 0.83159, accuracy: 0.82000, task: top, mean loss: 1.07774, accuracy: 0.77700, task: multi, mean loss: 0.23504, multilabel_accuracy: 0.45700, avg. loss over tasks: 0.67285
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 62 
task: majority, mean loss: 0.05219, accuracy: 0.98350, task: max, mean loss: 0.03658, accuracy: 0.99250, task: top, mean loss: 0.04041, accuracy: 0.98600, task: multi, mean loss: 0.14623, multilabel_accuracy: 0.54000, avg. loss over tasks: 0.06885, lr: 0.00037966001314796593
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 62 
task: majority, mean loss: 0.58670, accuracy: 0.82900, task: max, mean loss: 0.81799, accuracy: 0.82200, task: top, mean loss: 1.17877, accuracy: 0.74800, task: multi, mean loss: 0.24247, multilabel_accuracy: 0.41800, avg. loss over tasks: 0.70648
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 63 
task: majority, mean loss: 0.05009, accuracy: 0.98200, task: max, mean loss: 0.03425, accuracy: 0.99150, task: top, mean loss: 0.03529, accuracy: 0.99050, task: multi, mean loss: 0.14240, multilabel_accuracy: 0.56400, avg. loss over tasks: 0.06551, lr: 0.00036281914076940894
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 63 
task: majority, mean loss: 0.49371, accuracy: 0.85000, task: max, mean loss: 0.84193, accuracy: 0.81400, task: top, mean loss: 1.15784, accuracy: 0.76200, task: multi, mean loss: 0.23085, multilabel_accuracy: 0.44300, avg. loss over tasks: 0.68108
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 64 
task: majority, mean loss: 0.03995, accuracy: 0.98950, task: max, mean loss: 0.03124, accuracy: 0.99100, task: top, mean loss: 0.02604, accuracy: 0.99100, task: multi, mean loss: 0.13621, multilabel_accuracy: 0.58150, avg. loss over tasks: 0.05836, lr: 0.00034614601130971383
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 64 
task: majority, mean loss: 0.55372, accuracy: 0.84100, task: max, mean loss: 0.85368, accuracy: 0.81800, task: top, mean loss: 1.10647, accuracy: 0.78800, task: multi, mean loss: 0.22543, multilabel_accuracy: 0.45700, avg. loss over tasks: 0.68482
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 65 
task: majority, mean loss: 0.04966, accuracy: 0.98350, task: max, mean loss: 0.03290, accuracy: 0.99200, task: top, mean loss: 0.04250, accuracy: 0.98900, task: multi, mean loss: 0.13898, multilabel_accuracy: 0.56700, avg. loss over tasks: 0.06601, lr: 0.0003296609384088285
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 65 
task: majority, mean loss: 0.57662, accuracy: 0.84500, task: max, mean loss: 0.89807, accuracy: 0.81200, task: top, mean loss: 1.21886, accuracy: 0.76300, task: multi, mean loss: 0.23589, multilabel_accuracy: 0.45500, avg. loss over tasks: 0.73236
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 66 
task: majority, mean loss: 0.06293, accuracy: 0.98050, task: max, mean loss: 0.03251, accuracy: 0.99050, task: top, mean loss: 0.04230, accuracy: 0.98600, task: multi, mean loss: 0.14255, multilabel_accuracy: 0.56050, avg. loss over tasks: 0.07007, lr: 0.00031338400658875205
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 66 
task: majority, mean loss: 0.52239, accuracy: 0.85100, task: max, mean loss: 0.83554, accuracy: 0.81000, task: top, mean loss: 1.16111, accuracy: 0.76700, task: multi, mean loss: 0.22170, multilabel_accuracy: 0.45000, avg. loss over tasks: 0.68518
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 67 
task: majority, mean loss: 0.02720, accuracy: 0.99200, task: max, mean loss: 0.01590, accuracy: 0.99750, task: top, mean loss: 0.02553, accuracy: 0.99550, task: multi, mean loss: 0.12761, multilabel_accuracy: 0.61100, avg. loss over tasks: 0.04906, lr: 0.00029733504678363786
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 67 
task: majority, mean loss: 0.41679, accuracy: 0.88900, task: max, mean loss: 0.85807, accuracy: 0.81500, task: top, mean loss: 1.13520, accuracy: 0.77700, task: multi, mean loss: 0.21466, multilabel_accuracy: 0.48000, avg. loss over tasks: 0.65618
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 68 
task: majority, mean loss: 0.02622, accuracy: 0.99350, task: max, mean loss: 0.02189, accuracy: 0.99600, task: top, mean loss: 0.01555, accuracy: 0.99600, task: multi, mean loss: 0.12017, multilabel_accuracy: 0.63100, avg. loss over tasks: 0.04596, lr: 0.0002815336121788558
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 68 
task: majority, mean loss: 0.49471, accuracy: 0.86000, task: max, mean loss: 0.85051, accuracy: 0.82900, task: top, mean loss: 1.10126, accuracy: 0.78900, task: multi, mean loss: 0.21563, multilabel_accuracy: 0.47700, avg. loss over tasks: 0.66553
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 69 
task: majority, mean loss: 0.03433, accuracy: 0.98900, task: max, mean loss: 0.01788, accuracy: 0.99750, task: top, mean loss: 0.02040, accuracy: 0.99500, task: multi, mean loss: 0.12113, multilabel_accuracy: 0.62550, avg. loss over tasks: 0.04843, lr: 0.0002659989543884475
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 69 
task: majority, mean loss: 0.49154, accuracy: 0.85300, task: max, mean loss: 0.92844, accuracy: 0.81200, task: top, mean loss: 1.22708, accuracy: 0.77500, task: multi, mean loss: 0.21884, multilabel_accuracy: 0.48200, avg. loss over tasks: 0.71648
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 70 
task: majority, mean loss: 0.03682, accuracy: 0.98700, task: max, mean loss: 0.02651, accuracy: 0.99250, task: top, mean loss: 0.03050, accuracy: 0.99350, task: multi, mean loss: 0.11989, multilabel_accuracy: 0.63400, avg. loss over tasks: 0.05343, lr: 0.0002507500000000001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 70 
task: majority, mean loss: 0.45455, accuracy: 0.87300, task: max, mean loss: 0.85486, accuracy: 0.82600, task: top, mean loss: 1.19181, accuracy: 0.78000, task: multi, mean loss: 0.21339, multilabel_accuracy: 0.47300, avg. loss over tasks: 0.67865
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 71 
task: majority, mean loss: 0.02271, accuracy: 0.99650, task: max, mean loss: 0.01824, accuracy: 0.99650, task: top, mean loss: 0.02821, accuracy: 0.99500, task: multi, mean loss: 0.11353, multilabel_accuracy: 0.64300, avg. loss over tasks: 0.04567, lr: 0.0002358053275155142
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 71 
task: majority, mean loss: 0.43056, accuracy: 0.87500, task: max, mean loss: 0.88254, accuracy: 0.82600, task: top, mean loss: 1.17746, accuracy: 0.77700, task: multi, mean loss: 0.21452, multilabel_accuracy: 0.49300, avg. loss over tasks: 0.67627
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 72 
task: majority, mean loss: 0.02192, accuracy: 0.99500, task: max, mean loss: 0.01829, accuracy: 0.99550, task: top, mean loss: 0.01236, accuracy: 0.99750, task: multi, mean loss: 0.11214, multilabel_accuracy: 0.64850, avg. loss over tasks: 0.04118, lr: 0.00022118314471636204
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 72 
task: majority, mean loss: 0.40652, accuracy: 0.88200, task: max, mean loss: 0.87803, accuracy: 0.82800, task: top, mean loss: 1.15619, accuracy: 0.78200, task: multi, mean loss: 0.20710, multilabel_accuracy: 0.50000, avg. loss over tasks: 0.66196
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 73 
task: majority, mean loss: 0.01422, accuracy: 0.99750, task: max, mean loss: 0.00983, accuracy: 0.99900, task: top, mean loss: 0.01772, accuracy: 0.99600, task: multi, mean loss: 0.10415, multilabel_accuracy: 0.69050, avg. loss over tasks: 0.03648, lr: 0.00020690126647990973
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 73 
task: majority, mean loss: 0.52180, accuracy: 0.86700, task: max, mean loss: 0.87538, accuracy: 0.82100, task: top, mean loss: 1.18576, accuracy: 0.78500, task: multi, mean loss: 0.21216, multilabel_accuracy: 0.50200, avg. loss over tasks: 0.69878
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 74 
task: majority, mean loss: 0.03051, accuracy: 0.99200, task: max, mean loss: 0.01908, accuracy: 0.99500, task: top, mean loss: 0.03240, accuracy: 0.99250, task: multi, mean loss: 0.11218, multilabel_accuracy: 0.66600, avg. loss over tasks: 0.04854, lr: 0.00019297709307483367
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 74 
task: majority, mean loss: 0.43929, accuracy: 0.87100, task: max, mean loss: 0.84887, accuracy: 0.83300, task: top, mean loss: 1.21439, accuracy: 0.77400, task: multi, mean loss: 0.21298, multilabel_accuracy: 0.49700, avg. loss over tasks: 0.67888
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 75 
task: majority, mean loss: 0.02120, accuracy: 0.99450, task: max, mean loss: 0.01408, accuracy: 0.99550, task: top, mean loss: 0.01658, accuracy: 0.99550, task: multi, mean loss: 0.10429, multilabel_accuracy: 0.67900, avg. loss over tasks: 0.03904, lr: 0.0001794275889615736
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 75 
task: majority, mean loss: 0.44157, accuracy: 0.87800, task: max, mean loss: 0.84059, accuracy: 0.84300, task: top, mean loss: 1.16312, accuracy: 0.77600, task: multi, mean loss: 0.20678, multilabel_accuracy: 0.49800, avg. loss over tasks: 0.66301
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 76 
task: majority, mean loss: 0.01715, accuracy: 0.99450, task: max, mean loss: 0.01484, accuracy: 0.99750, task: top, mean loss: 0.01022, accuracy: 0.99800, task: multi, mean loss: 0.09780, multilabel_accuracy: 0.70050, avg. loss over tasks: 0.03500, lr: 0.0001662692621237503
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 76 
task: majority, mean loss: 0.62506, accuracy: 0.84200, task: max, mean loss: 0.90545, accuracy: 0.82600, task: top, mean loss: 1.28706, accuracy: 0.76600, task: multi, mean loss: 0.22942, multilabel_accuracy: 0.48300, avg. loss over tasks: 0.76175
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 77 
task: majority, mean loss: 0.02068, accuracy: 0.99500, task: max, mean loss: 0.01656, accuracy: 0.99650, task: top, mean loss: 0.01149, accuracy: 0.99850, task: multi, mean loss: 0.10076, multilabel_accuracy: 0.68850, avg. loss over tasks: 0.03737, lr: 0.00015351814395573083
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 77 
task: majority, mean loss: 0.47749, accuracy: 0.86300, task: max, mean loss: 0.88749, accuracy: 0.82800, task: top, mean loss: 1.19816, accuracy: 0.78500, task: multi, mean loss: 0.21376, multilabel_accuracy: 0.48800, avg. loss over tasks: 0.69422
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 78 
task: majority, mean loss: 0.01527, accuracy: 0.99600, task: max, mean loss: 0.01030, accuracy: 0.99800, task: top, mean loss: 0.00882, accuracy: 0.99850, task: multi, mean loss: 0.09800, multilabel_accuracy: 0.68750, avg. loss over tasks: 0.03310, lr: 0.00014118976973084385
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 78 
task: majority, mean loss: 0.37998, accuracy: 0.88600, task: max, mean loss: 0.89447, accuracy: 0.82900, task: top, mean loss: 1.18822, accuracy: 0.78700, task: multi, mean loss: 0.20714, multilabel_accuracy: 0.51000, avg. loss over tasks: 0.66745
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 79 
task: majority, mean loss: 0.01454, accuracy: 0.99650, task: max, mean loss: 0.00945, accuracy: 0.99650, task: top, mean loss: 0.01359, accuracy: 0.99700, task: multi, mean loss: 0.09481, multilabel_accuracy: 0.69850, avg. loss over tasks: 0.03310, lr: 0.0001292991596740417
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 79 
task: majority, mean loss: 0.39984, accuracy: 0.87800, task: max, mean loss: 0.88013, accuracy: 0.83300, task: top, mean loss: 1.20422, accuracy: 0.78000, task: multi, mean loss: 0.20730, multilabel_accuracy: 0.50300, avg. loss over tasks: 0.67287
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 80 
task: majority, mean loss: 0.00964, accuracy: 0.99900, task: max, mean loss: 0.00894, accuracy: 0.99800, task: top, mean loss: 0.00731, accuracy: 0.99850, task: multi, mean loss: 0.08889, multilabel_accuracy: 0.73150, avg. loss over tasks: 0.02870, lr: 0.00011786080066207054
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 80 
task: majority, mean loss: 0.46230, accuracy: 0.87000, task: max, mean loss: 0.84408, accuracy: 0.83700, task: top, mean loss: 1.19173, accuracy: 0.78900, task: multi, mean loss: 0.20683, multilabel_accuracy: 0.51900, avg. loss over tasks: 0.67623
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 81 
task: majority, mean loss: 0.01661, accuracy: 0.99450, task: max, mean loss: 0.01223, accuracy: 0.99750, task: top, mean loss: 0.00880, accuracy: 0.99750, task: multi, mean loss: 0.08794, multilabel_accuracy: 0.72400, avg. loss over tasks: 0.03140, lr: 0.00010688862857344241
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 81 
task: majority, mean loss: 0.40244, accuracy: 0.87500, task: max, mean loss: 0.83266, accuracy: 0.82900, task: top, mean loss: 1.15739, accuracy: 0.79400, task: multi, mean loss: 0.20382, multilabel_accuracy: 0.52200, avg. loss over tasks: 0.64908
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 82 
task: majority, mean loss: 0.01241, accuracy: 0.99750, task: max, mean loss: 0.00759, accuracy: 0.99850, task: top, mean loss: 0.00550, accuracy: 0.99900, task: multi, mean loss: 0.08679, multilabel_accuracy: 0.73650, avg. loss over tasks: 0.02807, lr: 9.63960113097138e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 82 
task: majority, mean loss: 0.44371, accuracy: 0.87000, task: max, mean loss: 0.87411, accuracy: 0.83500, task: top, mean loss: 1.17196, accuracy: 0.78900, task: multi, mean loss: 0.20761, multilabel_accuracy: 0.51700, avg. loss over tasks: 0.67435
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 83 
task: majority, mean loss: 0.01129, accuracy: 0.99800, task: max, mean loss: 0.00663, accuracy: 0.99900, task: top, mean loss: 0.00735, accuracy: 0.99900, task: multi, mean loss: 0.08551, multilabel_accuracy: 0.73250, avg. loss over tasks: 0.02769, lr: 8.639573250875671e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 83 
task: majority, mean loss: 0.39144, accuracy: 0.88100, task: max, mean loss: 0.83196, accuracy: 0.83800, task: top, mean loss: 1.13051, accuracy: 0.79100, task: multi, mean loss: 0.20212, multilabel_accuracy: 0.52100, avg. loss over tasks: 0.63901
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 84 
task: majority, mean loss: 0.00858, accuracy: 0.99800, task: max, mean loss: 0.00614, accuracy: 0.99900, task: top, mean loss: 0.00614, accuracy: 0.99900, task: multi, mean loss: 0.08392, multilabel_accuracy: 0.73750, avg. loss over tasks: 0.02620, lr: 7.689997596986524e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 84 
task: majority, mean loss: 0.37358, accuracy: 0.89100, task: max, mean loss: 0.86617, accuracy: 0.83400, task: top, mean loss: 1.12151, accuracy: 0.79400, task: multi, mean loss: 0.20142, multilabel_accuracy: 0.52800, avg. loss over tasks: 0.64067
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 85 
task: majority, mean loss: 0.00819, accuracy: 0.99850, task: max, mean loss: 0.00611, accuracy: 0.99950, task: top, mean loss: 0.00502, accuracy: 0.99950, task: multi, mean loss: 0.08166, multilabel_accuracy: 0.74900, avg. loss over tasks: 0.02524, lr: 6.792031080967287e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 85 
task: majority, mean loss: 0.37454, accuracy: 0.89100, task: max, mean loss: 0.84463, accuracy: 0.83800, task: top, mean loss: 1.09341, accuracy: 0.79500, task: multi, mean loss: 0.19826, multilabel_accuracy: 0.53000, avg. loss over tasks: 0.62771
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 86 
task: majority, mean loss: 0.00941, accuracy: 0.99850, task: max, mean loss: 0.00690, accuracy: 0.99850, task: top, mean loss: 0.00432, accuracy: 0.99950, task: multi, mean loss: 0.08056, multilabel_accuracy: 0.76450, avg. loss over tasks: 0.02530, lr: 5.946767736696608e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 86 
task: majority, mean loss: 0.39250, accuracy: 0.88400, task: max, mean loss: 0.86058, accuracy: 0.83800, task: top, mean loss: 1.14421, accuracy: 0.79000, task: multi, mean loss: 0.20083, multilabel_accuracy: 0.52300, avg. loss over tasks: 0.64953
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 87 
task: majority, mean loss: 0.00829, accuracy: 0.99850, task: max, mean loss: 0.00794, accuracy: 0.99850, task: top, mean loss: 0.00785, accuracy: 0.99800, task: multi, mean loss: 0.08022, multilabel_accuracy: 0.74900, avg. loss over tasks: 0.02607, lr: 5.155237387356618e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 87 
task: majority, mean loss: 0.38305, accuracy: 0.88200, task: max, mean loss: 0.87185, accuracy: 0.83300, task: top, mean loss: 1.12907, accuracy: 0.79300, task: multi, mean loss: 0.20078, multilabel_accuracy: 0.52700, avg. loss over tasks: 0.64619
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 88 
task: majority, mean loss: 0.00950, accuracy: 0.99850, task: max, mean loss: 0.00606, accuracy: 0.99900, task: top, mean loss: 0.00479, accuracy: 0.99900, task: multi, mean loss: 0.07808, multilabel_accuracy: 0.77200, avg. loss over tasks: 0.02461, lr: 4.418404390752081e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 88 
task: majority, mean loss: 0.42798, accuracy: 0.87800, task: max, mean loss: 0.87758, accuracy: 0.83800, task: top, mean loss: 1.15912, accuracy: 0.79400, task: multi, mean loss: 0.20617, multilabel_accuracy: 0.53000, avg. loss over tasks: 0.66771
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 89 
task: majority, mean loss: 0.00924, accuracy: 0.99700, task: max, mean loss: 0.00484, accuracy: 1.00000, task: top, mean loss: 0.00791, accuracy: 0.99750, task: multi, mean loss: 0.07818, multilabel_accuracy: 0.76250, avg. loss over tasks: 0.02504, lr: 3.7371664643889735e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 89 
task: majority, mean loss: 0.39062, accuracy: 0.88700, task: max, mean loss: 0.87774, accuracy: 0.83800, task: top, mean loss: 1.17623, accuracy: 0.79100, task: multi, mean loss: 0.19938, multilabel_accuracy: 0.51300, avg. loss over tasks: 0.66099
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 90 
task: majority, mean loss: 0.00639, accuracy: 0.99950, task: max, mean loss: 0.00450, accuracy: 1.00000, task: top, mean loss: 0.00486, accuracy: 0.99900, task: multi, mean loss: 0.07591, multilabel_accuracy: 0.77300, avg. loss over tasks: 0.02292, lr: 3.11235359174388e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 90 
task: majority, mean loss: 0.38445, accuracy: 0.88400, task: max, mean loss: 0.87275, accuracy: 0.83400, task: top, mean loss: 1.16172, accuracy: 0.79200, task: multi, mean loss: 0.19853, multilabel_accuracy: 0.51400, avg. loss over tasks: 0.65436
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 91 
task: majority, mean loss: 0.00596, accuracy: 0.99950, task: max, mean loss: 0.00567, accuracy: 0.99900, task: top, mean loss: 0.00366, accuracy: 1.00000, task: multi, mean loss: 0.07517, multilabel_accuracy: 0.76850, avg. loss over tasks: 0.02262, lr: 2.544727011057081e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 91 
task: majority, mean loss: 0.38424, accuracy: 0.88500, task: max, mean loss: 0.86074, accuracy: 0.83800, task: top, mean loss: 1.15301, accuracy: 0.79000, task: multi, mean loss: 0.19952, multilabel_accuracy: 0.52100, avg. loss over tasks: 0.64938
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 92 
task: majority, mean loss: 0.01174, accuracy: 0.99650, task: max, mean loss: 0.00423, accuracy: 1.00000, task: top, mean loss: 0.00372, accuracy: 0.99950, task: multi, mean loss: 0.07711, multilabel_accuracy: 0.77350, avg. loss over tasks: 0.02420, lr: 2.0349782878809714e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 92 
task: majority, mean loss: 0.37858, accuracy: 0.88900, task: max, mean loss: 0.86106, accuracy: 0.83300, task: top, mean loss: 1.13685, accuracy: 0.79600, task: multi, mean loss: 0.19942, multilabel_accuracy: 0.53000, avg. loss over tasks: 0.64398
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 93 
task: majority, mean loss: 0.00774, accuracy: 0.99900, task: max, mean loss: 0.00486, accuracy: 0.99900, task: top, mean loss: 0.00404, accuracy: 0.99950, task: multi, mean loss: 0.07306, multilabel_accuracy: 0.77300, avg. loss over tasks: 0.02243, lr: 1.583728472513976e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 93 
task: majority, mean loss: 0.39996, accuracy: 0.88700, task: max, mean loss: 0.85015, accuracy: 0.84100, task: top, mean loss: 1.15119, accuracy: 0.79100, task: multi, mean loss: 0.19980, multilabel_accuracy: 0.52800, avg. loss over tasks: 0.65027
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 94 
task: majority, mean loss: 0.00724, accuracy: 0.99850, task: max, mean loss: 0.00514, accuracy: 0.99850, task: top, mean loss: 0.00517, accuracy: 0.99850, task: multi, mean loss: 0.07437, multilabel_accuracy: 0.77300, avg. loss over tasks: 0.02298, lr: 1.1915273433464114e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 94 
task: majority, mean loss: 0.39577, accuracy: 0.89000, task: max, mean loss: 0.85432, accuracy: 0.83900, task: top, mean loss: 1.17408, accuracy: 0.78700, task: multi, mean loss: 0.19942, multilabel_accuracy: 0.52200, avg. loss over tasks: 0.65590
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 95 
task: majority, mean loss: 0.00864, accuracy: 0.99900, task: max, mean loss: 0.00534, accuracy: 0.99950, task: top, mean loss: 0.00423, accuracy: 0.99950, task: multi, mean loss: 0.07434, multilabel_accuracy: 0.77450, avg. loss over tasks: 0.02314, lr: 8.588527370402095e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 95 
task: majority, mean loss: 0.38675, accuracy: 0.88600, task: max, mean loss: 0.85717, accuracy: 0.83900, task: top, mean loss: 1.16774, accuracy: 0.78900, task: multi, mean loss: 0.19974, multilabel_accuracy: 0.52600, avg. loss over tasks: 0.65285
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 96 
task: majority, mean loss: 0.00876, accuracy: 0.99900, task: max, mean loss: 0.00477, accuracy: 0.99950, task: top, mean loss: 0.00339, accuracy: 0.99950, task: multi, mean loss: 0.07200, multilabel_accuracy: 0.79150, avg. loss over tasks: 0.02223, lr: 5.86109966358566e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 96 
task: majority, mean loss: 0.38739, accuracy: 0.88300, task: max, mean loss: 0.85682, accuracy: 0.83600, task: top, mean loss: 1.16930, accuracy: 0.79400, task: multi, mean loss: 0.19990, multilabel_accuracy: 0.53200, avg. loss over tasks: 0.65335
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 97 
task: majority, mean loss: 0.00860, accuracy: 0.99850, task: max, mean loss: 0.00489, accuracy: 0.99900, task: top, mean loss: 0.00326, accuracy: 0.99950, task: multi, mean loss: 0.07343, multilabel_accuracy: 0.77000, avg. loss over tasks: 0.02254, lr: 3.7363132635474912e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 97 
task: majority, mean loss: 0.38698, accuracy: 0.88500, task: max, mean loss: 0.85980, accuracy: 0.83500, task: top, mean loss: 1.16823, accuracy: 0.79500, task: multi, mean loss: 0.19976, multilabel_accuracy: 0.52300, avg. loss over tasks: 0.65369
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 98 
task: majority, mean loss: 0.00645, accuracy: 0.99900, task: max, mean loss: 0.00412, accuracy: 1.00000, task: top, mean loss: 0.00385, accuracy: 1.00000, task: multi, mean loss: 0.07237, multilabel_accuracy: 0.78950, avg. loss over tasks: 0.02170, lr: 2.2167568952178134e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 98 
task: majority, mean loss: 0.38380, accuracy: 0.88300, task: max, mean loss: 0.86603, accuracy: 0.83800, task: top, mean loss: 1.17303, accuracy: 0.79500, task: multi, mean loss: 0.19948, multilabel_accuracy: 0.52200, avg. loss over tasks: 0.65559
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 99 
task: majority, mean loss: 0.00606, accuracy: 0.99900, task: max, mean loss: 0.00353, accuracy: 1.00000, task: top, mean loss: 0.00562, accuracy: 0.99900, task: multi, mean loss: 0.07068, multilabel_accuracy: 0.80200, avg. loss over tasks: 0.02147, lr: 1.3042819039616668e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 99 
task: majority, mean loss: 0.39218, accuracy: 0.88700, task: max, mean loss: 0.86369, accuracy: 0.84100, task: top, mean loss: 1.17658, accuracy: 0.78900, task: multi, mean loss: 0.20000, multilabel_accuracy: 0.52400, avg. loss over tasks: 0.65811
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 100 
task: majority, mean loss: 0.00703, accuracy: 0.99850, task: max, mean loss: 0.00705, accuracy: 0.99800, task: top, mean loss: 0.00455, accuracy: 0.99950, task: multi, mean loss: 0.07187, multilabel_accuracy: 0.79100, avg. loss over tasks: 0.02263, lr: 1e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 100 
task: majority, mean loss: 0.38083, accuracy: 0.88300, task: max, mean loss: 0.86169, accuracy: 0.83900, task: top, mean loss: 1.16595, accuracy: 0.79700, task: multi, mean loss: 0.19944, multilabel_accuracy: 0.52700, avg. loss over tasks: 0.65198
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

