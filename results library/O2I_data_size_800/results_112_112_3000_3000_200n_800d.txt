Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 4,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': False,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train Epoch: 1 
task: majority, mean loss: 2.35787, accuracy: 0.10875, task: max, mean loss: 2.21278, accuracy: 0.27250, task: top, mean loss: 2.36241, accuracy: 0.09875, task: multi, mean loss: 0.69883, multilabel_accuracy: 0.00125, avg. loss over tasks: 1.90797, lr: 0.0001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
Test Epoch: 1 
task: majority, mean loss: 2.31570, accuracy: 0.10100, task: max, mean loss: 1.92291, accuracy: 0.27400, task: top, mean loss: 2.31860, accuracy: 0.10400, task: multi, mean loss: 0.63253, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79744
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 2 
task: majority, mean loss: 2.33548, accuracy: 0.09625, task: max, mean loss: 1.88000, accuracy: 0.26625, task: top, mean loss: 2.33466, accuracy: 0.11875, task: multi, mean loss: 0.61482, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79124, lr: 0.0002
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 2 
task: majority, mean loss: 2.32986, accuracy: 0.08900, task: max, mean loss: 1.87488, accuracy: 0.27400, task: top, mean loss: 2.31806, accuracy: 0.10800, task: multi, mean loss: 0.60458, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78184
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 3 
task: majority, mean loss: 2.32495, accuracy: 0.10750, task: max, mean loss: 1.85661, accuracy: 0.26000, task: top, mean loss: 2.33128, accuracy: 0.10875, task: multi, mean loss: 0.60588, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77968, lr: 0.0003
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 3 
task: majority, mean loss: 2.31680, accuracy: 0.11400, task: max, mean loss: 1.89615, accuracy: 0.27400, task: top, mean loss: 2.31173, accuracy: 0.09000, task: multi, mean loss: 0.60266, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78183
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 4 
task: majority, mean loss: 2.31368, accuracy: 0.11250, task: max, mean loss: 1.84217, accuracy: 0.27000, task: top, mean loss: 2.33324, accuracy: 0.10875, task: multi, mean loss: 0.60557, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77367, lr: 0.0004
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 4 
task: majority, mean loss: 2.45981, accuracy: 0.08800, task: max, mean loss: 1.90464, accuracy: 0.28300, task: top, mean loss: 2.38248, accuracy: 0.09600, task: multi, mean loss: 0.60461, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.83789
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 5 
task: majority, mean loss: 2.28255, accuracy: 0.13875, task: max, mean loss: 1.84255, accuracy: 0.26250, task: top, mean loss: 2.31624, accuracy: 0.10750, task: multi, mean loss: 0.60414, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76137, lr: 0.0005
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 5 
task: majority, mean loss: 2.47116, accuracy: 0.09000, task: max, mean loss: 1.92304, accuracy: 0.23000, task: top, mean loss: 2.42587, accuracy: 0.09500, task: multi, mean loss: 0.60546, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.85638
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 6 
task: majority, mean loss: 2.28498, accuracy: 0.13375, task: max, mean loss: 1.83234, accuracy: 0.26500, task: top, mean loss: 2.32134, accuracy: 0.11500, task: multi, mean loss: 0.60338, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76051, lr: 0.0006
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 6 
task: majority, mean loss: 2.52954, accuracy: 0.08800, task: max, mean loss: 1.92086, accuracy: 0.28100, task: top, mean loss: 2.50778, accuracy: 0.09500, task: multi, mean loss: 0.61469, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.89322
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 7 
task: majority, mean loss: 2.18283, accuracy: 0.19875, task: max, mean loss: 1.80339, accuracy: 0.26500, task: top, mean loss: 2.24886, accuracy: 0.15375, task: multi, mean loss: 0.59643, multilabel_accuracy: 0.00125, avg. loss over tasks: 1.70788, lr: 0.0007000000000000001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 7 
task: majority, mean loss: 2.47867, accuracy: 0.14700, task: max, mean loss: 2.14661, accuracy: 0.16800, task: top, mean loss: 2.47362, accuracy: 0.10500, task: multi, mean loss: 0.59967, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.92464
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 8 
task: majority, mean loss: 2.12442, accuracy: 0.20250, task: max, mean loss: 1.79807, accuracy: 0.28250, task: top, mean loss: 2.21927, accuracy: 0.17750, task: multi, mean loss: 0.59227, multilabel_accuracy: 0.00125, avg. loss over tasks: 1.68351, lr: 0.0008
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 8 
task: majority, mean loss: 2.54966, accuracy: 0.14800, task: max, mean loss: 1.88046, accuracy: 0.30800, task: top, mean loss: 2.48585, accuracy: 0.13400, task: multi, mean loss: 0.63561, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.88790
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 9 
task: majority, mean loss: 2.04046, accuracy: 0.24125, task: max, mean loss: 1.78453, accuracy: 0.30500, task: top, mean loss: 2.18520, accuracy: 0.20125, task: multi, mean loss: 0.59137, multilabel_accuracy: 0.00125, avg. loss over tasks: 1.65039, lr: 0.0009
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 9 
task: majority, mean loss: 3.13397, accuracy: 0.09000, task: max, mean loss: 1.92543, accuracy: 0.17100, task: top, mean loss: 2.83929, accuracy: 0.09500, task: multi, mean loss: 0.65184, multilabel_accuracy: 0.00300, avg. loss over tasks: 2.13763
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 10 
task: majority, mean loss: 2.01493, accuracy: 0.24625, task: max, mean loss: 1.74880, accuracy: 0.31000, task: top, mean loss: 2.13645, accuracy: 0.22625, task: multi, mean loss: 0.57790, multilabel_accuracy: 0.00875, avg. loss over tasks: 1.61952, lr: 0.001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 10 
task: majority, mean loss: 2.67328, accuracy: 0.10000, task: max, mean loss: 1.98953, accuracy: 0.21300, task: top, mean loss: 2.59868, accuracy: 0.11400, task: multi, mean loss: 0.63793, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.97485
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 11 
task: majority, mean loss: 1.84598, accuracy: 0.27250, task: max, mean loss: 1.71819, accuracy: 0.31500, task: top, mean loss: 2.09226, accuracy: 0.21000, task: multi, mean loss: 0.56789, multilabel_accuracy: 0.01125, avg. loss over tasks: 1.55608, lr: 0.0009996957180960382
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 11 
task: majority, mean loss: 1.83046, accuracy: 0.27800, task: max, mean loss: 1.72969, accuracy: 0.28400, task: top, mean loss: 2.08397, accuracy: 0.24100, task: multi, mean loss: 0.55786, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.55049
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 12 
task: majority, mean loss: 1.83268, accuracy: 0.28875, task: max, mean loss: 1.68368, accuracy: 0.34875, task: top, mean loss: 2.06310, accuracy: 0.23750, task: multi, mean loss: 0.56369, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.53579, lr: 0.0009987832431047822
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 12 
task: majority, mean loss: 2.08270, accuracy: 0.22400, task: max, mean loss: 1.99403, accuracy: 0.22600, task: top, mean loss: 2.25488, accuracy: 0.19700, task: multi, mean loss: 0.60452, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.73403
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 13 
task: majority, mean loss: 1.83131, accuracy: 0.30250, task: max, mean loss: 1.67724, accuracy: 0.36250, task: top, mean loss: 2.03750, accuracy: 0.24125, task: multi, mean loss: 0.56228, multilabel_accuracy: 0.01625, avg. loss over tasks: 1.52708, lr: 0.0009972636867364526
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 13 
task: majority, mean loss: 3.18507, accuracy: 0.14000, task: max, mean loss: 1.90960, accuracy: 0.26600, task: top, mean loss: 2.63163, accuracy: 0.13600, task: multi, mean loss: 0.69124, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.10438
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 14 
task: majority, mean loss: 1.74525, accuracy: 0.32375, task: max, mean loss: 1.66635, accuracy: 0.34375, task: top, mean loss: 1.98410, accuracy: 0.23500, task: multi, mean loss: 0.55654, multilabel_accuracy: 0.00625, avg. loss over tasks: 1.48806, lr: 0.0009951389003364144
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 14 
task: majority, mean loss: 1.84480, accuracy: 0.30300, task: max, mean loss: 1.68566, accuracy: 0.36500, task: top, mean loss: 2.05676, accuracy: 0.22200, task: multi, mean loss: 0.58309, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.54258
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 15 
task: majority, mean loss: 1.76210, accuracy: 0.30625, task: max, mean loss: 1.61711, accuracy: 0.37500, task: top, mean loss: 1.94805, accuracy: 0.26875, task: multi, mean loss: 0.55513, multilabel_accuracy: 0.01125, avg. loss over tasks: 1.47060, lr: 0.000992411472629598
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 15 
task: majority, mean loss: 2.54947, accuracy: 0.20300, task: max, mean loss: 1.72351, accuracy: 0.34500, task: top, mean loss: 2.64316, accuracy: 0.13600, task: multi, mean loss: 0.65265, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.89220
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 16 
task: majority, mean loss: 1.62086, accuracy: 0.37250, task: max, mean loss: 1.58161, accuracy: 0.39250, task: top, mean loss: 1.89217, accuracy: 0.28625, task: multi, mean loss: 0.54862, multilabel_accuracy: 0.01625, avg. loss over tasks: 1.41082, lr: 0.000989084726566536
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 16 
task: majority, mean loss: 2.49648, accuracy: 0.20000, task: max, mean loss: 1.90379, accuracy: 0.25400, task: top, mean loss: 2.36019, accuracy: 0.19500, task: multi, mean loss: 0.60146, multilabel_accuracy: 0.01100, avg. loss over tasks: 1.84048
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 17 
task: majority, mean loss: 1.57309, accuracy: 0.38125, task: max, mean loss: 1.57910, accuracy: 0.38375, task: top, mean loss: 1.81622, accuracy: 0.31875, task: multi, mean loss: 0.54506, multilabel_accuracy: 0.01250, avg. loss over tasks: 1.37837, lr: 0.00098516271527486
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 17 
task: majority, mean loss: 1.53265, accuracy: 0.41800, task: max, mean loss: 1.63905, accuracy: 0.37800, task: top, mean loss: 1.85602, accuracy: 0.32100, task: multi, mean loss: 0.55263, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.39509
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 18 
task: majority, mean loss: 1.58233, accuracy: 0.37250, task: max, mean loss: 1.58800, accuracy: 0.41125, task: top, mean loss: 1.75575, accuracy: 0.33750, task: multi, mean loss: 0.54720, multilabel_accuracy: 0.01250, avg. loss over tasks: 1.36832, lr: 0.0009806502171211902
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 18 
task: majority, mean loss: 2.49720, accuracy: 0.20100, task: max, mean loss: 1.76891, accuracy: 0.30600, task: top, mean loss: 2.35245, accuracy: 0.21500, task: multi, mean loss: 0.62463, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.81080
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 19 
task: majority, mean loss: 1.59248, accuracy: 0.41000, task: max, mean loss: 1.58665, accuracy: 0.39750, task: top, mean loss: 1.78583, accuracy: 0.32625, task: multi, mean loss: 0.54345, multilabel_accuracy: 0.01375, avg. loss over tasks: 1.37710, lr: 0.0009755527298894293
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 19 
task: majority, mean loss: 2.70225, accuracy: 0.22800, task: max, mean loss: 1.73670, accuracy: 0.30700, task: top, mean loss: 2.12682, accuracy: 0.24800, task: multi, mean loss: 0.64876, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.80363
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 20 
task: majority, mean loss: 1.65103, accuracy: 0.35625, task: max, mean loss: 1.61683, accuracy: 0.39375, task: top, mean loss: 1.81461, accuracy: 0.35000, task: multi, mean loss: 0.54879, multilabel_accuracy: 0.01250, avg. loss over tasks: 1.40781, lr: 0.0009698764640825613
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 20 
task: majority, mean loss: 3.35738, accuracy: 0.14300, task: max, mean loss: 1.89713, accuracy: 0.30800, task: top, mean loss: 2.84632, accuracy: 0.16600, task: multi, mean loss: 0.69030, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.19778
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 21 
task: majority, mean loss: 1.45656, accuracy: 0.45500, task: max, mean loss: 1.52890, accuracy: 0.43875, task: top, mean loss: 1.63342, accuracy: 0.40125, task: multi, mean loss: 0.52739, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.28657, lr: 0.0009636283353561103
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 21 
task: majority, mean loss: 2.38614, accuracy: 0.28000, task: max, mean loss: 2.21658, accuracy: 0.21000, task: top, mean loss: 2.19112, accuracy: 0.22900, task: multi, mean loss: 0.60093, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.84869
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 22 
task: majority, mean loss: 1.37882, accuracy: 0.45500, task: max, mean loss: 1.48354, accuracy: 0.44375, task: top, mean loss: 1.57482, accuracy: 0.42250, task: multi, mean loss: 0.52611, multilabel_accuracy: 0.01625, avg. loss over tasks: 1.24082, lr: 0.0009568159560924791
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 22 
task: majority, mean loss: 2.06516, accuracy: 0.27400, task: max, mean loss: 1.69366, accuracy: 0.38900, task: top, mean loss: 2.20148, accuracy: 0.27400, task: multi, mean loss: 0.56137, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.63042
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 23 
task: majority, mean loss: 1.35522, accuracy: 0.47250, task: max, mean loss: 1.47184, accuracy: 0.44500, task: top, mean loss: 1.55186, accuracy: 0.42375, task: multi, mean loss: 0.51964, multilabel_accuracy: 0.02875, avg. loss over tasks: 1.22464, lr: 0.000949447626126434
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 23 
task: majority, mean loss: 4.24358, accuracy: 0.10800, task: max, mean loss: 1.84742, accuracy: 0.27700, task: top, mean loss: 3.12751, accuracy: 0.17400, task: multi, mean loss: 0.73960, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.48953
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 24 
task: majority, mean loss: 1.42151, accuracy: 0.45125, task: max, mean loss: 1.48695, accuracy: 0.44625, task: top, mean loss: 1.62833, accuracy: 0.41625, task: multi, mean loss: 0.52083, multilabel_accuracy: 0.01875, avg. loss over tasks: 1.26440, lr: 0.000941532322633034
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 24 
task: majority, mean loss: 2.87964, accuracy: 0.18200, task: max, mean loss: 2.09419, accuracy: 0.24900, task: top, mean loss: 2.57246, accuracy: 0.21000, task: multi, mean loss: 0.67315, multilabel_accuracy: 0.01000, avg. loss over tasks: 2.05486
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 25 
task: majority, mean loss: 1.25325, accuracy: 0.53625, task: max, mean loss: 1.41891, accuracy: 0.48125, task: top, mean loss: 1.48464, accuracy: 0.46000, task: multi, mean loss: 0.50689, multilabel_accuracy: 0.02875, avg. loss over tasks: 1.16592, lr: 0.0009330796891903273
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 25 
task: majority, mean loss: 1.61403, accuracy: 0.38600, task: max, mean loss: 1.55232, accuracy: 0.38000, task: top, mean loss: 1.66277, accuracy: 0.39900, task: multi, mean loss: 0.53153, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.34016
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 26 
task: majority, mean loss: 1.28240, accuracy: 0.51375, task: max, mean loss: 1.40190, accuracy: 0.50125, task: top, mean loss: 1.42572, accuracy: 0.47750, task: multi, mean loss: 0.50288, multilabel_accuracy: 0.02625, avg. loss over tasks: 1.15323, lr: 0.0009241000240301347
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 26 
task: majority, mean loss: 3.47567, accuracy: 0.23400, task: max, mean loss: 1.98289, accuracy: 0.25700, task: top, mean loss: 2.90031, accuracy: 0.22300, task: multi, mean loss: 0.67960, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.25962
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 27 
task: majority, mean loss: 1.23672, accuracy: 0.57125, task: max, mean loss: 1.37597, accuracy: 0.49625, task: top, mean loss: 1.38835, accuracy: 0.48000, task: multi, mean loss: 0.50332, multilabel_accuracy: 0.02625, avg. loss over tasks: 1.12609, lr: 0.0009146042674912433
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 27 
task: majority, mean loss: 1.78605, accuracy: 0.34400, task: max, mean loss: 1.53649, accuracy: 0.43900, task: top, mean loss: 1.58709, accuracy: 0.45200, task: multi, mean loss: 0.53642, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.36152
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 28 
task: majority, mean loss: 1.13908, accuracy: 0.57375, task: max, mean loss: 1.30756, accuracy: 0.52625, task: top, mean loss: 1.26517, accuracy: 0.54375, task: multi, mean loss: 0.48901, multilabel_accuracy: 0.02875, avg. loss over tasks: 1.05020, lr: 0.0009046039886902862
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 28 
task: majority, mean loss: 1.88077, accuracy: 0.35200, task: max, mean loss: 1.87358, accuracy: 0.37300, task: top, mean loss: 2.10468, accuracy: 0.33700, task: multi, mean loss: 0.59669, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.61393
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 29 
task: majority, mean loss: 1.08383, accuracy: 0.59000, task: max, mean loss: 1.29951, accuracy: 0.54125, task: top, mean loss: 1.23098, accuracy: 0.57125, task: multi, mean loss: 0.48639, multilabel_accuracy: 0.03750, avg. loss over tasks: 1.02518, lr: 0.0008941113714265575
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 29 
task: majority, mean loss: 3.33400, accuracy: 0.16900, task: max, mean loss: 1.93023, accuracy: 0.32500, task: top, mean loss: 2.54287, accuracy: 0.25900, task: multi, mean loss: 0.69476, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.12546
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 30 
task: majority, mean loss: 1.08523, accuracy: 0.59750, task: max, mean loss: 1.28448, accuracy: 0.52500, task: top, mean loss: 1.27635, accuracy: 0.56000, task: multi, mean loss: 0.48791, multilabel_accuracy: 0.04250, avg. loss over tasks: 1.03350, lr: 0.0008831391993379295
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 30 
task: majority, mean loss: 1.59327, accuracy: 0.47800, task: max, mean loss: 1.52480, accuracy: 0.45000, task: top, mean loss: 1.57464, accuracy: 0.49000, task: multi, mean loss: 0.52304, multilabel_accuracy: 0.02400, avg. loss over tasks: 1.30394
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 31 
task: majority, mean loss: 0.99581, accuracy: 0.63750, task: max, mean loss: 1.21527, accuracy: 0.55750, task: top, mean loss: 1.16002, accuracy: 0.58250, task: multi, mean loss: 0.47458, multilabel_accuracy: 0.04750, avg. loss over tasks: 0.96142, lr: 0.0008717008403259584
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 31 
task: majority, mean loss: 1.84121, accuracy: 0.37700, task: max, mean loss: 1.95845, accuracy: 0.36700, task: top, mean loss: 1.64000, accuracy: 0.44400, task: multi, mean loss: 0.55768, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.49934
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 32 
task: majority, mean loss: 0.82570, accuracy: 0.71375, task: max, mean loss: 1.11868, accuracy: 0.58125, task: top, mean loss: 1.01239, accuracy: 0.64625, task: multi, mean loss: 0.45802, multilabel_accuracy: 0.04750, avg. loss over tasks: 0.85370, lr: 0.0008598102302691562
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 32 
task: majority, mean loss: 1.70455, accuracy: 0.44900, task: max, mean loss: 1.81238, accuracy: 0.40900, task: top, mean loss: 1.41044, accuracy: 0.54200, task: multi, mean loss: 0.55028, multilabel_accuracy: 0.03300, avg. loss over tasks: 1.36941
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 33 
task: majority, mean loss: 0.81290, accuracy: 0.70125, task: max, mean loss: 1.07277, accuracy: 0.61000, task: top, mean loss: 0.97371, accuracy: 0.65625, task: multi, mean loss: 0.45300, multilabel_accuracy: 0.04875, avg. loss over tasks: 0.82810, lr: 0.0008474818560442692
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 33 
task: majority, mean loss: 1.81777, accuracy: 0.44400, task: max, mean loss: 1.76500, accuracy: 0.43000, task: top, mean loss: 1.73192, accuracy: 0.44600, task: multi, mean loss: 0.56288, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.46939
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 34 
task: majority, mean loss: 0.70417, accuracy: 0.72875, task: max, mean loss: 1.03568, accuracy: 0.62500, task: top, mean loss: 0.87496, accuracy: 0.69500, task: multi, mean loss: 0.44240, multilabel_accuracy: 0.05875, avg. loss over tasks: 0.76430, lr: 0.0008347307378762497
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 34 
task: majority, mean loss: 1.10552, accuracy: 0.57900, task: max, mean loss: 1.40005, accuracy: 0.51600, task: top, mean loss: 1.24573, accuracy: 0.56900, task: multi, mean loss: 0.49055, multilabel_accuracy: 0.04200, avg. loss over tasks: 1.06046
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 35 
task: majority, mean loss: 0.73024, accuracy: 0.74000, task: max, mean loss: 0.99562, accuracy: 0.63875, task: top, mean loss: 0.88381, accuracy: 0.70375, task: multi, mean loss: 0.44045, multilabel_accuracy: 0.06625, avg. loss over tasks: 0.76253, lr: 0.0008215724110384264
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 35 
task: majority, mean loss: 1.23141, accuracy: 0.58500, task: max, mean loss: 1.22163, accuracy: 0.55200, task: top, mean loss: 1.25316, accuracy: 0.61400, task: multi, mean loss: 0.47345, multilabel_accuracy: 0.03600, avg. loss over tasks: 1.04491
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 36 
task: majority, mean loss: 0.71278, accuracy: 0.75250, task: max, mean loss: 1.01357, accuracy: 0.63125, task: top, mean loss: 0.83019, accuracy: 0.70875, task: multi, mean loss: 0.43622, multilabel_accuracy: 0.04750, avg. loss over tasks: 0.74819, lr: 0.0008080229069251663
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 36 
task: majority, mean loss: 1.54724, accuracy: 0.53000, task: max, mean loss: 1.50988, accuracy: 0.49600, task: top, mean loss: 1.57364, accuracy: 0.51000, task: multi, mean loss: 0.50599, multilabel_accuracy: 0.03800, avg. loss over tasks: 1.28419
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 37 
task: majority, mean loss: 0.74127, accuracy: 0.73500, task: max, mean loss: 0.97579, accuracy: 0.64875, task: top, mean loss: 0.88825, accuracy: 0.68500, task: multi, mean loss: 0.43598, multilabel_accuracy: 0.05375, avg. loss over tasks: 0.76032, lr: 0.0007940987335200902
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 37 
task: majority, mean loss: 1.76470, accuracy: 0.49100, task: max, mean loss: 1.47847, accuracy: 0.49800, task: top, mean loss: 1.74665, accuracy: 0.48800, task: multi, mean loss: 0.50472, multilabel_accuracy: 0.05100, avg. loss over tasks: 1.37363
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 38 
task: majority, mean loss: 0.66351, accuracy: 0.75375, task: max, mean loss: 0.88476, accuracy: 0.66625, task: top, mean loss: 0.78146, accuracy: 0.72750, task: multi, mean loss: 0.41792, multilabel_accuracy: 0.06125, avg. loss over tasks: 0.68691, lr: 0.0007798168552836382
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 38 
task: majority, mean loss: 1.19641, accuracy: 0.59900, task: max, mean loss: 1.26146, accuracy: 0.57000, task: top, mean loss: 1.17331, accuracy: 0.60500, task: multi, mean loss: 0.47303, multilabel_accuracy: 0.05200, avg. loss over tasks: 1.02605
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 39 
task: majority, mean loss: 0.64181, accuracy: 0.77625, task: max, mean loss: 0.79001, accuracy: 0.71875, task: top, mean loss: 0.65515, accuracy: 0.78875, task: multi, mean loss: 0.41605, multilabel_accuracy: 0.06875, avg. loss over tasks: 0.62576, lr: 0.000765194672484486
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 39 
task: majority, mean loss: 1.35286, accuracy: 0.57400, task: max, mean loss: 1.73277, accuracy: 0.43800, task: top, mean loss: 1.36282, accuracy: 0.57500, task: multi, mean loss: 0.50217, multilabel_accuracy: 0.05400, avg. loss over tasks: 1.23765
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 40 
task: majority, mean loss: 0.52729, accuracy: 0.81375, task: max, mean loss: 0.76613, accuracy: 0.72125, task: top, mean loss: 0.63262, accuracy: 0.79250, task: multi, mean loss: 0.40704, multilabel_accuracy: 0.07125, avg. loss over tasks: 0.58327, lr: 0.00075025
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 40 
task: majority, mean loss: 1.75347, accuracy: 0.52000, task: max, mean loss: 1.49506, accuracy: 0.55500, task: top, mean loss: 1.56473, accuracy: 0.54300, task: multi, mean loss: 0.51426, multilabel_accuracy: 0.03100, avg. loss over tasks: 1.33188
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 41 
task: majority, mean loss: 0.46044, accuracy: 0.84500, task: max, mean loss: 0.73007, accuracy: 0.73625, task: top, mean loss: 0.55880, accuracy: 0.80625, task: multi, mean loss: 0.39255, multilabel_accuracy: 0.09000, avg. loss over tasks: 0.53547, lr: 0.0007350010456115524
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 41 
task: majority, mean loss: 1.39323, accuracy: 0.56300, task: max, mean loss: 1.47150, accuracy: 0.54900, task: top, mean loss: 1.52220, accuracy: 0.55000, task: multi, mean loss: 0.49237, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.21982
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 42 
task: majority, mean loss: 0.50668, accuracy: 0.82625, task: max, mean loss: 0.75790, accuracy: 0.73000, task: top, mean loss: 0.57067, accuracy: 0.78875, task: multi, mean loss: 0.39505, multilabel_accuracy: 0.09750, avg. loss over tasks: 0.55758, lr: 0.0007194663878211441
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 42 
task: majority, mean loss: 2.18732, accuracy: 0.46100, task: max, mean loss: 2.23247, accuracy: 0.37000, task: top, mean loss: 1.72235, accuracy: 0.53400, task: multi, mean loss: 0.58986, multilabel_accuracy: 0.05300, avg. loss over tasks: 1.68300
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 43 
task: majority, mean loss: 0.54548, accuracy: 0.81375, task: max, mean loss: 0.75910, accuracy: 0.72125, task: top, mean loss: 0.56114, accuracy: 0.82750, task: multi, mean loss: 0.39607, multilabel_accuracy: 0.08500, avg. loss over tasks: 0.56545, lr: 0.0007036649532163622
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 43 
task: majority, mean loss: 1.06449, accuracy: 0.66100, task: max, mean loss: 1.42369, accuracy: 0.53200, task: top, mean loss: 1.03756, accuracy: 0.68100, task: multi, mean loss: 0.48177, multilabel_accuracy: 0.06200, avg. loss over tasks: 1.00188
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 44 
task: majority, mean loss: 0.49757, accuracy: 0.82375, task: max, mean loss: 0.68770, accuracy: 0.74375, task: top, mean loss: 0.47141, accuracy: 0.84375, task: multi, mean loss: 0.38383, multilabel_accuracy: 0.10500, avg. loss over tasks: 0.51013, lr: 0.0006876159934112482
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 44 
task: majority, mean loss: 1.40955, accuracy: 0.56700, task: max, mean loss: 1.37335, accuracy: 0.55100, task: top, mean loss: 1.37244, accuracy: 0.61300, task: multi, mean loss: 0.48811, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.16086
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 45 
task: majority, mean loss: 0.41670, accuracy: 0.85250, task: max, mean loss: 0.58887, accuracy: 0.78750, task: top, mean loss: 0.39790, accuracy: 0.87250, task: multi, mean loss: 0.36984, multilabel_accuracy: 0.10875, avg. loss over tasks: 0.44333, lr: 0.0006713390615911716
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 45 
task: majority, mean loss: 0.73970, accuracy: 0.75200, task: max, mean loss: 1.24561, accuracy: 0.60200, task: top, mean loss: 1.00433, accuracy: 0.70500, task: multi, mean loss: 0.41871, multilabel_accuracy: 0.08800, avg. loss over tasks: 0.85209
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 46 
task: majority, mean loss: 0.34400, accuracy: 0.88750, task: max, mean loss: 0.56909, accuracy: 0.80125, task: top, mean loss: 0.38138, accuracy: 0.87750, task: multi, mean loss: 0.36372, multilabel_accuracy: 0.09875, avg. loss over tasks: 0.41455, lr: 0.0006548539886902863
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 46 
task: majority, mean loss: 1.17073, accuracy: 0.61400, task: max, mean loss: 1.50506, accuracy: 0.56400, task: top, mean loss: 1.24186, accuracy: 0.62700, task: multi, mean loss: 0.46844, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.09652
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 47 
task: majority, mean loss: 0.39382, accuracy: 0.86000, task: max, mean loss: 0.54915, accuracy: 0.80375, task: top, mean loss: 0.37182, accuracy: 0.88125, task: multi, mean loss: 0.36470, multilabel_accuracy: 0.11125, avg. loss over tasks: 0.41987, lr: 0.0006381808592305911
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 47 
task: majority, mean loss: 0.92547, accuracy: 0.72000, task: max, mean loss: 1.41818, accuracy: 0.57200, task: top, mean loss: 1.07094, accuracy: 0.70500, task: multi, mean loss: 0.44756, multilabel_accuracy: 0.07900, avg. loss over tasks: 0.96554
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 48 
task: majority, mean loss: 0.37836, accuracy: 0.87500, task: max, mean loss: 0.48391, accuracy: 0.83000, task: top, mean loss: 0.39193, accuracy: 0.87250, task: multi, mean loss: 0.35912, multilabel_accuracy: 0.11375, avg. loss over tasks: 0.40333, lr: 0.000621339986852034
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 48 
task: majority, mean loss: 1.25160, accuracy: 0.61200, task: max, mean loss: 1.45686, accuracy: 0.56000, task: top, mean loss: 1.16823, accuracy: 0.66700, task: multi, mean loss: 0.46555, multilabel_accuracy: 0.07500, avg. loss over tasks: 1.08556
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 49 
task: majority, mean loss: 0.32226, accuracy: 0.88375, task: max, mean loss: 0.46864, accuracy: 0.83000, task: top, mean loss: 0.32519, accuracy: 0.88375, task: multi, mean loss: 0.35330, multilabel_accuracy: 0.13250, avg. loss over tasks: 0.36735, lr: 0.0006043518895634708
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 49 
task: majority, mean loss: 0.87211, accuracy: 0.74300, task: max, mean loss: 1.36111, accuracy: 0.60100, task: top, mean loss: 1.01796, accuracy: 0.72000, task: multi, mean loss: 0.43293, multilabel_accuracy: 0.09300, avg. loss over tasks: 0.92103
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 50 
task: majority, mean loss: 0.32686, accuracy: 0.88500, task: max, mean loss: 0.46130, accuracy: 0.83125, task: top, mean loss: 0.28932, accuracy: 0.90625, task: multi, mean loss: 0.34371, multilabel_accuracy: 0.13875, avg. loss over tasks: 0.35530, lr: 0.0005872372647446318
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 50 
task: majority, mean loss: 1.37086, accuracy: 0.58200, task: max, mean loss: 1.47265, accuracy: 0.58400, task: top, mean loss: 1.52558, accuracy: 0.57300, task: multi, mean loss: 0.46965, multilabel_accuracy: 0.07600, avg. loss over tasks: 1.20969
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 51 
task: majority, mean loss: 0.28692, accuracy: 0.90125, task: max, mean loss: 0.47861, accuracy: 0.83125, task: top, mean loss: 0.28557, accuracy: 0.90875, task: multi, mean loss: 0.34074, multilabel_accuracy: 0.15125, avg. loss over tasks: 0.34796, lr: 0.0005700169639295527
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 51 
task: majority, mean loss: 1.24174, accuracy: 0.62800, task: max, mean loss: 1.47379, accuracy: 0.57600, task: top, mean loss: 1.12814, accuracy: 0.70000, task: multi, mean loss: 0.47685, multilabel_accuracy: 0.07500, avg. loss over tasks: 1.08013
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 52 
task: majority, mean loss: 0.26664, accuracy: 0.91375, task: max, mean loss: 0.40681, accuracy: 0.85750, task: top, mean loss: 0.24882, accuracy: 0.92000, task: multi, mean loss: 0.33466, multilabel_accuracy: 0.14750, avg. loss over tasks: 0.31423, lr: 0.000552711967402193
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 52 
task: majority, mean loss: 1.45081, accuracy: 0.57900, task: max, mean loss: 1.84179, accuracy: 0.51200, task: top, mean loss: 1.44464, accuracy: 0.59500, task: multi, mean loss: 0.51122, multilabel_accuracy: 0.06100, avg. loss over tasks: 1.31211
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 53 
task: majority, mean loss: 0.22759, accuracy: 0.92125, task: max, mean loss: 0.39021, accuracy: 0.86125, task: top, mean loss: 0.24847, accuracy: 0.91625, task: multi, mean loss: 0.32758, multilabel_accuracy: 0.16000, avg. loss over tasks: 0.29846, lr: 0.0005353433586351906
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 53 
task: majority, mean loss: 1.76362, accuracy: 0.54100, task: max, mean loss: 2.07340, accuracy: 0.48800, task: top, mean loss: 1.47309, accuracy: 0.60700, task: multi, mean loss: 0.51470, multilabel_accuracy: 0.06600, avg. loss over tasks: 1.45621
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 54 
task: majority, mean loss: 0.19335, accuracy: 0.92500, task: max, mean loss: 0.31917, accuracy: 0.89250, task: top, mean loss: 0.20988, accuracy: 0.92875, task: multi, mean loss: 0.32470, multilabel_accuracy: 0.16000, avg. loss over tasks: 0.26177, lr: 0.0005179322986028993
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 54 
task: majority, mean loss: 0.83507, accuracy: 0.74000, task: max, mean loss: 1.37702, accuracy: 0.59800, task: top, mean loss: 1.02266, accuracy: 0.71700, task: multi, mean loss: 0.41797, multilabel_accuracy: 0.09600, avg. loss over tasks: 0.91318
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 55 
task: majority, mean loss: 0.21507, accuracy: 0.92625, task: max, mean loss: 0.31429, accuracy: 0.88375, task: top, mean loss: 0.22782, accuracy: 0.91375, task: multi, mean loss: 0.31997, multilabel_accuracy: 0.17500, avg. loss over tasks: 0.26928, lr: 0.0005005
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 55 
task: majority, mean loss: 0.67362, accuracy: 0.77700, task: max, mean loss: 1.37477, accuracy: 0.59400, task: top, mean loss: 1.07541, accuracy: 0.70800, task: multi, mean loss: 0.41086, multilabel_accuracy: 0.11200, avg. loss over tasks: 0.88367
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 56 
task: majority, mean loss: 0.18114, accuracy: 0.93750, task: max, mean loss: 0.26928, accuracy: 0.91250, task: top, mean loss: 0.18012, accuracy: 0.93750, task: multi, mean loss: 0.30835, multilabel_accuracy: 0.16500, avg. loss over tasks: 0.23472, lr: 0.00048306770139710094
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 56 
task: majority, mean loss: 0.79788, accuracy: 0.74400, task: max, mean loss: 1.42459, accuracy: 0.59800, task: top, mean loss: 1.06977, accuracy: 0.71200, task: multi, mean loss: 0.41386, multilabel_accuracy: 0.11200, avg. loss over tasks: 0.92652
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 57 
task: majority, mean loss: 0.16987, accuracy: 0.94000, task: max, mean loss: 0.26308, accuracy: 0.90875, task: top, mean loss: 0.16319, accuracy: 0.94750, task: multi, mean loss: 0.31102, multilabel_accuracy: 0.15750, avg. loss over tasks: 0.22679, lr: 0.0004656566413648095
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 57 
task: majority, mean loss: 0.83190, accuracy: 0.74400, task: max, mean loss: 1.54295, accuracy: 0.61000, task: top, mean loss: 1.18824, accuracy: 0.70400, task: multi, mean loss: 0.43318, multilabel_accuracy: 0.08100, avg. loss over tasks: 0.99907
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 58 
task: majority, mean loss: 0.14125, accuracy: 0.95250, task: max, mean loss: 0.20620, accuracy: 0.93125, task: top, mean loss: 0.11172, accuracy: 0.96750, task: multi, mean loss: 0.29392, multilabel_accuracy: 0.19875, avg. loss over tasks: 0.18827, lr: 0.0004482880325978072
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 58 
task: majority, mean loss: 0.79193, accuracy: 0.76700, task: max, mean loss: 1.37840, accuracy: 0.62400, task: top, mean loss: 1.02113, accuracy: 0.73500, task: multi, mean loss: 0.41694, multilabel_accuracy: 0.11000, avg. loss over tasks: 0.90210
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 59 
task: majority, mean loss: 0.13540, accuracy: 0.96000, task: max, mean loss: 0.22553, accuracy: 0.93750, task: top, mean loss: 0.10848, accuracy: 0.97250, task: multi, mean loss: 0.29986, multilabel_accuracy: 0.17750, avg. loss over tasks: 0.19232, lr: 0.0004309830360704473
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 59 
task: majority, mean loss: 0.91736, accuracy: 0.73800, task: max, mean loss: 1.39598, accuracy: 0.63100, task: top, mean loss: 1.11678, accuracy: 0.71800, task: multi, mean loss: 0.43652, multilabel_accuracy: 0.11200, avg. loss over tasks: 0.96666
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 60 
task: majority, mean loss: 0.11676, accuracy: 0.95500, task: max, mean loss: 0.18990, accuracy: 0.92875, task: top, mean loss: 0.10580, accuracy: 0.97500, task: multi, mean loss: 0.29287, multilabel_accuracy: 0.19625, avg. loss over tasks: 0.17633, lr: 0.00041376273525536834
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 60 
task: majority, mean loss: 0.66315, accuracy: 0.80000, task: max, mean loss: 1.45678, accuracy: 0.61100, task: top, mean loss: 0.99179, accuracy: 0.73100, task: multi, mean loss: 0.40130, multilabel_accuracy: 0.12800, avg. loss over tasks: 0.87826
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 61 
task: majority, mean loss: 0.10089, accuracy: 0.96875, task: max, mean loss: 0.16878, accuracy: 0.95250, task: top, mean loss: 0.07592, accuracy: 0.98625, task: multi, mean loss: 0.29080, multilabel_accuracy: 0.20875, avg. loss over tasks: 0.15910, lr: 0.00039664811043652916
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 61 
task: majority, mean loss: 0.87102, accuracy: 0.73100, task: max, mean loss: 1.55647, accuracy: 0.61200, task: top, mean loss: 1.07065, accuracy: 0.71700, task: multi, mean loss: 0.42645, multilabel_accuracy: 0.12200, avg. loss over tasks: 0.98115
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 62 
task: majority, mean loss: 0.17187, accuracy: 0.94250, task: max, mean loss: 0.18230, accuracy: 0.94625, task: top, mean loss: 0.12031, accuracy: 0.96375, task: multi, mean loss: 0.29720, multilabel_accuracy: 0.18625, avg. loss over tasks: 0.19292, lr: 0.00037966001314796604
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 62 
task: majority, mean loss: 0.82842, accuracy: 0.73300, task: max, mean loss: 1.41122, accuracy: 0.62900, task: top, mean loss: 1.14688, accuracy: 0.72000, task: multi, mean loss: 0.41929, multilabel_accuracy: 0.11100, avg. loss over tasks: 0.95145
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 63 
task: majority, mean loss: 0.11104, accuracy: 0.96750, task: max, mean loss: 0.17633, accuracy: 0.94375, task: top, mean loss: 0.07175, accuracy: 0.98000, task: multi, mean loss: 0.28364, multilabel_accuracy: 0.20375, avg. loss over tasks: 0.16069, lr: 0.00036281914076940884
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 63 
task: majority, mean loss: 0.65481, accuracy: 0.79600, task: max, mean loss: 1.49057, accuracy: 0.62500, task: top, mean loss: 0.98213, accuracy: 0.75600, task: multi, mean loss: 0.40010, multilabel_accuracy: 0.12800, avg. loss over tasks: 0.88190
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 64 
task: majority, mean loss: 0.07237, accuracy: 0.98250, task: max, mean loss: 0.15612, accuracy: 0.95500, task: top, mean loss: 0.08675, accuracy: 0.98000, task: multi, mean loss: 0.28085, multilabel_accuracy: 0.20625, avg. loss over tasks: 0.14902, lr: 0.0003461460113097137
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 64 
task: majority, mean loss: 0.65852, accuracy: 0.78800, task: max, mean loss: 1.46819, accuracy: 0.61200, task: top, mean loss: 0.99939, accuracy: 0.75100, task: multi, mean loss: 0.39315, multilabel_accuracy: 0.14000, avg. loss over tasks: 0.87982
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 65 
task: majority, mean loss: 0.08409, accuracy: 0.97500, task: max, mean loss: 0.12227, accuracy: 0.96500, task: top, mean loss: 0.07306, accuracy: 0.98125, task: multi, mean loss: 0.26710, multilabel_accuracy: 0.25625, avg. loss over tasks: 0.13663, lr: 0.00032966093840882863
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 65 
task: majority, mean loss: 0.66509, accuracy: 0.80300, task: max, mean loss: 1.51716, accuracy: 0.63500, task: top, mean loss: 0.98725, accuracy: 0.75500, task: multi, mean loss: 0.39664, multilabel_accuracy: 0.12700, avg. loss over tasks: 0.89153
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 66 
task: majority, mean loss: 0.06975, accuracy: 0.98125, task: max, mean loss: 0.12211, accuracy: 0.96875, task: top, mean loss: 0.06666, accuracy: 0.98125, task: multi, mean loss: 0.26664, multilabel_accuracy: 0.25000, avg. loss over tasks: 0.13129, lr: 0.00031338400658875205
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 66 
task: majority, mean loss: 0.59084, accuracy: 0.82300, task: max, mean loss: 1.45233, accuracy: 0.62900, task: top, mean loss: 0.97617, accuracy: 0.75500, task: multi, mean loss: 0.38619, multilabel_accuracy: 0.15500, avg. loss over tasks: 0.85138
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 67 
task: majority, mean loss: 0.09561, accuracy: 0.97250, task: max, mean loss: 0.12431, accuracy: 0.97000, task: top, mean loss: 0.06243, accuracy: 0.98500, task: multi, mean loss: 0.27724, multilabel_accuracy: 0.23625, avg. loss over tasks: 0.13990, lr: 0.00029733504678363786
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 67 
task: majority, mean loss: 0.64940, accuracy: 0.79900, task: max, mean loss: 1.50488, accuracy: 0.64100, task: top, mean loss: 1.01938, accuracy: 0.74700, task: multi, mean loss: 0.39463, multilabel_accuracy: 0.13700, avg. loss over tasks: 0.89208
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 68 
task: majority, mean loss: 0.06681, accuracy: 0.97875, task: max, mean loss: 0.08903, accuracy: 0.98000, task: top, mean loss: 0.06097, accuracy: 0.99000, task: multi, mean loss: 0.26912, multilabel_accuracy: 0.24875, avg. loss over tasks: 0.12148, lr: 0.00028153361217885594
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 68 
task: majority, mean loss: 0.61757, accuracy: 0.80600, task: max, mean loss: 1.49416, accuracy: 0.63700, task: top, mean loss: 0.99932, accuracy: 0.74600, task: multi, mean loss: 0.38737, multilabel_accuracy: 0.14900, avg. loss over tasks: 0.87461
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 69 
task: majority, mean loss: 0.07302, accuracy: 0.97375, task: max, mean loss: 0.10604, accuracy: 0.97500, task: top, mean loss: 0.05406, accuracy: 0.99000, task: multi, mean loss: 0.26298, multilabel_accuracy: 0.24750, avg. loss over tasks: 0.12403, lr: 0.0002659989543884477
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 69 
task: majority, mean loss: 0.61988, accuracy: 0.81100, task: max, mean loss: 1.57254, accuracy: 0.61800, task: top, mean loss: 1.10793, accuracy: 0.73200, task: multi, mean loss: 0.40183, multilabel_accuracy: 0.14400, avg. loss over tasks: 0.92555
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 70 
task: majority, mean loss: 0.07343, accuracy: 0.98000, task: max, mean loss: 0.09335, accuracy: 0.97750, task: top, mean loss: 0.05634, accuracy: 0.98875, task: multi, mean loss: 0.25262, multilabel_accuracy: 0.29125, avg. loss over tasks: 0.11893, lr: 0.0002507500000000001
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 70 
task: majority, mean loss: 0.61781, accuracy: 0.82200, task: max, mean loss: 1.54052, accuracy: 0.64400, task: top, mean loss: 1.03167, accuracy: 0.75300, task: multi, mean loss: 0.38835, multilabel_accuracy: 0.14400, avg. loss over tasks: 0.89459
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 71 
task: majority, mean loss: 0.06830, accuracy: 0.97875, task: max, mean loss: 0.10095, accuracy: 0.97500, task: top, mean loss: 0.04983, accuracy: 0.98750, task: multi, mean loss: 0.25945, multilabel_accuracy: 0.27875, avg. loss over tasks: 0.11963, lr: 0.0002358053275155142
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 71 
task: majority, mean loss: 0.57433, accuracy: 0.81000, task: max, mean loss: 1.54356, accuracy: 0.62800, task: top, mean loss: 0.98196, accuracy: 0.75200, task: multi, mean loss: 0.38134, multilabel_accuracy: 0.15300, avg. loss over tasks: 0.87030
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 72 
task: majority, mean loss: 0.04403, accuracy: 0.99000, task: max, mean loss: 0.07807, accuracy: 0.98250, task: top, mean loss: 0.03806, accuracy: 0.99250, task: multi, mean loss: 0.25582, multilabel_accuracy: 0.25750, avg. loss over tasks: 0.10400, lr: 0.00022118314471636204
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 72 
task: majority, mean loss: 0.60825, accuracy: 0.82700, task: max, mean loss: 1.63221, accuracy: 0.63000, task: top, mean loss: 1.00466, accuracy: 0.74300, task: multi, mean loss: 0.39508, multilabel_accuracy: 0.14500, avg. loss over tasks: 0.91005
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 73 
task: majority, mean loss: 0.08730, accuracy: 0.97375, task: max, mean loss: 0.10103, accuracy: 0.97000, task: top, mean loss: 0.07387, accuracy: 0.98500, task: multi, mean loss: 0.25887, multilabel_accuracy: 0.26125, avg. loss over tasks: 0.13026, lr: 0.00020690126647990973
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 73 
task: majority, mean loss: 1.31655, accuracy: 0.67000, task: max, mean loss: 1.92390, accuracy: 0.59200, task: top, mean loss: 1.27843, accuracy: 0.71000, task: multi, mean loss: 0.46741, multilabel_accuracy: 0.12000, avg. loss over tasks: 1.24657
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 74 
task: majority, mean loss: 0.05295, accuracy: 0.98750, task: max, mean loss: 0.08481, accuracy: 0.97750, task: top, mean loss: 0.05439, accuracy: 0.98625, task: multi, mean loss: 0.25074, multilabel_accuracy: 0.29375, avg. loss over tasks: 0.11072, lr: 0.00019297709307483367
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 74 
task: majority, mean loss: 0.61090, accuracy: 0.80700, task: max, mean loss: 1.66299, accuracy: 0.61600, task: top, mean loss: 1.05173, accuracy: 0.73800, task: multi, mean loss: 0.39185, multilabel_accuracy: 0.16000, avg. loss over tasks: 0.92937
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 75 
task: majority, mean loss: 0.04956, accuracy: 0.99125, task: max, mean loss: 0.08410, accuracy: 0.98125, task: top, mean loss: 0.03909, accuracy: 0.99000, task: multi, mean loss: 0.24855, multilabel_accuracy: 0.29375, avg. loss over tasks: 0.10532, lr: 0.0001794275889615736
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 75 
task: majority, mean loss: 0.59172, accuracy: 0.80800, task: max, mean loss: 1.49291, accuracy: 0.64700, task: top, mean loss: 0.98160, accuracy: 0.76200, task: multi, mean loss: 0.38056, multilabel_accuracy: 0.17300, avg. loss over tasks: 0.86170
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 76 
task: majority, mean loss: 0.04177, accuracy: 0.99000, task: max, mean loss: 0.06773, accuracy: 0.98500, task: top, mean loss: 0.02841, accuracy: 0.99750, task: multi, mean loss: 0.23811, multilabel_accuracy: 0.29000, avg. loss over tasks: 0.09401, lr: 0.0001662692621237503
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 76 
task: majority, mean loss: 0.63069, accuracy: 0.82100, task: max, mean loss: 1.56250, accuracy: 0.63000, task: top, mean loss: 1.03771, accuracy: 0.74300, task: multi, mean loss: 0.39240, multilabel_accuracy: 0.15500, avg. loss over tasks: 0.90582
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 77 
task: majority, mean loss: 0.03934, accuracy: 0.99000, task: max, mean loss: 0.05727, accuracy: 0.98750, task: top, mean loss: 0.03708, accuracy: 0.99000, task: multi, mean loss: 0.24221, multilabel_accuracy: 0.30000, avg. loss over tasks: 0.09397, lr: 0.00015351814395573083
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 77 
task: majority, mean loss: 0.64383, accuracy: 0.80600, task: max, mean loss: 1.54724, accuracy: 0.63700, task: top, mean loss: 1.01023, accuracy: 0.76000, task: multi, mean loss: 0.38269, multilabel_accuracy: 0.17000, avg. loss over tasks: 0.89600
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 78 
task: majority, mean loss: 0.04835, accuracy: 0.98750, task: max, mean loss: 0.04431, accuracy: 0.99500, task: top, mean loss: 0.03309, accuracy: 0.99250, task: multi, mean loss: 0.23888, multilabel_accuracy: 0.30750, avg. loss over tasks: 0.09116, lr: 0.00014118976973084385
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 78 
task: majority, mean loss: 0.55360, accuracy: 0.84400, task: max, mean loss: 1.59421, accuracy: 0.63300, task: top, mean loss: 0.99844, accuracy: 0.76700, task: multi, mean loss: 0.38207, multilabel_accuracy: 0.16400, avg. loss over tasks: 0.88208
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 79 
task: majority, mean loss: 0.04206, accuracy: 0.98875, task: max, mean loss: 0.04954, accuracy: 0.98625, task: top, mean loss: 0.03987, accuracy: 0.98875, task: multi, mean loss: 0.23851, multilabel_accuracy: 0.32125, avg. loss over tasks: 0.09250, lr: 0.0001292991596740417
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 79 
task: majority, mean loss: 0.67658, accuracy: 0.80800, task: max, mean loss: 1.68766, accuracy: 0.61100, task: top, mean loss: 1.06031, accuracy: 0.75800, task: multi, mean loss: 0.40378, multilabel_accuracy: 0.14800, avg. loss over tasks: 0.95708
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 80 
task: majority, mean loss: 0.04921, accuracy: 0.98625, task: max, mean loss: 0.04324, accuracy: 0.99375, task: top, mean loss: 0.03397, accuracy: 0.99500, task: multi, mean loss: 0.24132, multilabel_accuracy: 0.30375, avg. loss over tasks: 0.09194, lr: 0.00011786080066207054
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 80 
task: majority, mean loss: 0.54208, accuracy: 0.82600, task: max, mean loss: 1.59039, accuracy: 0.63300, task: top, mean loss: 1.00374, accuracy: 0.76200, task: multi, mean loss: 0.37923, multilabel_accuracy: 0.16700, avg. loss over tasks: 0.87886
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 81 
task: majority, mean loss: 0.03701, accuracy: 0.99125, task: max, mean loss: 0.04394, accuracy: 0.99000, task: top, mean loss: 0.05291, accuracy: 0.98750, task: multi, mean loss: 0.23273, multilabel_accuracy: 0.33375, avg. loss over tasks: 0.09165, lr: 0.00010688862857344241
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 81 
task: majority, mean loss: 0.54628, accuracy: 0.83100, task: max, mean loss: 1.53666, accuracy: 0.63600, task: top, mean loss: 0.97761, accuracy: 0.76100, task: multi, mean loss: 0.37652, multilabel_accuracy: 0.17500, avg. loss over tasks: 0.85927
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 82 
task: majority, mean loss: 0.03653, accuracy: 0.99000, task: max, mean loss: 0.03474, accuracy: 0.99500, task: top, mean loss: 0.02493, accuracy: 0.99750, task: multi, mean loss: 0.22956, multilabel_accuracy: 0.31375, avg. loss over tasks: 0.08144, lr: 9.63960113097138e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 82 
task: majority, mean loss: 0.56250, accuracy: 0.82600, task: max, mean loss: 1.59260, accuracy: 0.64000, task: top, mean loss: 0.97592, accuracy: 0.76600, task: multi, mean loss: 0.37723, multilabel_accuracy: 0.17200, avg. loss over tasks: 0.87706
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 83 
task: majority, mean loss: 0.05055, accuracy: 0.98500, task: max, mean loss: 0.04022, accuracy: 0.99125, task: top, mean loss: 0.03985, accuracy: 0.99125, task: multi, mean loss: 0.22499, multilabel_accuracy: 0.33250, avg. loss over tasks: 0.08891, lr: 8.639573250875671e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 83 
task: majority, mean loss: 0.54926, accuracy: 0.82600, task: max, mean loss: 1.59666, accuracy: 0.62600, task: top, mean loss: 1.01157, accuracy: 0.76000, task: multi, mean loss: 0.37914, multilabel_accuracy: 0.17600, avg. loss over tasks: 0.88416
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 84 
task: majority, mean loss: 0.03615, accuracy: 0.99500, task: max, mean loss: 0.03802, accuracy: 0.99375, task: top, mean loss: 0.03378, accuracy: 0.99250, task: multi, mean loss: 0.22338, multilabel_accuracy: 0.32375, avg. loss over tasks: 0.08283, lr: 7.689997596986524e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 84 
task: majority, mean loss: 0.51901, accuracy: 0.83100, task: max, mean loss: 1.59585, accuracy: 0.62900, task: top, mean loss: 0.97327, accuracy: 0.77100, task: multi, mean loss: 0.37653, multilabel_accuracy: 0.17700, avg. loss over tasks: 0.86616
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 85 
task: majority, mean loss: 0.03310, accuracy: 0.99375, task: max, mean loss: 0.03390, accuracy: 0.99750, task: top, mean loss: 0.03224, accuracy: 0.99000, task: multi, mean loss: 0.22978, multilabel_accuracy: 0.33500, avg. loss over tasks: 0.08225, lr: 6.792031080967287e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 85 
task: majority, mean loss: 0.54378, accuracy: 0.83700, task: max, mean loss: 1.63688, accuracy: 0.63200, task: top, mean loss: 0.98499, accuracy: 0.77100, task: multi, mean loss: 0.38223, multilabel_accuracy: 0.16800, avg. loss over tasks: 0.88697
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 86 
task: majority, mean loss: 0.02526, accuracy: 0.99625, task: max, mean loss: 0.04383, accuracy: 0.99000, task: top, mean loss: 0.03159, accuracy: 0.99000, task: multi, mean loss: 0.22890, multilabel_accuracy: 0.32250, avg. loss over tasks: 0.08239, lr: 5.946767736696597e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 86 
task: majority, mean loss: 0.52768, accuracy: 0.83800, task: max, mean loss: 1.65324, accuracy: 0.61300, task: top, mean loss: 0.97195, accuracy: 0.76500, task: multi, mean loss: 0.38012, multilabel_accuracy: 0.17300, avg. loss over tasks: 0.88325
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 87 
task: majority, mean loss: 0.02766, accuracy: 0.99250, task: max, mean loss: 0.04981, accuracy: 0.98750, task: top, mean loss: 0.02514, accuracy: 0.99500, task: multi, mean loss: 0.22263, multilabel_accuracy: 0.34250, avg. loss over tasks: 0.08131, lr: 5.155237387356607e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 87 
task: majority, mean loss: 0.53334, accuracy: 0.83300, task: max, mean loss: 1.57896, accuracy: 0.62900, task: top, mean loss: 0.96355, accuracy: 0.76900, task: multi, mean loss: 0.37529, multilabel_accuracy: 0.16300, avg. loss over tasks: 0.86279
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 88 
task: majority, mean loss: 0.03741, accuracy: 0.99250, task: max, mean loss: 0.02889, accuracy: 0.99500, task: top, mean loss: 0.02193, accuracy: 0.99500, task: multi, mean loss: 0.21902, multilabel_accuracy: 0.34750, avg. loss over tasks: 0.07681, lr: 4.418404390752081e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 88 
task: majority, mean loss: 0.53673, accuracy: 0.82900, task: max, mean loss: 1.57923, accuracy: 0.63500, task: top, mean loss: 0.97275, accuracy: 0.76500, task: multi, mean loss: 0.37465, multilabel_accuracy: 0.17900, avg. loss over tasks: 0.86584
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 89 
task: majority, mean loss: 0.02708, accuracy: 0.99625, task: max, mean loss: 0.03681, accuracy: 0.99375, task: top, mean loss: 0.02028, accuracy: 0.99750, task: multi, mean loss: 0.22216, multilabel_accuracy: 0.36125, avg. loss over tasks: 0.07658, lr: 3.7371664643889627e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 89 
task: majority, mean loss: 0.52328, accuracy: 0.83600, task: max, mean loss: 1.56138, accuracy: 0.63200, task: top, mean loss: 0.99151, accuracy: 0.76600, task: multi, mean loss: 0.37349, multilabel_accuracy: 0.16600, avg. loss over tasks: 0.86241
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 90 
task: majority, mean loss: 0.03217, accuracy: 0.99375, task: max, mean loss: 0.03626, accuracy: 0.99500, task: top, mean loss: 0.02220, accuracy: 0.99750, task: multi, mean loss: 0.22209, multilabel_accuracy: 0.34750, avg. loss over tasks: 0.07818, lr: 3.11235359174388e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 90 
task: majority, mean loss: 0.52818, accuracy: 0.83900, task: max, mean loss: 1.57800, accuracy: 0.63600, task: top, mean loss: 0.97634, accuracy: 0.76800, task: multi, mean loss: 0.37257, multilabel_accuracy: 0.18700, avg. loss over tasks: 0.86377
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 91 
task: majority, mean loss: 0.02539, accuracy: 0.99625, task: max, mean loss: 0.03139, accuracy: 0.99500, task: top, mean loss: 0.02756, accuracy: 0.99250, task: multi, mean loss: 0.22028, multilabel_accuracy: 0.34500, avg. loss over tasks: 0.07616, lr: 2.544727011057081e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 91 
task: majority, mean loss: 0.52650, accuracy: 0.84500, task: max, mean loss: 1.57596, accuracy: 0.63400, task: top, mean loss: 0.97619, accuracy: 0.77000, task: multi, mean loss: 0.37294, multilabel_accuracy: 0.18600, avg. loss over tasks: 0.86290
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 92 
task: majority, mean loss: 0.03028, accuracy: 0.99625, task: max, mean loss: 0.04210, accuracy: 0.99000, task: top, mean loss: 0.01866, accuracy: 0.99750, task: multi, mean loss: 0.21780, multilabel_accuracy: 0.34625, avg. loss over tasks: 0.07721, lr: 2.0349782878809714e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 92 
task: majority, mean loss: 0.53079, accuracy: 0.83700, task: max, mean loss: 1.59870, accuracy: 0.63300, task: top, mean loss: 0.97033, accuracy: 0.76800, task: multi, mean loss: 0.37245, multilabel_accuracy: 0.18300, avg. loss over tasks: 0.86807
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 93 
task: majority, mean loss: 0.01973, accuracy: 0.99875, task: max, mean loss: 0.03624, accuracy: 0.99250, task: top, mean loss: 0.02206, accuracy: 0.99625, task: multi, mean loss: 0.21967, multilabel_accuracy: 0.36750, avg. loss over tasks: 0.07442, lr: 1.583728472513976e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 93 
task: majority, mean loss: 0.51703, accuracy: 0.84200, task: max, mean loss: 1.55647, accuracy: 0.63600, task: top, mean loss: 0.98289, accuracy: 0.76400, task: multi, mean loss: 0.37041, multilabel_accuracy: 0.18100, avg. loss over tasks: 0.85670
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 94 
task: majority, mean loss: 0.02824, accuracy: 0.99500, task: max, mean loss: 0.02901, accuracy: 0.99375, task: top, mean loss: 0.01499, accuracy: 0.99875, task: multi, mean loss: 0.21748, multilabel_accuracy: 0.35000, avg. loss over tasks: 0.07243, lr: 1.191527343346406e-05
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 94 
task: majority, mean loss: 0.52403, accuracy: 0.83800, task: max, mean loss: 1.58611, accuracy: 0.63700, task: top, mean loss: 0.97690, accuracy: 0.76900, task: multi, mean loss: 0.37249, multilabel_accuracy: 0.17700, avg. loss over tasks: 0.86488
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 95 
task: majority, mean loss: 0.03160, accuracy: 0.99000, task: max, mean loss: 0.03398, accuracy: 0.99375, task: top, mean loss: 0.01919, accuracy: 0.99750, task: multi, mean loss: 0.21961, multilabel_accuracy: 0.36125, avg. loss over tasks: 0.07609, lr: 8.588527370402095e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 95 
task: majority, mean loss: 0.51650, accuracy: 0.84400, task: max, mean loss: 1.56230, accuracy: 0.63800, task: top, mean loss: 0.98970, accuracy: 0.76500, task: multi, mean loss: 0.37335, multilabel_accuracy: 0.17900, avg. loss over tasks: 0.86046
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 96 
task: majority, mean loss: 0.02290, accuracy: 0.99750, task: max, mean loss: 0.02745, accuracy: 0.99750, task: top, mean loss: 0.02340, accuracy: 0.99625, task: multi, mean loss: 0.22058, multilabel_accuracy: 0.37875, avg. loss over tasks: 0.07358, lr: 5.86109966358566e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 96 
task: majority, mean loss: 0.52010, accuracy: 0.84500, task: max, mean loss: 1.57979, accuracy: 0.63500, task: top, mean loss: 0.97896, accuracy: 0.76400, task: multi, mean loss: 0.37312, multilabel_accuracy: 0.17600, avg. loss over tasks: 0.86299
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 97 
task: majority, mean loss: 0.02406, accuracy: 0.99625, task: max, mean loss: 0.02979, accuracy: 0.99375, task: top, mean loss: 0.02164, accuracy: 0.99500, task: multi, mean loss: 0.21835, multilabel_accuracy: 0.35125, avg. loss over tasks: 0.07346, lr: 3.7363132635474912e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 97 
task: majority, mean loss: 0.52359, accuracy: 0.84500, task: max, mean loss: 1.59775, accuracy: 0.63400, task: top, mean loss: 0.97305, accuracy: 0.76800, task: multi, mean loss: 0.37377, multilabel_accuracy: 0.17400, avg. loss over tasks: 0.86704
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 98 
task: majority, mean loss: 0.02733, accuracy: 0.99750, task: max, mean loss: 0.03270, accuracy: 0.99750, task: top, mean loss: 0.02169, accuracy: 0.99625, task: multi, mean loss: 0.21695, multilabel_accuracy: 0.36500, avg. loss over tasks: 0.07467, lr: 2.2167568952178134e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 98 
task: majority, mean loss: 0.52098, accuracy: 0.84400, task: max, mean loss: 1.58578, accuracy: 0.63500, task: top, mean loss: 0.97200, accuracy: 0.76400, task: multi, mean loss: 0.37275, multilabel_accuracy: 0.17100, avg. loss over tasks: 0.86288
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 99 
task: majority, mean loss: 0.02827, accuracy: 0.99250, task: max, mean loss: 0.02499, accuracy: 0.99750, task: top, mean loss: 0.03136, accuracy: 0.98875, task: multi, mean loss: 0.22102, multilabel_accuracy: 0.35500, avg. loss over tasks: 0.07641, lr: 1.3042819039616668e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 99 
task: majority, mean loss: 0.51675, accuracy: 0.84500, task: max, mean loss: 1.57367, accuracy: 0.63700, task: top, mean loss: 0.98330, accuracy: 0.76400, task: multi, mean loss: 0.37315, multilabel_accuracy: 0.18300, avg. loss over tasks: 0.86172
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Train Epoch: 100 
task: majority, mean loss: 0.02317, accuracy: 0.99750, task: max, mean loss: 0.02784, accuracy: 0.99625, task: top, mean loss: 0.02010, accuracy: 0.99750, task: multi, mean loss: 0.22180, multilabel_accuracy: 0.35375, avg. loss over tasks: 0.07323, lr: 1e-06
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

Test Epoch: 100 
task: majority, mean loss: 0.51768, accuracy: 0.84200, task: max, mean loss: 1.58447, accuracy: 0.63600, task: top, mean loss: 0.97990, accuracy: 0.76400, task: multi, mean loss: 0.37378, multilabel_accuracy: 0.17900, avg. loss over tasks: 0.86396
Diversity Loss - Mean: 0.00000, Variance: 0.00000
Semantic Loss - Mean: 0.00000, Variance: 0.00000

