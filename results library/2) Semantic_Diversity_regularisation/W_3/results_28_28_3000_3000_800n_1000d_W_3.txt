Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.35807, accuracy: 0.12100, task: max, mean loss: 2.21475, accuracy: 0.24300, task: top, mean loss: 2.35712, accuracy: 0.10100, task: multi, mean loss: 0.69853, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.90712, lr: 0.0001
Diversity Loss - Mean: -0.11218, Variance: 0.07652
Semantic Loss - Mean: 1.99347, Variance: 0.00715

Test Epoch: 1 
task: majority, mean loss: 2.31370, accuracy: 0.10600, task: max, mean loss: 1.91550, accuracy: 0.27400, task: top, mean loss: 2.31473, accuracy: 0.10300, task: multi, mean loss: 0.63058, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79363
Diversity Loss - Mean: -0.14171, Variance: 0.09342
Semantic Loss - Mean: 1.90806, Variance: 0.00435

Train Epoch: 2 
task: majority, mean loss: 2.32552, accuracy: 0.11600, task: max, mean loss: 1.86479, accuracy: 0.26800, task: top, mean loss: 2.32600, accuracy: 0.09700, task: multi, mean loss: 0.61425, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78264, lr: 0.0002
Diversity Loss - Mean: -0.14196, Variance: 0.09514
Semantic Loss - Mean: 1.83810, Variance: 0.00435

Test Epoch: 2 
task: majority, mean loss: 2.31952, accuracy: 0.10000, task: max, mean loss: 1.89842, accuracy: 0.21300, task: top, mean loss: 2.31881, accuracy: 0.09900, task: multi, mean loss: 0.60213, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78472
Diversity Loss - Mean: -0.14220, Variance: 0.11997
Semantic Loss - Mean: 1.79469, Variance: 0.00231

Train Epoch: 3 
task: majority, mean loss: 2.33471, accuracy: 0.09500, task: max, mean loss: 1.85562, accuracy: 0.24500, task: top, mean loss: 2.33498, accuracy: 0.09600, task: multi, mean loss: 0.60641, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78293, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14187, Variance: 0.11562
Semantic Loss - Mean: 1.77724, Variance: 0.00299

Test Epoch: 3 
task: majority, mean loss: 2.33382, accuracy: 0.09300, task: max, mean loss: 1.86499, accuracy: 0.27400, task: top, mean loss: 2.31273, accuracy: 0.09700, task: multi, mean loss: 0.60188, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77836
Diversity Loss - Mean: -0.14133, Variance: 0.13778
Semantic Loss - Mean: 1.77419, Variance: 0.00155

Train Epoch: 4 
task: majority, mean loss: 2.34225, accuracy: 0.09200, task: max, mean loss: 1.84587, accuracy: 0.24900, task: top, mean loss: 2.32359, accuracy: 0.11900, task: multi, mean loss: 0.60699, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77967, lr: 0.0004
Diversity Loss - Mean: -0.14176, Variance: 0.12892
Semantic Loss - Mean: 1.76974, Variance: 0.00229

Test Epoch: 4 
task: majority, mean loss: 2.32946, accuracy: 0.10000, task: max, mean loss: 1.86273, accuracy: 0.27600, task: top, mean loss: 2.33597, accuracy: 0.10000, task: multi, mean loss: 0.60373, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78297
Diversity Loss - Mean: -0.14177, Variance: 0.14514
Semantic Loss - Mean: 1.77609, Variance: 0.00117

Train Epoch: 5 
task: majority, mean loss: 2.33150, accuracy: 0.10300, task: max, mean loss: 1.83624, accuracy: 0.24900, task: top, mean loss: 2.33132, accuracy: 0.08600, task: multi, mean loss: 0.60566, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77618, lr: 0.0005
Diversity Loss - Mean: -0.14204, Variance: 0.13605
Semantic Loss - Mean: 1.76833, Variance: 0.00186

Test Epoch: 5 
task: majority, mean loss: 2.31926, accuracy: 0.10200, task: max, mean loss: 1.85899, accuracy: 0.27400, task: top, mean loss: 2.31603, accuracy: 0.10700, task: multi, mean loss: 0.60214, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77410
Diversity Loss - Mean: -0.14175, Variance: 0.14972
Semantic Loss - Mean: 1.77230, Variance: 0.00094

Train Epoch: 6 
task: majority, mean loss: 2.32718, accuracy: 0.10800, task: max, mean loss: 1.84544, accuracy: 0.24100, task: top, mean loss: 2.33070, accuracy: 0.09700, task: multi, mean loss: 0.60640, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77743, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.14202, Variance: 0.14074
Semantic Loss - Mean: 1.76896, Variance: 0.00157

Test Epoch: 6 
task: majority, mean loss: 2.33218, accuracy: 0.09000, task: max, mean loss: 1.86137, accuracy: 0.24800, task: top, mean loss: 2.32757, accuracy: 0.10000, task: multi, mean loss: 0.60197, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78077
Diversity Loss - Mean: -0.14174, Variance: 0.15027
Semantic Loss - Mean: 1.77235, Variance: 0.00079

Train Epoch: 7 
task: majority, mean loss: 2.32505, accuracy: 0.09400, task: max, mean loss: 1.85476, accuracy: 0.25100, task: top, mean loss: 2.32390, accuracy: 0.10000, task: multi, mean loss: 0.60682, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77763, lr: 0.0007
Diversity Loss - Mean: -0.14177, Variance: 0.14225
Semantic Loss - Mean: 1.76809, Variance: 0.00137

Test Epoch: 7 
task: majority, mean loss: 2.32074, accuracy: 0.09900, task: max, mean loss: 1.91184, accuracy: 0.16500, task: top, mean loss: 2.34592, accuracy: 0.10200, task: multi, mean loss: 0.60445, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79573
Diversity Loss - Mean: -0.14011, Variance: 0.15109
Semantic Loss - Mean: 1.77940, Variance: 0.00068

Train Epoch: 8 
task: majority, mean loss: 2.31843, accuracy: 0.11200, task: max, mean loss: 1.84399, accuracy: 0.24000, task: top, mean loss: 2.32641, accuracy: 0.11100, task: multi, mean loss: 0.60644, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77382, lr: 0.0008
Diversity Loss - Mean: -0.14149, Variance: 0.14299
Semantic Loss - Mean: 1.76780, Variance: 0.00121

Test Epoch: 8 
task: majority, mean loss: 2.32181, accuracy: 0.10700, task: max, mean loss: 1.88033, accuracy: 0.21300, task: top, mean loss: 2.33126, accuracy: 0.10500, task: multi, mean loss: 0.60171, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78377
Diversity Loss - Mean: -0.13899, Variance: 0.15032
Semantic Loss - Mean: 1.77750, Variance: 0.00060

Train Epoch: 9 
task: majority, mean loss: 2.27197, accuracy: 0.14200, task: max, mean loss: 1.84954, accuracy: 0.24100, task: top, mean loss: 2.30324, accuracy: 0.12600, task: multi, mean loss: 0.60614, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75772, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.13987, Variance: 0.14399
Semantic Loss - Mean: 1.76749, Variance: 0.00109

Test Epoch: 9 
task: majority, mean loss: 2.61387, accuracy: 0.12100, task: max, mean loss: 1.86787, accuracy: 0.24100, task: top, mean loss: 2.46946, accuracy: 0.11200, task: multi, mean loss: 0.60324, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.88861
Diversity Loss - Mean: -0.13417, Variance: 0.14930
Semantic Loss - Mean: 1.77847, Variance: 0.00056

Train Epoch: 10 
task: majority, mean loss: 2.19870, accuracy: 0.15200, task: max, mean loss: 1.82771, accuracy: 0.23000, task: top, mean loss: 2.23453, accuracy: 0.14200, task: multi, mean loss: 0.59590, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71421, lr: 0.001
Diversity Loss - Mean: -0.13812, Variance: 0.14410
Semantic Loss - Mean: 1.75039, Variance: 0.00105

Test Epoch: 10 
task: majority, mean loss: 2.21825, accuracy: 0.16500, task: max, mean loss: 1.85829, accuracy: 0.27400, task: top, mean loss: 2.26776, accuracy: 0.15600, task: multi, mean loss: 0.58778, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73302
Diversity Loss - Mean: -0.13865, Variance: 0.14815
Semantic Loss - Mean: 1.75660, Variance: 0.00065

Train Epoch: 11 
task: majority, mean loss: 2.15654, accuracy: 0.17700, task: max, mean loss: 1.82353, accuracy: 0.25300, task: top, mean loss: 2.22359, accuracy: 0.16900, task: multi, mean loss: 0.58806, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.69793, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.13757, Variance: 0.14412
Semantic Loss - Mean: 1.71498, Variance: 0.00109

Test Epoch: 11 
task: majority, mean loss: 2.39249, accuracy: 0.13000, task: max, mean loss: 1.86105, accuracy: 0.28100, task: top, mean loss: 2.35452, accuracy: 0.10600, task: multi, mean loss: 0.61168, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.80493
Diversity Loss - Mean: -0.14041, Variance: 0.14807
Semantic Loss - Mean: 1.79153, Variance: 0.00067

Train Epoch: 12 
task: majority, mean loss: 2.15560, accuracy: 0.17900, task: max, mean loss: 1.78821, accuracy: 0.28100, task: top, mean loss: 2.20599, accuracy: 0.14600, task: multi, mean loss: 0.58793, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68443, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.13736, Variance: 0.14406
Semantic Loss - Mean: 1.69728, Variance: 0.00107

Test Epoch: 12 
task: majority, mean loss: 2.37034, accuracy: 0.11100, task: max, mean loss: 1.91446, accuracy: 0.21300, task: top, mean loss: 2.35172, accuracy: 0.10100, task: multi, mean loss: 0.60628, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.81070
Diversity Loss - Mean: -0.13173, Variance: 0.14806
Semantic Loss - Mean: 1.82866, Variance: 0.00081

Train Epoch: 13 
task: majority, mean loss: 2.27905, accuracy: 0.14400, task: max, mean loss: 1.81765, accuracy: 0.25900, task: top, mean loss: 2.26217, accuracy: 0.15300, task: multi, mean loss: 0.59785, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73918, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.13653, Variance: 0.14379
Semantic Loss - Mean: 1.74093, Variance: 0.00102

Test Epoch: 13 
task: majority, mean loss: 2.32230, accuracy: 0.11000, task: max, mean loss: 1.88831, accuracy: 0.21300, task: top, mean loss: 2.32508, accuracy: 0.11500, task: multi, mean loss: 0.60294, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78466
Diversity Loss - Mean: -0.14221, Variance: 0.14814
Semantic Loss - Mean: 1.77553, Variance: 0.00075

Train Epoch: 14 
task: majority, mean loss: 2.20330, accuracy: 0.15400, task: max, mean loss: 1.80701, accuracy: 0.25000, task: top, mean loss: 2.24182, accuracy: 0.13100, task: multi, mean loss: 0.59366, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71145, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.13803, Variance: 0.14331
Semantic Loss - Mean: 1.71102, Variance: 0.00097

Test Epoch: 14 
task: majority, mean loss: 2.15591, accuracy: 0.17600, task: max, mean loss: 1.81375, accuracy: 0.24300, task: top, mean loss: 2.25968, accuracy: 0.15500, task: multi, mean loss: 0.57588, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70131
Diversity Loss - Mean: -0.14202, Variance: 0.14819
Semantic Loss - Mean: 1.70170, Variance: 0.00071

Train Epoch: 15 
task: majority, mean loss: 2.17180, accuracy: 0.16600, task: max, mean loss: 1.77096, accuracy: 0.28400, task: top, mean loss: 2.19025, accuracy: 0.15500, task: multi, mean loss: 0.58354, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67914, lr: 0.000992411472629598
Diversity Loss - Mean: -0.13880, Variance: 0.14314
Semantic Loss - Mean: 1.68325, Variance: 0.00094

Test Epoch: 15 
task: majority, mean loss: 2.48314, accuracy: 0.09500, task: max, mean loss: 1.99058, accuracy: 0.27400, task: top, mean loss: 2.45553, accuracy: 0.09900, task: multi, mean loss: 0.63716, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.89160
Diversity Loss - Mean: -0.14157, Variance: 0.14868
Semantic Loss - Mean: 1.85641, Variance: 0.00067

Train Epoch: 16 
task: majority, mean loss: 2.10792, accuracy: 0.20100, task: max, mean loss: 1.76482, accuracy: 0.27400, task: top, mean loss: 2.16701, accuracy: 0.17700, task: multi, mean loss: 0.57794, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.65442, lr: 0.000989084726566536
Diversity Loss - Mean: -0.13853, Variance: 0.14262
Semantic Loss - Mean: 1.66308, Variance: 0.00091

Test Epoch: 16 
task: majority, mean loss: 2.36983, accuracy: 0.09900, task: max, mean loss: 1.95319, accuracy: 0.27600, task: top, mean loss: 2.35698, accuracy: 0.10100, task: multi, mean loss: 0.62565, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.82641
Diversity Loss - Mean: -0.14238, Variance: 0.14890
Semantic Loss - Mean: 1.79454, Variance: 0.00066

Train Epoch: 17 
task: majority, mean loss: 2.10251, accuracy: 0.18900, task: max, mean loss: 1.77023, accuracy: 0.27000, task: top, mean loss: 2.14482, accuracy: 0.16700, task: multi, mean loss: 0.57817, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.64893, lr: 0.00098516271527486
Diversity Loss - Mean: -0.13738, Variance: 0.14217
Semantic Loss - Mean: 1.66441, Variance: 0.00090

Test Epoch: 17 
task: majority, mean loss: 2.54011, accuracy: 0.11500, task: max, mean loss: 1.99284, accuracy: 0.27300, task: top, mean loss: 2.47891, accuracy: 0.11500, task: multi, mean loss: 0.64197, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.91346
Diversity Loss - Mean: -0.14191, Variance: 0.14893
Semantic Loss - Mean: 1.85435, Variance: 0.00067

Train Epoch: 18 
task: majority, mean loss: 2.04165, accuracy: 0.21600, task: max, mean loss: 1.74777, accuracy: 0.27600, task: top, mean loss: 2.13190, accuracy: 0.18200, task: multi, mean loss: 0.57304, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.62359, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.13893, Variance: 0.14165
Semantic Loss - Mean: 1.63730, Variance: 0.00089

Test Epoch: 18 
task: majority, mean loss: 2.15514, accuracy: 0.18600, task: max, mean loss: 1.79892, accuracy: 0.29900, task: top, mean loss: 2.26419, accuracy: 0.15700, task: multi, mean loss: 0.56807, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.69658
Diversity Loss - Mean: -0.14206, Variance: 0.14856
Semantic Loss - Mean: 1.70697, Variance: 0.00064

Train Epoch: 19 
task: majority, mean loss: 2.05008, accuracy: 0.20400, task: max, mean loss: 1.74822, accuracy: 0.28600, task: top, mean loss: 2.10133, accuracy: 0.19300, task: multi, mean loss: 0.57247, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.61802, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.13956, Variance: 0.14124
Semantic Loss - Mean: 1.63419, Variance: 0.00088

Test Epoch: 19 
task: majority, mean loss: 2.23967, accuracy: 0.14900, task: max, mean loss: 1.80263, accuracy: 0.26500, task: top, mean loss: 2.27735, accuracy: 0.12900, task: multi, mean loss: 0.57972, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.72484
Diversity Loss - Mean: -0.14223, Variance: 0.14846
Semantic Loss - Mean: 1.73572, Variance: 0.00062

Train Epoch: 20 
task: majority, mean loss: 2.12447, accuracy: 0.19000, task: max, mean loss: 1.77050, accuracy: 0.28100, task: top, mean loss: 2.13085, accuracy: 0.18400, task: multi, mean loss: 0.58194, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.65194, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.13900, Variance: 0.14075
Semantic Loss - Mean: 1.66526, Variance: 0.00087

Test Epoch: 20 
task: majority, mean loss: 2.92873, accuracy: 0.08900, task: max, mean loss: 1.96441, accuracy: 0.14100, task: top, mean loss: 2.70107, accuracy: 0.10000, task: multi, mean loss: 0.63782, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.05801
Diversity Loss - Mean: -0.14188, Variance: 0.15217
Semantic Loss - Mean: 2.08078, Variance: 0.00065

Train Epoch: 21 
task: majority, mean loss: 2.05782, accuracy: 0.21100, task: max, mean loss: 1.75622, accuracy: 0.30200, task: top, mean loss: 2.12417, accuracy: 0.16000, task: multi, mean loss: 0.57336, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.62789, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.13857, Variance: 0.14011
Semantic Loss - Mean: 1.64506, Variance: 0.00086

Test Epoch: 21 
task: majority, mean loss: 2.27557, accuracy: 0.12100, task: max, mean loss: 1.88070, accuracy: 0.28300, task: top, mean loss: 2.27606, accuracy: 0.12500, task: multi, mean loss: 0.60209, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75860
Diversity Loss - Mean: -0.14244, Variance: 0.15141
Semantic Loss - Mean: 1.74849, Variance: 0.00064

Train Epoch: 22 
task: majority, mean loss: 2.05252, accuracy: 0.18800, task: max, mean loss: 1.73197, accuracy: 0.29500, task: top, mean loss: 2.10886, accuracy: 0.20400, task: multi, mean loss: 0.57235, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.61642, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.13880, Variance: 0.13949
Semantic Loss - Mean: 1.63673, Variance: 0.00085

Test Epoch: 22 
task: majority, mean loss: 2.34811, accuracy: 0.13800, task: max, mean loss: 1.79117, accuracy: 0.29900, task: top, mean loss: 2.21447, accuracy: 0.18100, task: multi, mean loss: 0.57952, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.73332
Diversity Loss - Mean: -0.14141, Variance: 0.15109
Semantic Loss - Mean: 1.75576, Variance: 0.00062

Train Epoch: 23 
task: majority, mean loss: 2.05763, accuracy: 0.20500, task: max, mean loss: 1.73576, accuracy: 0.29600, task: top, mean loss: 2.08382, accuracy: 0.19300, task: multi, mean loss: 0.57128, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.61212, lr: 0.000949447626126434
Diversity Loss - Mean: -0.13864, Variance: 0.13878
Semantic Loss - Mean: 1.62729, Variance: 0.00084

Test Epoch: 23 
task: majority, mean loss: 2.91857, accuracy: 0.10500, task: max, mean loss: 2.10317, accuracy: 0.27400, task: top, mean loss: 2.72780, accuracy: 0.10200, task: multi, mean loss: 0.68733, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.10922
Diversity Loss - Mean: -0.14248, Variance: 0.15102
Semantic Loss - Mean: 2.00181, Variance: 0.00060

Train Epoch: 24 
task: majority, mean loss: 2.04386, accuracy: 0.21500, task: max, mean loss: 1.74166, accuracy: 0.30400, task: top, mean loss: 2.07339, accuracy: 0.18200, task: multi, mean loss: 0.57447, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.60834, lr: 0.000941532322633034
Diversity Loss - Mean: -0.13994, Variance: 0.13826
Semantic Loss - Mean: 1.62174, Variance: 0.00083

Test Epoch: 24 
task: majority, mean loss: 2.11379, accuracy: 0.19900, task: max, mean loss: 1.77049, accuracy: 0.30600, task: top, mean loss: 2.24980, accuracy: 0.15500, task: multi, mean loss: 0.56604, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67503
Diversity Loss - Mean: -0.14242, Variance: 0.15015
Semantic Loss - Mean: 1.67116, Variance: 0.00058

Train Epoch: 25 
task: majority, mean loss: 2.01772, accuracy: 0.21800, task: max, mean loss: 1.71817, accuracy: 0.30000, task: top, mean loss: 2.03310, accuracy: 0.19500, task: multi, mean loss: 0.57093, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.58498, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.13984, Variance: 0.13773
Semantic Loss - Mean: 1.60798, Variance: 0.00083

Test Epoch: 25 
task: majority, mean loss: 2.24475, accuracy: 0.17500, task: max, mean loss: 1.82351, accuracy: 0.29000, task: top, mean loss: 2.39463, accuracy: 0.15000, task: multi, mean loss: 0.59668, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.76489
Diversity Loss - Mean: -0.14222, Variance: 0.14944
Semantic Loss - Mean: 1.73407, Variance: 0.00058

Train Epoch: 26 
task: majority, mean loss: 1.96219, accuracy: 0.21900, task: max, mean loss: 1.71988, accuracy: 0.30800, task: top, mean loss: 2.03397, accuracy: 0.20100, task: multi, mean loss: 0.56886, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.57122, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.13937, Variance: 0.13714
Semantic Loss - Mean: 1.59318, Variance: 0.00083

Test Epoch: 26 
task: majority, mean loss: 2.75063, accuracy: 0.10600, task: max, mean loss: 1.87171, accuracy: 0.24200, task: top, mean loss: 2.38954, accuracy: 0.13600, task: multi, mean loss: 0.62575, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.90941
Diversity Loss - Mean: -0.14221, Variance: 0.14917
Semantic Loss - Mean: 1.89670, Variance: 0.00059

Train Epoch: 27 
task: majority, mean loss: 1.97344, accuracy: 0.24000, task: max, mean loss: 1.72317, accuracy: 0.34000, task: top, mean loss: 2.02963, accuracy: 0.20500, task: multi, mean loss: 0.56582, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.57302, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.13900, Variance: 0.13653
Semantic Loss - Mean: 1.59327, Variance: 0.00084

Test Epoch: 27 
task: majority, mean loss: 2.15979, accuracy: 0.19100, task: max, mean loss: 1.82162, accuracy: 0.28300, task: top, mean loss: 2.25144, accuracy: 0.17000, task: multi, mean loss: 0.57673, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.70240
Diversity Loss - Mean: -0.14223, Variance: 0.14828
Semantic Loss - Mean: 1.68715, Variance: 0.00058

Train Epoch: 28 
task: majority, mean loss: 1.97390, accuracy: 0.21900, task: max, mean loss: 1.68921, accuracy: 0.35200, task: top, mean loss: 2.00421, accuracy: 0.22000, task: multi, mean loss: 0.56771, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.55876, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.13990, Variance: 0.13595
Semantic Loss - Mean: 1.58424, Variance: 0.00084

Test Epoch: 28 
task: majority, mean loss: 2.43532, accuracy: 0.14000, task: max, mean loss: 1.84176, accuracy: 0.26000, task: top, mean loss: 2.35185, accuracy: 0.14500, task: multi, mean loss: 0.60136, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.80757
Diversity Loss - Mean: -0.14246, Variance: 0.14757
Semantic Loss - Mean: 1.77971, Variance: 0.00057

Train Epoch: 29 
task: majority, mean loss: 2.01107, accuracy: 0.23300, task: max, mean loss: 1.71385, accuracy: 0.32100, task: top, mean loss: 2.05378, accuracy: 0.21400, task: multi, mean loss: 0.57377, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.58812, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.13872, Variance: 0.13529
Semantic Loss - Mean: 1.60996, Variance: 0.00085

Test Epoch: 29 
task: majority, mean loss: 2.18821, accuracy: 0.13400, task: max, mean loss: 1.84772, accuracy: 0.23400, task: top, mean loss: 2.19468, accuracy: 0.16900, task: multi, mean loss: 0.57901, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70240
Diversity Loss - Mean: -0.14221, Variance: 0.14661
Semantic Loss - Mean: 1.72117, Variance: 0.00055

Train Epoch: 30 
task: majority, mean loss: 1.98006, accuracy: 0.22100, task: max, mean loss: 1.69754, accuracy: 0.34200, task: top, mean loss: 1.99664, accuracy: 0.21800, task: multi, mean loss: 0.56824, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.56062, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.13924, Variance: 0.13454
Semantic Loss - Mean: 1.58265, Variance: 0.00085

Test Epoch: 30 
task: majority, mean loss: 2.66623, accuracy: 0.10900, task: max, mean loss: 1.91305, accuracy: 0.21500, task: top, mean loss: 2.51951, accuracy: 0.11900, task: multi, mean loss: 0.62157, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.93009
Diversity Loss - Mean: -0.14239, Variance: 0.14642
Semantic Loss - Mean: 1.91046, Variance: 0.00056

Train Epoch: 31 
task: majority, mean loss: 1.96807, accuracy: 0.25200, task: max, mean loss: 1.68044, accuracy: 0.36500, task: top, mean loss: 2.02746, accuracy: 0.23100, task: multi, mean loss: 0.56856, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.56113, lr: 0.0008717008403259585
Diversity Loss - Mean: -0.13891, Variance: 0.13383
Semantic Loss - Mean: 1.58799, Variance: 0.00086

Test Epoch: 31 
task: majority, mean loss: 2.32762, accuracy: 0.13900, task: max, mean loss: 1.91321, accuracy: 0.27500, task: top, mean loss: 2.25325, accuracy: 0.17000, task: multi, mean loss: 0.59640, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77262
Diversity Loss - Mean: -0.14234, Variance: 0.14569
Semantic Loss - Mean: 1.72114, Variance: 0.00055

Train Epoch: 32 
task: majority, mean loss: 1.93773, accuracy: 0.25300, task: max, mean loss: 1.69191, accuracy: 0.36200, task: top, mean loss: 1.96132, accuracy: 0.23700, task: multi, mean loss: 0.56607, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.53926, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.13916, Variance: 0.13314
Semantic Loss - Mean: 1.56350, Variance: 0.00087

Test Epoch: 32 
task: majority, mean loss: 2.28089, accuracy: 0.16800, task: max, mean loss: 1.77330, accuracy: 0.30400, task: top, mean loss: 2.46235, accuracy: 0.14600, task: multi, mean loss: 0.57512, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77291
Diversity Loss - Mean: -0.14245, Variance: 0.14506
Semantic Loss - Mean: 1.75173, Variance: 0.00054

Train Epoch: 33 
task: majority, mean loss: 1.88299, accuracy: 0.26700, task: max, mean loss: 1.67020, accuracy: 0.36200, task: top, mean loss: 2.00151, accuracy: 0.22800, task: multi, mean loss: 0.56562, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.53008, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.13898, Variance: 0.13242
Semantic Loss - Mean: 1.56082, Variance: 0.00088

Test Epoch: 33 
task: majority, mean loss: 2.11996, accuracy: 0.24200, task: max, mean loss: 1.78555, accuracy: 0.30500, task: top, mean loss: 2.22495, accuracy: 0.20800, task: multi, mean loss: 0.56657, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.67426
Diversity Loss - Mean: -0.14222, Variance: 0.14420
Semantic Loss - Mean: 1.66828, Variance: 0.00053

Train Epoch: 34 
task: majority, mean loss: 1.85753, accuracy: 0.28700, task: max, mean loss: 1.63993, accuracy: 0.37500, task: top, mean loss: 1.92951, accuracy: 0.25100, task: multi, mean loss: 0.56053, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.49688, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.13921, Variance: 0.13179
Semantic Loss - Mean: 1.53054, Variance: 0.00089

Test Epoch: 34 
task: majority, mean loss: 2.13777, accuracy: 0.20800, task: max, mean loss: 1.77246, accuracy: 0.31800, task: top, mean loss: 2.24698, accuracy: 0.19400, task: multi, mean loss: 0.56326, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.68012
Diversity Loss - Mean: -0.14240, Variance: 0.14339
Semantic Loss - Mean: 1.68587, Variance: 0.00052

Train Epoch: 35 
task: majority, mean loss: 1.87178, accuracy: 0.27300, task: max, mean loss: 1.64365, accuracy: 0.38300, task: top, mean loss: 1.91984, accuracy: 0.27000, task: multi, mean loss: 0.56423, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.49987, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.13967, Variance: 0.13118
Semantic Loss - Mean: 1.52981, Variance: 0.00090

Test Epoch: 35 
task: majority, mean loss: 3.12116, accuracy: 0.09500, task: max, mean loss: 2.21242, accuracy: 0.26800, task: top, mean loss: 2.81221, accuracy: 0.10300, task: multi, mean loss: 0.66449, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.20257
Diversity Loss - Mean: -0.14254, Variance: 0.14326
Semantic Loss - Mean: 2.10816, Variance: 0.00052

Train Epoch: 36 
task: majority, mean loss: 1.91364, accuracy: 0.27300, task: max, mean loss: 1.65824, accuracy: 0.36500, task: top, mean loss: 1.94917, accuracy: 0.24500, task: multi, mean loss: 0.56515, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.52155, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.13911, Variance: 0.13057
Semantic Loss - Mean: 1.55248, Variance: 0.00091

Test Epoch: 36 
task: majority, mean loss: 2.11772, accuracy: 0.23500, task: max, mean loss: 1.76752, accuracy: 0.31300, task: top, mean loss: 2.18424, accuracy: 0.20300, task: multi, mean loss: 0.56565, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.65878
Diversity Loss - Mean: -0.14244, Variance: 0.14245
Semantic Loss - Mean: 1.66559, Variance: 0.00052

Train Epoch: 37 
task: majority, mean loss: 1.85999, accuracy: 0.29300, task: max, mean loss: 1.62336, accuracy: 0.39300, task: top, mean loss: 1.89558, accuracy: 0.26700, task: multi, mean loss: 0.56272, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.48541, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.13911, Variance: 0.12993
Semantic Loss - Mean: 1.52432, Variance: 0.00091

Test Epoch: 37 
task: majority, mean loss: 2.37220, accuracy: 0.14600, task: max, mean loss: 1.93783, accuracy: 0.23400, task: top, mean loss: 2.36179, accuracy: 0.17800, task: multi, mean loss: 0.60052, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.81809
Diversity Loss - Mean: -0.14254, Variance: 0.14173
Semantic Loss - Mean: 1.79106, Variance: 0.00052

Train Epoch: 38 
task: majority, mean loss: 1.83507, accuracy: 0.29800, task: max, mean loss: 1.62618, accuracy: 0.40800, task: top, mean loss: 1.87045, accuracy: 0.28000, task: multi, mean loss: 0.56043, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.47303, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.13893, Variance: 0.12932
Semantic Loss - Mean: 1.51176, Variance: 0.00093

Test Epoch: 38 
task: majority, mean loss: 2.17926, accuracy: 0.22800, task: max, mean loss: 1.78255, accuracy: 0.31300, task: top, mean loss: 2.21724, accuracy: 0.19200, task: multi, mean loss: 0.56519, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.68606
Diversity Loss - Mean: -0.14235, Variance: 0.14098
Semantic Loss - Mean: 1.67942, Variance: 0.00051

Train Epoch: 39 
task: majority, mean loss: 1.82885, accuracy: 0.32300, task: max, mean loss: 1.59248, accuracy: 0.41400, task: top, mean loss: 1.86921, accuracy: 0.27800, task: multi, mean loss: 0.55761, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.46204, lr: 0.000765194672484486
Diversity Loss - Mean: -0.13907, Variance: 0.12873
Semantic Loss - Mean: 1.50346, Variance: 0.00094

Test Epoch: 39 
task: majority, mean loss: 2.08415, accuracy: 0.23000, task: max, mean loss: 1.78721, accuracy: 0.30600, task: top, mean loss: 2.28349, accuracy: 0.19200, task: multi, mean loss: 0.56537, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.68005
Diversity Loss - Mean: -0.14222, Variance: 0.14027
Semantic Loss - Mean: 1.67944, Variance: 0.00051

Train Epoch: 40 
task: majority, mean loss: 1.82802, accuracy: 0.30400, task: max, mean loss: 1.60044, accuracy: 0.39200, task: top, mean loss: 1.87876, accuracy: 0.28000, task: multi, mean loss: 0.56097, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.46705, lr: 0.00075025
Diversity Loss - Mean: -0.13868, Variance: 0.12811
Semantic Loss - Mean: 1.50861, Variance: 0.00095

Test Epoch: 40 
task: majority, mean loss: 3.33718, accuracy: 0.09600, task: max, mean loss: 2.09921, accuracy: 0.19800, task: top, mean loss: 2.90522, accuracy: 0.11500, task: multi, mean loss: 0.66230, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.25098
Diversity Loss - Mean: -0.14246, Variance: 0.14074
Semantic Loss - Mean: 2.15639, Variance: 0.00054

Train Epoch: 41 
task: majority, mean loss: 1.84400, accuracy: 0.29100, task: max, mean loss: 1.59609, accuracy: 0.40800, task: top, mean loss: 1.86664, accuracy: 0.26800, task: multi, mean loss: 0.55914, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.46647, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.13918, Variance: 0.12750
Semantic Loss - Mean: 1.51309, Variance: 0.00097

Test Epoch: 41 
task: majority, mean loss: 2.16831, accuracy: 0.18200, task: max, mean loss: 1.93068, accuracy: 0.31100, task: top, mean loss: 2.25830, accuracy: 0.18100, task: multi, mean loss: 0.58322, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.73513
Diversity Loss - Mean: -0.14225, Variance: 0.14008
Semantic Loss - Mean: 1.70792, Variance: 0.00055

Train Epoch: 42 
task: majority, mean loss: 1.81586, accuracy: 0.30300, task: max, mean loss: 1.57138, accuracy: 0.41800, task: top, mean loss: 1.81330, accuracy: 0.29500, task: multi, mean loss: 0.55626, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.43920, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.13866, Variance: 0.12694
Semantic Loss - Mean: 1.48531, Variance: 0.00098

Test Epoch: 42 
task: majority, mean loss: 2.10367, accuracy: 0.21700, task: max, mean loss: 1.77874, accuracy: 0.31900, task: top, mean loss: 2.24620, accuracy: 0.19500, task: multi, mean loss: 0.56129, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67247
Diversity Loss - Mean: -0.14197, Variance: 0.13924
Semantic Loss - Mean: 1.68101, Variance: 0.00055

Train Epoch: 43 
task: majority, mean loss: 1.75774, accuracy: 0.33400, task: max, mean loss: 1.56125, accuracy: 0.41800, task: top, mean loss: 1.77387, accuracy: 0.30300, task: multi, mean loss: 0.55378, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.41166, lr: 0.0007036649532163622
Diversity Loss - Mean: -0.13859, Variance: 0.12638
Semantic Loss - Mean: 1.46515, Variance: 0.00099

Test Epoch: 43 
task: majority, mean loss: 2.10120, accuracy: 0.22100, task: max, mean loss: 1.86081, accuracy: 0.31500, task: top, mean loss: 2.27294, accuracy: 0.20900, task: multi, mean loss: 0.56818, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70078
Diversity Loss - Mean: -0.14235, Variance: 0.13851
Semantic Loss - Mean: 1.68038, Variance: 0.00056

Train Epoch: 44 
task: majority, mean loss: 1.84899, accuracy: 0.30300, task: max, mean loss: 1.61477, accuracy: 0.39800, task: top, mean loss: 1.87144, accuracy: 0.28200, task: multi, mean loss: 0.56203, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.47431, lr: 0.000687615993411248
Diversity Loss - Mean: -0.13761, Variance: 0.12582
Semantic Loss - Mean: 1.51476, Variance: 0.00101

Test Epoch: 44 
task: majority, mean loss: 2.26033, accuracy: 0.21800, task: max, mean loss: 1.81106, accuracy: 0.31400, task: top, mean loss: 2.44111, accuracy: 0.18600, task: multi, mean loss: 0.57135, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.77096
Diversity Loss - Mean: -0.14227, Variance: 0.13788
Semantic Loss - Mean: 1.77966, Variance: 0.00056

Train Epoch: 45 
task: majority, mean loss: 1.74853, accuracy: 0.34700, task: max, mean loss: 1.53899, accuracy: 0.43200, task: top, mean loss: 1.76532, accuracy: 0.32800, task: multi, mean loss: 0.55452, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.40184, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.13818, Variance: 0.12526
Semantic Loss - Mean: 1.45697, Variance: 0.00102

Test Epoch: 45 
task: majority, mean loss: 2.93206, accuracy: 0.12500, task: max, mean loss: 1.99561, accuracy: 0.24400, task: top, mean loss: 2.54701, accuracy: 0.14800, task: multi, mean loss: 0.62415, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.02470
Diversity Loss - Mean: -0.14233, Variance: 0.13755
Semantic Loss - Mean: 1.97969, Variance: 0.00057

Train Epoch: 46 
task: majority, mean loss: 1.69717, accuracy: 0.35100, task: max, mean loss: 1.52800, accuracy: 0.44000, task: top, mean loss: 1.70234, accuracy: 0.36100, task: multi, mean loss: 0.55027, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.36944, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.13830, Variance: 0.12475
Semantic Loss - Mean: 1.42919, Variance: 0.00103

Test Epoch: 46 
task: majority, mean loss: 2.15094, accuracy: 0.23000, task: max, mean loss: 1.82647, accuracy: 0.33200, task: top, mean loss: 2.33760, accuracy: 0.20400, task: multi, mean loss: 0.56542, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72011
Diversity Loss - Mean: -0.14212, Variance: 0.13695
Semantic Loss - Mean: 1.72094, Variance: 0.00057

Train Epoch: 47 
task: majority, mean loss: 1.70965, accuracy: 0.34200, task: max, mean loss: 1.53412, accuracy: 0.44100, task: top, mean loss: 1.72596, accuracy: 0.35200, task: multi, mean loss: 0.55123, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.38024, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.13761, Variance: 0.12422
Semantic Loss - Mean: 1.44244, Variance: 0.00105

Test Epoch: 47 
task: majority, mean loss: 2.25023, accuracy: 0.22700, task: max, mean loss: 1.86781, accuracy: 0.30300, task: top, mean loss: 2.43837, accuracy: 0.20000, task: multi, mean loss: 0.57382, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.78256
Diversity Loss - Mean: -0.14180, Variance: 0.13619
Semantic Loss - Mean: 1.76643, Variance: 0.00059

Train Epoch: 48 
task: majority, mean loss: 1.72757, accuracy: 0.34700, task: max, mean loss: 1.55310, accuracy: 0.42900, task: top, mean loss: 1.73689, accuracy: 0.32600, task: multi, mean loss: 0.55268, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.39256, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.13683, Variance: 0.12364
Semantic Loss - Mean: 1.45218, Variance: 0.00106

Test Epoch: 48 
task: majority, mean loss: 2.49756, accuracy: 0.19600, task: max, mean loss: 1.83019, accuracy: 0.32100, task: top, mean loss: 2.54253, accuracy: 0.19400, task: multi, mean loss: 0.58238, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.86317
Diversity Loss - Mean: -0.14207, Variance: 0.13583
Semantic Loss - Mean: 1.80609, Variance: 0.00060

Train Epoch: 49 
task: majority, mean loss: 1.67138, accuracy: 0.36100, task: max, mean loss: 1.49812, accuracy: 0.45900, task: top, mean loss: 1.65603, accuracy: 0.35900, task: multi, mean loss: 0.54854, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.34352, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.13754, Variance: 0.12308
Semantic Loss - Mean: 1.41136, Variance: 0.00108

Test Epoch: 49 
task: majority, mean loss: 2.11992, accuracy: 0.24100, task: max, mean loss: 1.82154, accuracy: 0.34300, task: top, mean loss: 2.34652, accuracy: 0.22200, task: multi, mean loss: 0.56110, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.71227
Diversity Loss - Mean: -0.14177, Variance: 0.13523
Semantic Loss - Mean: 1.70635, Variance: 0.00061

Train Epoch: 50 
task: majority, mean loss: 1.66419, accuracy: 0.37700, task: max, mean loss: 1.50445, accuracy: 0.46300, task: top, mean loss: 1.67240, accuracy: 0.36200, task: multi, mean loss: 0.54559, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.34666, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.13674, Variance: 0.12248
Semantic Loss - Mean: 1.41629, Variance: 0.00110

Test Epoch: 50 
task: majority, mean loss: 2.24558, accuracy: 0.18600, task: max, mean loss: 1.86973, accuracy: 0.33000, task: top, mean loss: 2.41405, accuracy: 0.18200, task: multi, mean loss: 0.57523, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77615
Diversity Loss - Mean: -0.14195, Variance: 0.13458
Semantic Loss - Mean: 1.72894, Variance: 0.00062

Train Epoch: 51 
task: majority, mean loss: 1.66075, accuracy: 0.36600, task: max, mean loss: 1.50434, accuracy: 0.45900, task: top, mean loss: 1.69204, accuracy: 0.34200, task: multi, mean loss: 0.54724, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.35109, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.13706, Variance: 0.12183
Semantic Loss - Mean: 1.41984, Variance: 0.00111

Test Epoch: 51 
task: majority, mean loss: 3.74180, accuracy: 0.10300, task: max, mean loss: 2.40183, accuracy: 0.18800, task: top, mean loss: 3.41995, accuracy: 0.10800, task: multi, mean loss: 0.68470, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.56207
Diversity Loss - Mean: -0.14182, Variance: 0.13425
Semantic Loss - Mean: 2.36708, Variance: 0.00064

Train Epoch: 52 
task: majority, mean loss: 1.62792, accuracy: 0.39400, task: max, mean loss: 1.46763, accuracy: 0.48100, task: top, mean loss: 1.63909, accuracy: 0.37000, task: multi, mean loss: 0.54274, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.31935, lr: 0.0005527119674021931
Diversity Loss - Mean: -0.13672, Variance: 0.12119
Semantic Loss - Mean: 1.38142, Variance: 0.00111

Test Epoch: 52 
task: majority, mean loss: 2.29230, accuracy: 0.21500, task: max, mean loss: 1.93029, accuracy: 0.32400, task: top, mean loss: 2.36358, accuracy: 0.21400, task: multi, mean loss: 0.58168, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79196
Diversity Loss - Mean: -0.14089, Variance: 0.13377
Semantic Loss - Mean: 1.80201, Variance: 0.00067

Train Epoch: 53 
task: majority, mean loss: 1.63433, accuracy: 0.38500, task: max, mean loss: 1.47698, accuracy: 0.45000, task: top, mean loss: 1.67526, accuracy: 0.35700, task: multi, mean loss: 0.54524, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.33295, lr: 0.0005353433586351905
Diversity Loss - Mean: -0.13635, Variance: 0.12055
Semantic Loss - Mean: 1.39240, Variance: 0.00113

Test Epoch: 53 
task: majority, mean loss: 3.38748, accuracy: 0.10400, task: max, mean loss: 2.31711, accuracy: 0.22600, task: top, mean loss: 3.13442, accuracy: 0.12300, task: multi, mean loss: 0.65818, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.37430
Diversity Loss - Mean: -0.14173, Variance: 0.13335
Semantic Loss - Mean: 2.24711, Variance: 0.00071

Train Epoch: 54 
task: majority, mean loss: 1.70935, accuracy: 0.36200, task: max, mean loss: 1.47039, accuracy: 0.45100, task: top, mean loss: 1.64881, accuracy: 0.36600, task: multi, mean loss: 0.54627, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.34371, lr: 0.0005179322986028993
Diversity Loss - Mean: -0.13606, Variance: 0.11987
Semantic Loss - Mean: 1.39876, Variance: 0.00114

Test Epoch: 54 
task: majority, mean loss: 2.36353, accuracy: 0.23200, task: max, mean loss: 1.85918, accuracy: 0.31400, task: top, mean loss: 2.43171, accuracy: 0.22200, task: multi, mean loss: 0.57488, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.80733
Diversity Loss - Mean: -0.14117, Variance: 0.13235
Semantic Loss - Mean: 1.79437, Variance: 0.00072

Train Epoch: 55 
task: majority, mean loss: 1.60562, accuracy: 0.41200, task: max, mean loss: 1.43103, accuracy: 0.50100, task: top, mean loss: 1.58706, accuracy: 0.38700, task: multi, mean loss: 0.54070, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.29110, lr: 0.0005005
Diversity Loss - Mean: -0.13553, Variance: 0.11920
Semantic Loss - Mean: 1.36201, Variance: 0.00116

Test Epoch: 55 
task: majority, mean loss: 2.23100, accuracy: 0.21300, task: max, mean loss: 1.88559, accuracy: 0.34300, task: top, mean loss: 2.42905, accuracy: 0.21700, task: multi, mean loss: 0.57434, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.77999
Diversity Loss - Mean: -0.14147, Variance: 0.13174
Semantic Loss - Mean: 1.77387, Variance: 0.00073

Train Epoch: 56 
task: majority, mean loss: 1.57890, accuracy: 0.40800, task: max, mean loss: 1.42886, accuracy: 0.48600, task: top, mean loss: 1.56461, accuracy: 0.39700, task: multi, mean loss: 0.53666, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.27726, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.13587, Variance: 0.11851
Semantic Loss - Mean: 1.34910, Variance: 0.00117

Test Epoch: 56 
task: majority, mean loss: 2.38259, accuracy: 0.20400, task: max, mean loss: 1.90218, accuracy: 0.34300, task: top, mean loss: 2.49897, accuracy: 0.22500, task: multi, mean loss: 0.58016, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.84098
Diversity Loss - Mean: -0.14160, Variance: 0.13096
Semantic Loss - Mean: 1.78603, Variance: 0.00074

Train Epoch: 57 
task: majority, mean loss: 1.59755, accuracy: 0.43200, task: max, mean loss: 1.41671, accuracy: 0.50400, task: top, mean loss: 1.56636, accuracy: 0.40900, task: multi, mean loss: 0.53555, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.27904, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.13486, Variance: 0.11784
Semantic Loss - Mean: 1.35039, Variance: 0.00119

Test Epoch: 57 
task: majority, mean loss: 2.11597, accuracy: 0.28600, task: max, mean loss: 1.76457, accuracy: 0.38300, task: top, mean loss: 2.34996, accuracy: 0.25900, task: multi, mean loss: 0.55042, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.69523
Diversity Loss - Mean: -0.14168, Variance: 0.13024
Semantic Loss - Mean: 1.68742, Variance: 0.00075

Train Epoch: 58 
task: majority, mean loss: 1.50614, accuracy: 0.44900, task: max, mean loss: 1.36661, accuracy: 0.51500, task: top, mean loss: 1.44924, accuracy: 0.44600, task: multi, mean loss: 0.53142, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.21335, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.13620, Variance: 0.11716
Semantic Loss - Mean: 1.28871, Variance: 0.00120

Test Epoch: 58 
task: majority, mean loss: 2.48070, accuracy: 0.19100, task: max, mean loss: 2.01438, accuracy: 0.31200, task: top, mean loss: 2.49841, accuracy: 0.22900, task: multi, mean loss: 0.59245, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.89649
Diversity Loss - Mean: -0.14104, Variance: 0.12985
Semantic Loss - Mean: 1.93355, Variance: 0.00076

Train Epoch: 59 
task: majority, mean loss: 1.50124, accuracy: 0.44700, task: max, mean loss: 1.36306, accuracy: 0.51600, task: top, mean loss: 1.45453, accuracy: 0.44300, task: multi, mean loss: 0.52921, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.21201, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.13647, Variance: 0.11650
Semantic Loss - Mean: 1.29093, Variance: 0.00121

Test Epoch: 59 
task: majority, mean loss: 2.45431, accuracy: 0.27700, task: max, mean loss: 1.77673, accuracy: 0.36800, task: top, mean loss: 2.61108, accuracy: 0.25800, task: multi, mean loss: 0.55590, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.84950
Diversity Loss - Mean: -0.14166, Variance: 0.12946
Semantic Loss - Mean: 1.83245, Variance: 0.00077

Train Epoch: 60 
task: majority, mean loss: 1.45866, accuracy: 0.46300, task: max, mean loss: 1.33738, accuracy: 0.52300, task: top, mean loss: 1.41378, accuracy: 0.47400, task: multi, mean loss: 0.52520, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.18375, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.13578, Variance: 0.11588
Semantic Loss - Mean: 1.26099, Variance: 0.00123

Test Epoch: 60 
task: majority, mean loss: 2.41810, accuracy: 0.24500, task: max, mean loss: 1.85878, accuracy: 0.33300, task: top, mean loss: 2.68509, accuracy: 0.23100, task: multi, mean loss: 0.57296, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.88373
Diversity Loss - Mean: -0.14158, Variance: 0.12857
Semantic Loss - Mean: 1.77551, Variance: 0.00078

Train Epoch: 61 
task: majority, mean loss: 1.42350, accuracy: 0.48000, task: max, mean loss: 1.31098, accuracy: 0.52100, task: top, mean loss: 1.41074, accuracy: 0.47200, task: multi, mean loss: 0.52400, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.16731, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.13604, Variance: 0.11526
Semantic Loss - Mean: 1.25210, Variance: 0.00125

Test Epoch: 61 
task: majority, mean loss: 2.34871, accuracy: 0.23000, task: max, mean loss: 1.83517, accuracy: 0.36300, task: top, mean loss: 2.59152, accuracy: 0.25500, task: multi, mean loss: 0.56472, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.83503
Diversity Loss - Mean: -0.14173, Variance: 0.12786
Semantic Loss - Mean: 1.77982, Variance: 0.00080

Train Epoch: 62 
task: majority, mean loss: 1.44824, accuracy: 0.46200, task: max, mean loss: 1.32910, accuracy: 0.49800, task: top, mean loss: 1.40217, accuracy: 0.48000, task: multi, mean loss: 0.52394, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.17586, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.13576, Variance: 0.11469
Semantic Loss - Mean: 1.25423, Variance: 0.00127

Test Epoch: 62 
task: majority, mean loss: 2.66524, accuracy: 0.18500, task: max, mean loss: 1.95734, accuracy: 0.31400, task: top, mean loss: 2.73996, accuracy: 0.21000, task: multi, mean loss: 0.58676, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.98733
Diversity Loss - Mean: -0.14127, Variance: 0.12700
Semantic Loss - Mean: 1.80066, Variance: 0.00083

Train Epoch: 63 
task: majority, mean loss: 1.55360, accuracy: 0.42700, task: max, mean loss: 1.37331, accuracy: 0.49500, task: top, mean loss: 1.47069, accuracy: 0.45400, task: multi, mean loss: 0.53113, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.23218, lr: 0.00036281914076940884
Diversity Loss - Mean: -0.13501, Variance: 0.11407
Semantic Loss - Mean: 1.31145, Variance: 0.00129

Test Epoch: 63 
task: majority, mean loss: 2.16789, accuracy: 0.26800, task: max, mean loss: 1.71303, accuracy: 0.38900, task: top, mean loss: 2.53844, accuracy: 0.25900, task: multi, mean loss: 0.54598, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.74133
Diversity Loss - Mean: -0.14137, Variance: 0.12639
Semantic Loss - Mean: 1.70786, Variance: 0.00084

Train Epoch: 64 
task: majority, mean loss: 1.42499, accuracy: 0.46900, task: max, mean loss: 1.28126, accuracy: 0.53100, task: top, mean loss: 1.31071, accuracy: 0.49200, task: multi, mean loss: 0.51820, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.13379, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.13523, Variance: 0.11353
Semantic Loss - Mean: 1.21358, Variance: 0.00130

Test Epoch: 64 
task: majority, mean loss: 2.60120, accuracy: 0.23800, task: max, mean loss: 2.16181, accuracy: 0.33400, task: top, mean loss: 2.66159, accuracy: 0.23700, task: multi, mean loss: 0.61513, multilabel_accuracy: 0.00200, avg. loss over tasks: 2.00993
Diversity Loss - Mean: -0.14106, Variance: 0.12635
Semantic Loss - Mean: 2.06779, Variance: 0.00087

Train Epoch: 65 
task: majority, mean loss: 1.34338, accuracy: 0.52500, task: max, mean loss: 1.24593, accuracy: 0.54200, task: top, mean loss: 1.28584, accuracy: 0.51600, task: multi, mean loss: 0.51653, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.09792, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.13576, Variance: 0.11302
Semantic Loss - Mean: 1.18385, Variance: 0.00132

Test Epoch: 65 
task: majority, mean loss: 2.16895, accuracy: 0.34400, task: max, mean loss: 1.63704, accuracy: 0.40200, task: top, mean loss: 2.46197, accuracy: 0.28600, task: multi, mean loss: 0.53702, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.70125
Diversity Loss - Mean: -0.14184, Variance: 0.12583
Semantic Loss - Mean: 1.66629, Variance: 0.00087

Train Epoch: 66 
task: majority, mean loss: 1.34563, accuracy: 0.50900, task: max, mean loss: 1.23192, accuracy: 0.55800, task: top, mean loss: 1.24126, accuracy: 0.53600, task: multi, mean loss: 0.50976, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.08214, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.13564, Variance: 0.11253
Semantic Loss - Mean: 1.17990, Variance: 0.00134

Test Epoch: 66 
task: majority, mean loss: 2.32199, accuracy: 0.30500, task: max, mean loss: 1.80101, accuracy: 0.37700, task: top, mean loss: 2.65312, accuracy: 0.26800, task: multi, mean loss: 0.56070, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.83421
Diversity Loss - Mean: -0.14175, Variance: 0.12555
Semantic Loss - Mean: 1.80211, Variance: 0.00088

Train Epoch: 67 
task: majority, mean loss: 1.28607, accuracy: 0.54000, task: max, mean loss: 1.20681, accuracy: 0.55100, task: top, mean loss: 1.19708, accuracy: 0.55900, task: multi, mean loss: 0.50883, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.04970, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.13524, Variance: 0.11207
Semantic Loss - Mean: 1.14556, Variance: 0.00136

Test Epoch: 67 
task: majority, mean loss: 2.27449, accuracy: 0.32200, task: max, mean loss: 1.67347, accuracy: 0.39700, task: top, mean loss: 2.71662, accuracy: 0.28400, task: multi, mean loss: 0.53926, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.80096
Diversity Loss - Mean: -0.14142, Variance: 0.12528
Semantic Loss - Mean: 1.82541, Variance: 0.00090

Train Epoch: 68 
task: majority, mean loss: 1.29334, accuracy: 0.54300, task: max, mean loss: 1.21679, accuracy: 0.56400, task: top, mean loss: 1.18354, accuracy: 0.56100, task: multi, mean loss: 0.50967, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.05084, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.13535, Variance: 0.11159
Semantic Loss - Mean: 1.15027, Variance: 0.00138

Test Epoch: 68 
task: majority, mean loss: 2.47855, accuracy: 0.27300, task: max, mean loss: 1.88299, accuracy: 0.35400, task: top, mean loss: 2.73343, accuracy: 0.26400, task: multi, mean loss: 0.57719, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.91804
Diversity Loss - Mean: -0.14192, Variance: 0.12491
Semantic Loss - Mean: 1.87657, Variance: 0.00092

Train Epoch: 69 
task: majority, mean loss: 1.30254, accuracy: 0.51900, task: max, mean loss: 1.21532, accuracy: 0.55300, task: top, mean loss: 1.20033, accuracy: 0.53900, task: multi, mean loss: 0.50831, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.05662, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.13571, Variance: 0.11113
Semantic Loss - Mean: 1.15460, Variance: 0.00140

Test Epoch: 69 
task: majority, mean loss: 2.23378, accuracy: 0.35500, task: max, mean loss: 1.68000, accuracy: 0.40100, task: top, mean loss: 2.54812, accuracy: 0.29200, task: multi, mean loss: 0.53338, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.74882
Diversity Loss - Mean: -0.14169, Variance: 0.12435
Semantic Loss - Mean: 1.69987, Variance: 0.00093

Train Epoch: 70 
task: majority, mean loss: 1.26832, accuracy: 0.53000, task: max, mean loss: 1.19082, accuracy: 0.56700, task: top, mean loss: 1.16992, accuracy: 0.57600, task: multi, mean loss: 0.50717, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.03406, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.13513, Variance: 0.11069
Semantic Loss - Mean: 1.12744, Variance: 0.00142

Test Epoch: 70 
task: majority, mean loss: 2.33999, accuracy: 0.29800, task: max, mean loss: 1.83517, accuracy: 0.35700, task: top, mean loss: 2.76025, accuracy: 0.28800, task: multi, mean loss: 0.55557, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.87274
Diversity Loss - Mean: -0.14182, Variance: 0.12375
Semantic Loss - Mean: 1.76492, Variance: 0.00094

Train Epoch: 71 
task: majority, mean loss: 1.18028, accuracy: 0.58100, task: max, mean loss: 1.15563, accuracy: 0.57600, task: top, mean loss: 1.10922, accuracy: 0.59500, task: multi, mean loss: 0.50165, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.98669, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.13547, Variance: 0.11027
Semantic Loss - Mean: 1.08459, Variance: 0.00144

Test Epoch: 71 
task: majority, mean loss: 2.32324, accuracy: 0.31400, task: max, mean loss: 1.79184, accuracy: 0.36600, task: top, mean loss: 2.77032, accuracy: 0.27900, task: multi, mean loss: 0.55286, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.85957
Diversity Loss - Mean: -0.14180, Variance: 0.12321
Semantic Loss - Mean: 1.78037, Variance: 0.00095

Train Epoch: 72 
task: majority, mean loss: 1.17364, accuracy: 0.57600, task: max, mean loss: 1.10837, accuracy: 0.59700, task: top, mean loss: 1.04779, accuracy: 0.61700, task: multi, mean loss: 0.49996, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.95744, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.13568, Variance: 0.10989
Semantic Loss - Mean: 1.05665, Variance: 0.00146

Test Epoch: 72 
task: majority, mean loss: 2.24712, accuracy: 0.35500, task: max, mean loss: 1.70808, accuracy: 0.40000, task: top, mean loss: 2.75295, accuracy: 0.29000, task: multi, mean loss: 0.54288, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.81276
Diversity Loss - Mean: -0.14191, Variance: 0.12275
Semantic Loss - Mean: 1.74271, Variance: 0.00096

Train Epoch: 73 
task: majority, mean loss: 1.14095, accuracy: 0.59200, task: max, mean loss: 1.10612, accuracy: 0.60700, task: top, mean loss: 1.03301, accuracy: 0.61900, task: multi, mean loss: 0.49834, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.94461, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.13507, Variance: 0.10949
Semantic Loss - Mean: 1.05383, Variance: 0.00148

Test Epoch: 73 
task: majority, mean loss: 2.38851, accuracy: 0.33200, task: max, mean loss: 1.80146, accuracy: 0.39400, task: top, mean loss: 2.80909, accuracy: 0.29200, task: multi, mean loss: 0.55350, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.88814
Diversity Loss - Mean: -0.14179, Variance: 0.12242
Semantic Loss - Mean: 1.84231, Variance: 0.00097

Train Epoch: 74 
task: majority, mean loss: 1.18321, accuracy: 0.57200, task: max, mean loss: 1.14546, accuracy: 0.57100, task: top, mean loss: 1.06949, accuracy: 0.60500, task: multi, mean loss: 0.50435, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.97563, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.13510, Variance: 0.10912
Semantic Loss - Mean: 1.07604, Variance: 0.00151

Test Epoch: 74 
task: majority, mean loss: 2.31451, accuracy: 0.33700, task: max, mean loss: 1.79554, accuracy: 0.38600, task: top, mean loss: 2.76537, accuracy: 0.31200, task: multi, mean loss: 0.54923, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.85616
Diversity Loss - Mean: -0.14184, Variance: 0.12205
Semantic Loss - Mean: 1.82095, Variance: 0.00098

Train Epoch: 75 
task: majority, mean loss: 1.10670, accuracy: 0.61200, task: max, mean loss: 1.07243, accuracy: 0.61200, task: top, mean loss: 0.97518, accuracy: 0.66400, task: multi, mean loss: 0.49469, multilabel_accuracy: 0.00100, avg. loss over tasks: 0.91225, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.13493, Variance: 0.10876
Semantic Loss - Mean: 1.01953, Variance: 0.00152

Test Epoch: 75 
task: majority, mean loss: 2.32420, accuracy: 0.36100, task: max, mean loss: 1.73824, accuracy: 0.38700, task: top, mean loss: 2.86024, accuracy: 0.30400, task: multi, mean loss: 0.54404, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.86668
Diversity Loss - Mean: -0.14196, Variance: 0.12163
Semantic Loss - Mean: 1.79001, Variance: 0.00099

Train Epoch: 76 
task: majority, mean loss: 1.06342, accuracy: 0.62000, task: max, mean loss: 1.05121, accuracy: 0.62800, task: top, mean loss: 0.94377, accuracy: 0.65700, task: multi, mean loss: 0.49834, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.88918, lr: 0.0001662692621237503
Diversity Loss - Mean: -0.13510, Variance: 0.10841
Semantic Loss - Mean: 1.00720, Variance: 0.00155

Test Epoch: 76 
task: majority, mean loss: 2.52858, accuracy: 0.35100, task: max, mean loss: 1.74592, accuracy: 0.39400, task: top, mean loss: 2.95300, accuracy: 0.30200, task: multi, mean loss: 0.54637, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.94347
Diversity Loss - Mean: -0.14197, Variance: 0.12130
Semantic Loss - Mean: 1.85545, Variance: 0.00099

Train Epoch: 77 
task: majority, mean loss: 1.06361, accuracy: 0.61200, task: max, mean loss: 1.05610, accuracy: 0.61600, task: top, mean loss: 0.93619, accuracy: 0.66100, task: multi, mean loss: 0.49565, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.88789, lr: 0.000153518143955731
Diversity Loss - Mean: -0.13471, Variance: 0.10806
Semantic Loss - Mean: 0.99635, Variance: 0.00157

Test Epoch: 77 
task: majority, mean loss: 2.32373, accuracy: 0.35600, task: max, mean loss: 1.81250, accuracy: 0.38900, task: top, mean loss: 2.90801, accuracy: 0.31100, task: multi, mean loss: 0.54612, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.89759
Diversity Loss - Mean: -0.14182, Variance: 0.12089
Semantic Loss - Mean: 1.81394, Variance: 0.00101

Train Epoch: 78 
task: majority, mean loss: 1.02230, accuracy: 0.63300, task: max, mean loss: 1.02562, accuracy: 0.64100, task: top, mean loss: 0.90700, accuracy: 0.68800, task: multi, mean loss: 0.49359, multilabel_accuracy: 0.00000, avg. loss over tasks: 0.86213, lr: 0.00014118976973084374
Diversity Loss - Mean: -0.13470, Variance: 0.10773
Semantic Loss - Mean: 0.98583, Variance: 0.00159

Test Epoch: 78 
task: majority, mean loss: 2.34135, accuracy: 0.33800, task: max, mean loss: 1.80727, accuracy: 0.39800, task: top, mean loss: 2.89686, accuracy: 0.30900, task: multi, mean loss: 0.54713, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.89815
Diversity Loss - Mean: -0.14182, Variance: 0.12047
Semantic Loss - Mean: 1.80791, Variance: 0.00102

Train Epoch: 79 
task: majority, mean loss: 1.02206, accuracy: 0.64100, task: max, mean loss: 1.00736, accuracy: 0.64100, task: top, mean loss: 0.89131, accuracy: 0.69300, task: multi, mean loss: 0.49436, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.85377, lr: 0.0001292991596740417
Diversity Loss - Mean: -0.13540, Variance: 0.10743
Semantic Loss - Mean: 0.96831, Variance: 0.00161

Test Epoch: 79 
task: majority, mean loss: 2.31154, accuracy: 0.36300, task: max, mean loss: 1.80870, accuracy: 0.41400, task: top, mean loss: 2.93551, accuracy: 0.31800, task: multi, mean loss: 0.54636, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.90053
Diversity Loss - Mean: -0.14187, Variance: 0.12013
Semantic Loss - Mean: 1.82532, Variance: 0.00103

Train Epoch: 80 
task: majority, mean loss: 0.98510, accuracy: 0.64500, task: max, mean loss: 0.99505, accuracy: 0.65100, task: top, mean loss: 0.85378, accuracy: 0.69900, task: multi, mean loss: 0.49243, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.83159, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.13462, Variance: 0.10712
Semantic Loss - Mean: 0.95313, Variance: 0.00163

Test Epoch: 80 
task: majority, mean loss: 2.47347, accuracy: 0.37400, task: max, mean loss: 1.79626, accuracy: 0.40200, task: top, mean loss: 3.06699, accuracy: 0.31100, task: multi, mean loss: 0.55108, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.97195
Diversity Loss - Mean: -0.14191, Variance: 0.11988
Semantic Loss - Mean: 1.89579, Variance: 0.00104

Train Epoch: 81 
task: majority, mean loss: 1.00328, accuracy: 0.64000, task: max, mean loss: 0.95329, accuracy: 0.66900, task: top, mean loss: 0.86571, accuracy: 0.69500, task: multi, mean loss: 0.49084, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.82828, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.13465, Variance: 0.10682
Semantic Loss - Mean: 0.94484, Variance: 0.00165

Test Epoch: 81 
task: majority, mean loss: 2.49220, accuracy: 0.36000, task: max, mean loss: 1.83855, accuracy: 0.39200, task: top, mean loss: 3.04944, accuracy: 0.31000, task: multi, mean loss: 0.55530, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.98387
Diversity Loss - Mean: -0.14193, Variance: 0.11963
Semantic Loss - Mean: 1.91108, Variance: 0.00104

Train Epoch: 82 
task: majority, mean loss: 0.96940, accuracy: 0.64300, task: max, mean loss: 0.98327, accuracy: 0.64800, task: top, mean loss: 0.85156, accuracy: 0.70300, task: multi, mean loss: 0.49334, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.82439, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.13483, Variance: 0.10652
Semantic Loss - Mean: 0.94382, Variance: 0.00166

Test Epoch: 82 
task: majority, mean loss: 2.56896, accuracy: 0.36000, task: max, mean loss: 1.93463, accuracy: 0.38500, task: top, mean loss: 3.12566, accuracy: 0.30400, task: multi, mean loss: 0.56493, multilabel_accuracy: 0.00200, avg. loss over tasks: 2.04855
Diversity Loss - Mean: -0.14195, Variance: 0.11942
Semantic Loss - Mean: 1.97784, Variance: 0.00105

Train Epoch: 83 
task: majority, mean loss: 0.96090, accuracy: 0.64400, task: max, mean loss: 0.93731, accuracy: 0.67500, task: top, mean loss: 0.82579, accuracy: 0.71900, task: multi, mean loss: 0.49148, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.80387, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.13501, Variance: 0.10624
Semantic Loss - Mean: 0.92861, Variance: 0.00168

Test Epoch: 83 
task: majority, mean loss: 2.43771, accuracy: 0.36800, task: max, mean loss: 1.87625, accuracy: 0.39100, task: top, mean loss: 3.06957, accuracy: 0.31800, task: multi, mean loss: 0.55063, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.98354
Diversity Loss - Mean: -0.14186, Variance: 0.11909
Semantic Loss - Mean: 1.89141, Variance: 0.00106

Train Epoch: 84 
task: majority, mean loss: 0.93787, accuracy: 0.67000, task: max, mean loss: 0.94051, accuracy: 0.67400, task: top, mean loss: 0.77797, accuracy: 0.74000, task: multi, mean loss: 0.48655, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.78572, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.13500, Variance: 0.10596
Semantic Loss - Mean: 0.90774, Variance: 0.00171

Test Epoch: 84 
task: majority, mean loss: 2.42443, accuracy: 0.36600, task: max, mean loss: 1.82914, accuracy: 0.38800, task: top, mean loss: 3.07341, accuracy: 0.31600, task: multi, mean loss: 0.54885, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.96896
Diversity Loss - Mean: -0.14187, Variance: 0.11877
Semantic Loss - Mean: 1.88170, Variance: 0.00107

Train Epoch: 85 
task: majority, mean loss: 0.93121, accuracy: 0.66800, task: max, mean loss: 0.93602, accuracy: 0.67800, task: top, mean loss: 0.77787, accuracy: 0.73300, task: multi, mean loss: 0.48660, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.78293, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.13503, Variance: 0.10569
Semantic Loss - Mean: 0.91522, Variance: 0.00173

Test Epoch: 85 
task: majority, mean loss: 2.43908, accuracy: 0.36900, task: max, mean loss: 1.86465, accuracy: 0.39400, task: top, mean loss: 3.12734, accuracy: 0.30100, task: multi, mean loss: 0.54937, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.99511
Diversity Loss - Mean: -0.14191, Variance: 0.11846
Semantic Loss - Mean: 1.89693, Variance: 0.00109

Train Epoch: 86 
task: majority, mean loss: 0.89727, accuracy: 0.66600, task: max, mean loss: 0.92500, accuracy: 0.67800, task: top, mean loss: 0.76560, accuracy: 0.73100, task: multi, mean loss: 0.48758, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.76886, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.13500, Variance: 0.10541
Semantic Loss - Mean: 0.89456, Variance: 0.00175

Test Epoch: 86 
task: majority, mean loss: 2.55821, accuracy: 0.36200, task: max, mean loss: 1.94944, accuracy: 0.39100, task: top, mean loss: 3.17025, accuracy: 0.32200, task: multi, mean loss: 0.56099, multilabel_accuracy: 0.00300, avg. loss over tasks: 2.05972
Diversity Loss - Mean: -0.14175, Variance: 0.11823
Semantic Loss - Mean: 1.98021, Variance: 0.00110

Train Epoch: 87 
task: majority, mean loss: 0.91945, accuracy: 0.66700, task: max, mean loss: 0.89665, accuracy: 0.69000, task: top, mean loss: 0.76073, accuracy: 0.74000, task: multi, mean loss: 0.48682, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.76591, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.13503, Variance: 0.10516
Semantic Loss - Mean: 0.88973, Variance: 0.00178

Test Epoch: 87 
task: majority, mean loss: 2.54421, accuracy: 0.36900, task: max, mean loss: 1.89425, accuracy: 0.39400, task: top, mean loss: 3.18576, accuracy: 0.30300, task: multi, mean loss: 0.55482, multilabel_accuracy: 0.00300, avg. loss over tasks: 2.04476
Diversity Loss - Mean: -0.14195, Variance: 0.11799
Semantic Loss - Mean: 1.96017, Variance: 0.00111

Train Epoch: 88 
task: majority, mean loss: 0.88303, accuracy: 0.68000, task: max, mean loss: 0.89460, accuracy: 0.69100, task: top, mean loss: 0.73352, accuracy: 0.76600, task: multi, mean loss: 0.48507, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.74905, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.13494, Variance: 0.10491
Semantic Loss - Mean: 0.87945, Variance: 0.00179

Test Epoch: 88 
task: majority, mean loss: 2.47003, accuracy: 0.36600, task: max, mean loss: 1.90204, accuracy: 0.39500, task: top, mean loss: 3.16710, accuracy: 0.30400, task: multi, mean loss: 0.55118, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.02259
Diversity Loss - Mean: -0.14188, Variance: 0.11770
Semantic Loss - Mean: 1.91817, Variance: 0.00111

Train Epoch: 89 
task: majority, mean loss: 0.90198, accuracy: 0.67100, task: max, mean loss: 0.88314, accuracy: 0.70600, task: top, mean loss: 0.74370, accuracy: 0.74200, task: multi, mean loss: 0.48605, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.75372, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.13500, Variance: 0.10467
Semantic Loss - Mean: 0.87709, Variance: 0.00181

Test Epoch: 89 
task: majority, mean loss: 2.52277, accuracy: 0.37300, task: max, mean loss: 1.92347, accuracy: 0.39600, task: top, mean loss: 3.18564, accuracy: 0.31000, task: multi, mean loss: 0.55403, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.04648
Diversity Loss - Mean: -0.14187, Variance: 0.11746
Semantic Loss - Mean: 1.95213, Variance: 0.00113

Train Epoch: 90 
task: majority, mean loss: 0.87529, accuracy: 0.68200, task: max, mean loss: 0.86856, accuracy: 0.71100, task: top, mean loss: 0.72817, accuracy: 0.76900, task: multi, mean loss: 0.48538, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.73935, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.13496, Variance: 0.10442
Semantic Loss - Mean: 0.87020, Variance: 0.00183

Test Epoch: 90 
task: majority, mean loss: 2.50764, accuracy: 0.37500, task: max, mean loss: 1.91678, accuracy: 0.39900, task: top, mean loss: 3.19644, accuracy: 0.30400, task: multi, mean loss: 0.55458, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.04386
Diversity Loss - Mean: -0.14188, Variance: 0.11721
Semantic Loss - Mean: 1.94888, Variance: 0.00114

Train Epoch: 91 
task: majority, mean loss: 0.86828, accuracy: 0.69900, task: max, mean loss: 0.87225, accuracy: 0.71300, task: top, mean loss: 0.71507, accuracy: 0.75600, task: multi, mean loss: 0.48441, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.73500, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.13490, Variance: 0.10419
Semantic Loss - Mean: 0.86562, Variance: 0.00185

Test Epoch: 91 
task: majority, mean loss: 2.50743, accuracy: 0.36800, task: max, mean loss: 1.93748, accuracy: 0.40000, task: top, mean loss: 3.20781, accuracy: 0.31300, task: multi, mean loss: 0.55446, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.05179
Diversity Loss - Mean: -0.14185, Variance: 0.11696
Semantic Loss - Mean: 1.95297, Variance: 0.00115

Train Epoch: 92 
task: majority, mean loss: 0.86358, accuracy: 0.69700, task: max, mean loss: 0.86146, accuracy: 0.70700, task: top, mean loss: 0.70680, accuracy: 0.77300, task: multi, mean loss: 0.48450, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.72908, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.13505, Variance: 0.10396
Semantic Loss - Mean: 0.85776, Variance: 0.00187

Test Epoch: 92 
task: majority, mean loss: 2.51847, accuracy: 0.36500, task: max, mean loss: 1.94942, accuracy: 0.39600, task: top, mean loss: 3.21649, accuracy: 0.31200, task: multi, mean loss: 0.55399, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.05959
Diversity Loss - Mean: -0.14186, Variance: 0.11672
Semantic Loss - Mean: 1.96515, Variance: 0.00116

Train Epoch: 93 
task: majority, mean loss: 0.86601, accuracy: 0.69600, task: max, mean loss: 0.86731, accuracy: 0.71700, task: top, mean loss: 0.72721, accuracy: 0.76000, task: multi, mean loss: 0.48391, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.73611, lr: 1.583728472513976e-05
Diversity Loss - Mean: -0.13482, Variance: 0.10373
Semantic Loss - Mean: 0.86548, Variance: 0.00189

Test Epoch: 93 
task: majority, mean loss: 2.52331, accuracy: 0.37000, task: max, mean loss: 1.90336, accuracy: 0.39100, task: top, mean loss: 3.23584, accuracy: 0.30000, task: multi, mean loss: 0.55386, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.05409
Diversity Loss - Mean: -0.14185, Variance: 0.11649
Semantic Loss - Mean: 1.95472, Variance: 0.00117

Train Epoch: 94 
task: majority, mean loss: 0.84653, accuracy: 0.69600, task: max, mean loss: 0.85209, accuracy: 0.71100, task: top, mean loss: 0.68257, accuracy: 0.77500, task: multi, mean loss: 0.48183, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.71575, lr: 1.1915273433464114e-05
Diversity Loss - Mean: -0.13507, Variance: 0.10351
Semantic Loss - Mean: 0.85452, Variance: 0.00191

Test Epoch: 94 
task: majority, mean loss: 2.52426, accuracy: 0.36500, task: max, mean loss: 1.92708, accuracy: 0.39600, task: top, mean loss: 3.22456, accuracy: 0.30900, task: multi, mean loss: 0.55293, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.05721
Diversity Loss - Mean: -0.14186, Variance: 0.11625
Semantic Loss - Mean: 1.95917, Variance: 0.00118

Train Epoch: 95 
task: majority, mean loss: 0.84947, accuracy: 0.70200, task: max, mean loss: 0.84776, accuracy: 0.71200, task: top, mean loss: 0.70402, accuracy: 0.77300, task: multi, mean loss: 0.48188, multilabel_accuracy: 0.00600, avg. loss over tasks: 0.72078, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.13456, Variance: 0.10330
Semantic Loss - Mean: 0.84553, Variance: 0.00193

Test Epoch: 95 
task: majority, mean loss: 2.52000, accuracy: 0.37000, task: max, mean loss: 1.92076, accuracy: 0.39400, task: top, mean loss: 3.22882, accuracy: 0.30600, task: multi, mean loss: 0.55394, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.05588
Diversity Loss - Mean: -0.14185, Variance: 0.11602
Semantic Loss - Mean: 1.95696, Variance: 0.00119

Train Epoch: 96 
task: majority, mean loss: 0.84992, accuracy: 0.68800, task: max, mean loss: 0.84915, accuracy: 0.71200, task: top, mean loss: 0.69505, accuracy: 0.77200, task: multi, mean loss: 0.48451, multilabel_accuracy: 0.00700, avg. loss over tasks: 0.71966, lr: 5.861099663585604e-06
Diversity Loss - Mean: -0.13478, Variance: 0.10309
Semantic Loss - Mean: 0.84948, Variance: 0.00194

Test Epoch: 96 
task: majority, mean loss: 2.52484, accuracy: 0.37700, task: max, mean loss: 1.92847, accuracy: 0.39400, task: top, mean loss: 3.24265, accuracy: 0.30600, task: multi, mean loss: 0.55452, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.06262
Diversity Loss - Mean: -0.14187, Variance: 0.11580
Semantic Loss - Mean: 1.96496, Variance: 0.00120

Train Epoch: 97 
task: majority, mean loss: 0.86812, accuracy: 0.67400, task: max, mean loss: 0.85317, accuracy: 0.72400, task: top, mean loss: 0.69183, accuracy: 0.78300, task: multi, mean loss: 0.48363, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.72419, lr: 3.736313263547436e-06
Diversity Loss - Mean: -0.13503, Variance: 0.10288
Semantic Loss - Mean: 0.85072, Variance: 0.00197

Test Epoch: 97 
task: majority, mean loss: 2.53029, accuracy: 0.36900, task: max, mean loss: 1.94245, accuracy: 0.40300, task: top, mean loss: 3.23145, accuracy: 0.31300, task: multi, mean loss: 0.55412, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.06458
Diversity Loss - Mean: -0.14183, Variance: 0.11558
Semantic Loss - Mean: 1.96583, Variance: 0.00121

Train Epoch: 98 
task: majority, mean loss: 0.88012, accuracy: 0.68100, task: max, mean loss: 0.86892, accuracy: 0.71000, task: top, mean loss: 0.71588, accuracy: 0.76800, task: multi, mean loss: 0.48633, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.73781, lr: 2.2167568952178134e-06
Diversity Loss - Mean: -0.13514, Variance: 0.10269
Semantic Loss - Mean: 0.86017, Variance: 0.00198

Test Epoch: 98 
task: majority, mean loss: 2.53322, accuracy: 0.37700, task: max, mean loss: 1.93611, accuracy: 0.39400, task: top, mean loss: 3.23854, accuracy: 0.30300, task: multi, mean loss: 0.55485, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.06568
Diversity Loss - Mean: -0.14186, Variance: 0.11538
Semantic Loss - Mean: 1.96849, Variance: 0.00122

Train Epoch: 99 
task: majority, mean loss: 0.86588, accuracy: 0.68500, task: max, mean loss: 0.85275, accuracy: 0.70800, task: top, mean loss: 0.68551, accuracy: 0.78100, task: multi, mean loss: 0.48332, multilabel_accuracy: 0.01000, avg. loss over tasks: 0.72187, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.13501, Variance: 0.10249
Semantic Loss - Mean: 0.85314, Variance: 0.00200

Test Epoch: 99 
task: majority, mean loss: 2.53727, accuracy: 0.37300, task: max, mean loss: 1.92711, accuracy: 0.39500, task: top, mean loss: 3.24694, accuracy: 0.30600, task: multi, mean loss: 0.55494, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.06657
Diversity Loss - Mean: -0.14185, Variance: 0.11518
Semantic Loss - Mean: 1.96775, Variance: 0.00123

Train Epoch: 100 
task: majority, mean loss: 0.84474, accuracy: 0.70200, task: max, mean loss: 0.84729, accuracy: 0.70700, task: top, mean loss: 0.69070, accuracy: 0.76900, task: multi, mean loss: 0.48373, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.71661, lr: 1e-06
Diversity Loss - Mean: -0.13489, Variance: 0.10230
Semantic Loss - Mean: 0.84504, Variance: 0.00202

Test Epoch: 100 
task: majority, mean loss: 2.53525, accuracy: 0.37600, task: max, mean loss: 1.93440, accuracy: 0.39400, task: top, mean loss: 3.24386, accuracy: 0.30400, task: multi, mean loss: 0.55498, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.06712
Diversity Loss - Mean: -0.14186, Variance: 0.11498
Semantic Loss - Mean: 1.96888, Variance: 0.00124

