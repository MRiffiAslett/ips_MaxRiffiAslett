Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.35270, accuracy: 0.11900, task: max, mean loss: 2.19888, accuracy: 0.24300, task: top, mean loss: 2.34910, accuracy: 0.10000, task: multi, mean loss: 0.69492, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.89890, lr: 0.0001
Diversity Loss - Mean: -0.10449, Variance: 0.07455
Semantic Loss - Mean: 1.99176, Variance: 0.00815

Test Epoch: 1 
task: majority, mean loss: 2.30930, accuracy: 0.10300, task: max, mean loss: 1.92370, accuracy: 0.21300, task: top, mean loss: 2.30951, accuracy: 0.11100, task: multi, mean loss: 0.62915, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79292
Diversity Loss - Mean: -0.13898, Variance: 0.09128
Semantic Loss - Mean: 1.90610, Variance: 0.00457

Train Epoch: 2 
task: majority, mean loss: 2.32307, accuracy: 0.10900, task: max, mean loss: 1.86242, accuracy: 0.26600, task: top, mean loss: 2.33265, accuracy: 0.09000, task: multi, mean loss: 0.61376, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78298, lr: 0.0002
Diversity Loss - Mean: -0.14052, Variance: 0.09328
Semantic Loss - Mean: 1.83693, Variance: 0.00484

Test Epoch: 2 
task: majority, mean loss: 2.32007, accuracy: 0.10000, task: max, mean loss: 1.89115, accuracy: 0.22100, task: top, mean loss: 2.32532, accuracy: 0.10100, task: multi, mean loss: 0.60203, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78464
Diversity Loss - Mean: -0.13731, Variance: 0.11484
Semantic Loss - Mean: 1.79866, Variance: 0.00244

Train Epoch: 3 
task: majority, mean loss: 2.33196, accuracy: 0.09200, task: max, mean loss: 1.85330, accuracy: 0.24300, task: top, mean loss: 2.32371, accuracy: 0.09100, task: multi, mean loss: 0.60713, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77902, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14071, Variance: 0.11326
Semantic Loss - Mean: 1.77721, Variance: 0.00330

Test Epoch: 3 
task: majority, mean loss: 2.33184, accuracy: 0.09900, task: max, mean loss: 1.86650, accuracy: 0.27300, task: top, mean loss: 2.32659, accuracy: 0.10300, task: multi, mean loss: 0.60263, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78189
Diversity Loss - Mean: -0.14120, Variance: 0.13106
Semantic Loss - Mean: 1.77717, Variance: 0.00165

Train Epoch: 4 
task: majority, mean loss: 2.33887, accuracy: 0.09400, task: max, mean loss: 1.84849, accuracy: 0.25800, task: top, mean loss: 2.33960, accuracy: 0.09400, task: multi, mean loss: 0.60682, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78344, lr: 0.0004
Diversity Loss - Mean: -0.14070, Variance: 0.12500
Semantic Loss - Mean: 1.77178, Variance: 0.00252

Test Epoch: 4 
task: majority, mean loss: 2.32476, accuracy: 0.10100, task: max, mean loss: 1.86414, accuracy: 0.21400, task: top, mean loss: 2.34436, accuracy: 0.10100, task: multi, mean loss: 0.60309, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78409
Diversity Loss - Mean: -0.14171, Variance: 0.13688
Semantic Loss - Mean: 1.77733, Variance: 0.00124

Train Epoch: 5 
task: majority, mean loss: 2.33031, accuracy: 0.09600, task: max, mean loss: 1.83532, accuracy: 0.24900, task: top, mean loss: 2.32241, accuracy: 0.10400, task: multi, mean loss: 0.60526, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77333, lr: 0.0005
Diversity Loss - Mean: -0.14122, Variance: 0.13052
Semantic Loss - Mean: 1.76830, Variance: 0.00205

Test Epoch: 5 
task: majority, mean loss: 2.31556, accuracy: 0.09000, task: max, mean loss: 1.86262, accuracy: 0.27400, task: top, mean loss: 2.30653, accuracy: 0.10100, task: multi, mean loss: 0.60254, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77181
Diversity Loss - Mean: -0.14116, Variance: 0.13950
Semantic Loss - Mean: 1.77050, Variance: 0.00100

Train Epoch: 6 
task: majority, mean loss: 2.32442, accuracy: 0.10800, task: max, mean loss: 1.84651, accuracy: 0.25000, task: top, mean loss: 2.33027, accuracy: 0.10800, task: multi, mean loss: 0.60733, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77713, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.14058, Variance: 0.13282
Semantic Loss - Mean: 1.76947, Variance: 0.00173

Test Epoch: 6 
task: majority, mean loss: 2.34294, accuracy: 0.09000, task: max, mean loss: 1.87426, accuracy: 0.21300, task: top, mean loss: 2.31884, accuracy: 0.10300, task: multi, mean loss: 0.60155, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78440
Diversity Loss - Mean: -0.13882, Variance: 0.13896
Semantic Loss - Mean: 1.77308, Variance: 0.00085

Train Epoch: 7 
task: majority, mean loss: 2.29438, accuracy: 0.12100, task: max, mean loss: 1.85389, accuracy: 0.25900, task: top, mean loss: 2.31163, accuracy: 0.11800, task: multi, mean loss: 0.60697, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76672, lr: 0.0007
Diversity Loss - Mean: -0.13824, Variance: 0.13370
Semantic Loss - Mean: 1.76713, Variance: 0.00151

Test Epoch: 7 
task: majority, mean loss: 2.29494, accuracy: 0.10400, task: max, mean loss: 1.92992, accuracy: 0.16500, task: top, mean loss: 2.31659, accuracy: 0.12400, task: multi, mean loss: 0.60431, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78644
Diversity Loss - Mean: -0.13522, Variance: 0.13916
Semantic Loss - Mean: 1.77847, Variance: 0.00074

Train Epoch: 8 
task: majority, mean loss: 2.27197, accuracy: 0.14800, task: max, mean loss: 1.83373, accuracy: 0.27000, task: top, mean loss: 2.30604, accuracy: 0.11600, task: multi, mean loss: 0.60375, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75387, lr: 0.0008
Diversity Loss - Mean: -0.13320, Variance: 0.13279
Semantic Loss - Mean: 1.76504, Variance: 0.00135

Test Epoch: 8 
task: majority, mean loss: 2.35832, accuracy: 0.11100, task: max, mean loss: 1.86871, accuracy: 0.21300, task: top, mean loss: 2.32594, accuracy: 0.10100, task: multi, mean loss: 0.60232, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78882
Diversity Loss - Mean: -0.13350, Variance: 0.13923
Semantic Loss - Mean: 1.77774, Variance: 0.00068

Train Epoch: 9 
task: majority, mean loss: 2.28104, accuracy: 0.13700, task: max, mean loss: 1.83496, accuracy: 0.26400, task: top, mean loss: 2.30078, accuracy: 0.11400, task: multi, mean loss: 0.60372, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75513, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.13691, Variance: 0.13449
Semantic Loss - Mean: 1.76434, Variance: 0.00124

Test Epoch: 9 
task: majority, mean loss: 2.83485, accuracy: 0.08900, task: max, mean loss: 1.97659, accuracy: 0.14100, task: top, mean loss: 2.64820, accuracy: 0.09300, task: multi, mean loss: 0.63264, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.02307
Diversity Loss - Mean: -0.08290, Variance: 0.13714
Semantic Loss - Mean: 1.84692, Variance: 0.00113

Train Epoch: 10 
task: majority, mean loss: 2.20404, accuracy: 0.17300, task: max, mean loss: 1.82890, accuracy: 0.21800, task: top, mean loss: 2.27184, accuracy: 0.15100, task: multi, mean loss: 0.59435, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72478, lr: 0.001
Diversity Loss - Mean: -0.13246, Variance: 0.13390
Semantic Loss - Mean: 1.73885, Variance: 0.00121

Test Epoch: 10 
task: majority, mean loss: 2.20115, accuracy: 0.17800, task: max, mean loss: 1.85205, accuracy: 0.28500, task: top, mean loss: 2.28489, accuracy: 0.12900, task: multi, mean loss: 0.58951, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73190
Diversity Loss - Mean: -0.13352, Variance: 0.13610
Semantic Loss - Mean: 1.75179, Variance: 0.00113

Train Epoch: 11 
task: majority, mean loss: 2.14376, accuracy: 0.19000, task: max, mean loss: 1.80665, accuracy: 0.25800, task: top, mean loss: 2.23980, accuracy: 0.15600, task: multi, mean loss: 0.58731, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.69438, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.13187, Variance: 0.13294
Semantic Loss - Mean: 1.71679, Variance: 0.00125

Test Epoch: 11 
task: majority, mean loss: 2.13608, accuracy: 0.18300, task: max, mean loss: 1.83236, accuracy: 0.25100, task: top, mean loss: 2.25655, accuracy: 0.14800, task: multi, mean loss: 0.58141, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70160
Diversity Loss - Mean: -0.13932, Variance: 0.13622
Semantic Loss - Mean: 1.71747, Variance: 0.00115

Train Epoch: 12 
task: majority, mean loss: 2.13434, accuracy: 0.17200, task: max, mean loss: 1.79322, accuracy: 0.25700, task: top, mean loss: 2.19950, accuracy: 0.17500, task: multi, mean loss: 0.58351, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67764, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.13432, Variance: 0.13262
Semantic Loss - Mean: 1.69514, Variance: 0.00125

Test Epoch: 12 
task: majority, mean loss: 2.37524, accuracy: 0.13000, task: max, mean loss: 1.82319, accuracy: 0.25600, task: top, mean loss: 2.30418, accuracy: 0.14400, task: multi, mean loss: 0.59461, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.77431
Diversity Loss - Mean: -0.12940, Variance: 0.13640
Semantic Loss - Mean: 1.80948, Variance: 0.00114

Train Epoch: 13 
task: majority, mean loss: 2.12353, accuracy: 0.20100, task: max, mean loss: 1.78535, accuracy: 0.27000, task: top, mean loss: 2.20256, accuracy: 0.16100, task: multi, mean loss: 0.58505, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67412, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.13401, Variance: 0.13214
Semantic Loss - Mean: 1.68862, Variance: 0.00120

Test Epoch: 13 
task: majority, mean loss: 2.16870, accuracy: 0.17800, task: max, mean loss: 1.81817, accuracy: 0.27800, task: top, mean loss: 2.23682, accuracy: 0.14300, task: multi, mean loss: 0.57981, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70088
Diversity Loss - Mean: -0.14019, Variance: 0.13622
Semantic Loss - Mean: 1.70656, Variance: 0.00107

Train Epoch: 14 
task: majority, mean loss: 2.08618, accuracy: 0.20500, task: max, mean loss: 1.76940, accuracy: 0.27800, task: top, mean loss: 2.18320, accuracy: 0.16400, task: multi, mean loss: 0.58220, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.65525, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.13622, Variance: 0.13182
Semantic Loss - Mean: 1.66895, Variance: 0.00115

Test Epoch: 14 
task: majority, mean loss: 2.16896, accuracy: 0.18700, task: max, mean loss: 1.81833, accuracy: 0.25200, task: top, mean loss: 2.23089, accuracy: 0.14400, task: multi, mean loss: 0.58418, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70059
Diversity Loss - Mean: -0.14023, Variance: 0.13705
Semantic Loss - Mean: 1.70631, Variance: 0.00101

Train Epoch: 15 
task: majority, mean loss: 2.07430, accuracy: 0.19100, task: max, mean loss: 1.77478, accuracy: 0.27300, task: top, mean loss: 2.15828, accuracy: 0.16800, task: multi, mean loss: 0.58048, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.64696, lr: 0.000992411472629598
Diversity Loss - Mean: -0.13546, Variance: 0.13176
Semantic Loss - Mean: 1.66248, Variance: 0.00111

Test Epoch: 15 
task: majority, mean loss: 3.05007, accuracy: 0.10900, task: max, mean loss: 2.11354, accuracy: 0.27400, task: top, mean loss: 2.79577, accuracy: 0.09600, task: multi, mean loss: 0.70285, multilabel_accuracy: 0.00300, avg. loss over tasks: 2.16556
Diversity Loss - Mean: -0.14054, Variance: 0.13645
Semantic Loss - Mean: 1.95616, Variance: 0.00097

Train Epoch: 16 
task: majority, mean loss: 2.06850, accuracy: 0.22500, task: max, mean loss: 1.76201, accuracy: 0.27400, task: top, mean loss: 2.18455, accuracy: 0.16200, task: multi, mean loss: 0.58052, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.64889, lr: 0.000989084726566536
Diversity Loss - Mean: -0.13577, Variance: 0.13169
Semantic Loss - Mean: 1.66356, Variance: 0.00108

Test Epoch: 16 
task: majority, mean loss: 2.42568, accuracy: 0.12100, task: max, mean loss: 1.81959, accuracy: 0.29200, task: top, mean loss: 2.40193, accuracy: 0.11300, task: multi, mean loss: 0.60327, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.81262
Diversity Loss - Mean: -0.14110, Variance: 0.13900
Semantic Loss - Mean: 1.81659, Variance: 0.00098

Train Epoch: 17 
task: majority, mean loss: 2.06144, accuracy: 0.21200, task: max, mean loss: 1.75437, accuracy: 0.28500, task: top, mean loss: 2.14068, accuracy: 0.16900, task: multi, mean loss: 0.57543, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.63298, lr: 0.00098516271527486
Diversity Loss - Mean: -0.13656, Variance: 0.13199
Semantic Loss - Mean: 1.65114, Variance: 0.00105

Test Epoch: 17 
task: majority, mean loss: 2.10646, accuracy: 0.20200, task: max, mean loss: 1.78493, accuracy: 0.30500, task: top, mean loss: 2.18697, accuracy: 0.18100, task: multi, mean loss: 0.57495, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.66333
Diversity Loss - Mean: -0.14094, Variance: 0.13884
Semantic Loss - Mean: 1.67601, Variance: 0.00093

Train Epoch: 18 
task: majority, mean loss: 2.00477, accuracy: 0.25900, task: max, mean loss: 1.74018, accuracy: 0.28400, task: top, mean loss: 2.07623, accuracy: 0.19700, task: multi, mean loss: 0.57296, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.59854, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.13624, Variance: 0.13174
Semantic Loss - Mean: 1.62728, Variance: 0.00103

Test Epoch: 18 
task: majority, mean loss: 2.80132, accuracy: 0.11300, task: max, mean loss: 1.91795, accuracy: 0.17900, task: top, mean loss: 2.68531, accuracy: 0.12800, task: multi, mean loss: 0.63488, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.00986
Diversity Loss - Mean: -0.14063, Variance: 0.14247
Semantic Loss - Mean: 1.96098, Variance: 0.00106

Train Epoch: 19 
task: majority, mean loss: 1.98993, accuracy: 0.24200, task: max, mean loss: 1.75545, accuracy: 0.27400, task: top, mean loss: 2.08721, accuracy: 0.21500, task: multi, mean loss: 0.57228, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.60122, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.13591, Variance: 0.13163
Semantic Loss - Mean: 1.63093, Variance: 0.00104

Test Epoch: 19 
task: majority, mean loss: 2.07008, accuracy: 0.21500, task: max, mean loss: 1.80876, accuracy: 0.23800, task: top, mean loss: 2.18474, accuracy: 0.18300, task: multi, mean loss: 0.57378, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65934
Diversity Loss - Mean: -0.13722, Variance: 0.14220
Semantic Loss - Mean: 1.66709, Variance: 0.00103

Train Epoch: 20 
task: majority, mean loss: 2.03692, accuracy: 0.23900, task: max, mean loss: 1.76966, accuracy: 0.27900, task: top, mean loss: 2.12302, accuracy: 0.18700, task: multi, mean loss: 0.57416, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.62594, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.13552, Variance: 0.13178
Semantic Loss - Mean: 1.65329, Variance: 0.00103

Test Epoch: 20 
task: majority, mean loss: 2.19250, accuracy: 0.18900, task: max, mean loss: 1.81349, accuracy: 0.28700, task: top, mean loss: 2.21694, accuracy: 0.16400, task: multi, mean loss: 0.57920, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70053
Diversity Loss - Mean: -0.14000, Variance: 0.14315
Semantic Loss - Mean: 1.74654, Variance: 0.00100

Train Epoch: 21 
task: majority, mean loss: 2.00026, accuracy: 0.26600, task: max, mean loss: 1.74220, accuracy: 0.29600, task: top, mean loss: 2.07330, accuracy: 0.19700, task: multi, mean loss: 0.56842, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59604, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.13543, Variance: 0.13160
Semantic Loss - Mean: 1.62883, Variance: 0.00102

Test Epoch: 21 
task: majority, mean loss: 2.74626, accuracy: 0.14200, task: max, mean loss: 2.03989, accuracy: 0.21700, task: top, mean loss: 2.49489, accuracy: 0.14200, task: multi, mean loss: 0.65325, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.98357
Diversity Loss - Mean: -0.13710, Variance: 0.14215
Semantic Loss - Mean: 1.92624, Variance: 0.00101

Train Epoch: 22 
task: majority, mean loss: 1.92038, accuracy: 0.27300, task: max, mean loss: 1.72260, accuracy: 0.29800, task: top, mean loss: 2.03395, accuracy: 0.23400, task: multi, mean loss: 0.56506, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.56050, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.13582, Variance: 0.13137
Semantic Loss - Mean: 1.60123, Variance: 0.00102

Test Epoch: 22 
task: majority, mean loss: 2.42107, accuracy: 0.20500, task: max, mean loss: 1.93426, accuracy: 0.25200, task: top, mean loss: 2.42105, accuracy: 0.16100, task: multi, mean loss: 0.62129, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.84942
Diversity Loss - Mean: -0.13889, Variance: 0.14087
Semantic Loss - Mean: 1.81279, Variance: 0.00108

Train Epoch: 23 
task: majority, mean loss: 1.87902, accuracy: 0.31700, task: max, mean loss: 1.71252, accuracy: 0.28500, task: top, mean loss: 2.00661, accuracy: 0.24900, task: multi, mean loss: 0.55987, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.53950, lr: 0.000949447626126434
Diversity Loss - Mean: -0.13510, Variance: 0.13115
Semantic Loss - Mean: 1.59085, Variance: 0.00104

Test Epoch: 23 
task: majority, mean loss: 2.64472, accuracy: 0.15800, task: max, mean loss: 2.01529, accuracy: 0.20400, task: top, mean loss: 2.37391, accuracy: 0.20800, task: multi, mean loss: 0.64997, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.92097
Diversity Loss - Mean: -0.13805, Variance: 0.13996
Semantic Loss - Mean: 1.85242, Variance: 0.00113

Train Epoch: 24 
task: majority, mean loss: 1.87283, accuracy: 0.30700, task: max, mean loss: 1.70241, accuracy: 0.30900, task: top, mean loss: 1.96768, accuracy: 0.27100, task: multi, mean loss: 0.55645, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.52484, lr: 0.000941532322633034
Diversity Loss - Mean: -0.13259, Variance: 0.13084
Semantic Loss - Mean: 1.57561, Variance: 0.00106

Test Epoch: 24 
task: majority, mean loss: 2.25485, accuracy: 0.22000, task: max, mean loss: 1.74696, accuracy: 0.30600, task: top, mean loss: 2.26509, accuracy: 0.19100, task: multi, mean loss: 0.57958, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71162
Diversity Loss - Mean: -0.12291, Variance: 0.13928
Semantic Loss - Mean: 1.69719, Variance: 0.00116

Train Epoch: 25 
task: majority, mean loss: 1.87890, accuracy: 0.31300, task: max, mean loss: 1.70502, accuracy: 0.30100, task: top, mean loss: 1.95341, accuracy: 0.27900, task: multi, mean loss: 0.55599, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.52333, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.13221, Variance: 0.13051
Semantic Loss - Mean: 1.57449, Variance: 0.00109

Test Epoch: 25 
task: majority, mean loss: 2.48235, accuracy: 0.22700, task: max, mean loss: 1.91949, accuracy: 0.28200, task: top, mean loss: 2.40612, accuracy: 0.20700, task: multi, mean loss: 0.62736, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.85883
Diversity Loss - Mean: -0.13304, Variance: 0.13822
Semantic Loss - Mean: 1.81888, Variance: 0.00117

Train Epoch: 26 
task: majority, mean loss: 1.76824, accuracy: 0.34200, task: max, mean loss: 1.68938, accuracy: 0.30200, task: top, mean loss: 1.85816, accuracy: 0.33000, task: multi, mean loss: 0.54568, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.46537, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.13046, Variance: 0.12975
Semantic Loss - Mean: 1.52684, Variance: 0.00111

Test Epoch: 26 
task: majority, mean loss: 1.94601, accuracy: 0.29500, task: max, mean loss: 1.74960, accuracy: 0.30400, task: top, mean loss: 2.01417, accuracy: 0.28400, task: multi, mean loss: 0.56000, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.56744
Diversity Loss - Mean: -0.13563, Variance: 0.13826
Semantic Loss - Mean: 1.63829, Variance: 0.00118

Train Epoch: 27 
task: majority, mean loss: 1.78225, accuracy: 0.33200, task: max, mean loss: 1.69610, accuracy: 0.30700, task: top, mean loss: 1.87451, accuracy: 0.32600, task: multi, mean loss: 0.55594, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.47720, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.12735, Variance: 0.12906
Semantic Loss - Mean: 1.55266, Variance: 0.00115

Test Epoch: 27 
task: majority, mean loss: 2.06393, accuracy: 0.27700, task: max, mean loss: 1.74116, accuracy: 0.28400, task: top, mean loss: 2.07370, accuracy: 0.26700, task: multi, mean loss: 0.56888, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.61192
Diversity Loss - Mean: -0.11943, Variance: 0.13716
Semantic Loss - Mean: 1.62523, Variance: 0.00118

Train Epoch: 28 
task: majority, mean loss: 1.72747, accuracy: 0.37800, task: max, mean loss: 1.65681, accuracy: 0.34600, task: top, mean loss: 1.84609, accuracy: 0.33600, task: multi, mean loss: 0.54797, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.44458, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.12694, Variance: 0.12827
Semantic Loss - Mean: 1.51730, Variance: 0.00118

Test Epoch: 28 
task: majority, mean loss: 1.90571, accuracy: 0.30500, task: max, mean loss: 1.73881, accuracy: 0.30900, task: top, mean loss: 2.04828, accuracy: 0.26600, task: multi, mean loss: 0.54649, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.55982
Diversity Loss - Mean: -0.13212, Variance: 0.13635
Semantic Loss - Mean: 1.58381, Variance: 0.00120

Train Epoch: 29 
task: majority, mean loss: 1.73492, accuracy: 0.37900, task: max, mean loss: 1.65581, accuracy: 0.34600, task: top, mean loss: 1.82432, accuracy: 0.32500, task: multi, mean loss: 0.54778, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.44071, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.12826, Variance: 0.12762
Semantic Loss - Mean: 1.52589, Variance: 0.00122

Test Epoch: 29 
task: majority, mean loss: 1.86933, accuracy: 0.28800, task: max, mean loss: 1.73010, accuracy: 0.32700, task: top, mean loss: 1.99682, accuracy: 0.29800, task: multi, mean loss: 0.55040, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.53666
Diversity Loss - Mean: -0.13130, Variance: 0.13553
Semantic Loss - Mean: 1.57462, Variance: 0.00119

Train Epoch: 30 
task: majority, mean loss: 1.62651, accuracy: 0.39400, task: max, mean loss: 1.59255, accuracy: 0.38400, task: top, mean loss: 1.73780, accuracy: 0.37700, task: multi, mean loss: 0.53709, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.37349, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.12885, Variance: 0.12668
Semantic Loss - Mean: 1.45695, Variance: 0.00124

Test Epoch: 30 
task: majority, mean loss: 1.91602, accuracy: 0.26700, task: max, mean loss: 1.63562, accuracy: 0.38200, task: top, mean loss: 1.99746, accuracy: 0.25500, task: multi, mean loss: 0.55728, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.52660
Diversity Loss - Mean: -0.13274, Variance: 0.13473
Semantic Loss - Mean: 1.60302, Variance: 0.00124

Train Epoch: 31 
task: majority, mean loss: 1.56239, accuracy: 0.40400, task: max, mean loss: 1.54687, accuracy: 0.41200, task: top, mean loss: 1.69497, accuracy: 0.37600, task: multi, mean loss: 0.53978, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.33600, lr: 0.0008717008403259585
Diversity Loss - Mean: -0.12352, Variance: 0.12565
Semantic Loss - Mean: 1.44706, Variance: 0.00130

Test Epoch: 31 
task: majority, mean loss: 2.41146, accuracy: 0.24900, task: max, mean loss: 1.84919, accuracy: 0.27200, task: top, mean loss: 2.06027, accuracy: 0.26600, task: multi, mean loss: 0.59530, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.72906
Diversity Loss - Mean: -0.11497, Variance: 0.13352
Semantic Loss - Mean: 1.71992, Variance: 0.00139

Train Epoch: 32 
task: majority, mean loss: 1.52676, accuracy: 0.42600, task: max, mean loss: 1.48985, accuracy: 0.43600, task: top, mean loss: 1.65192, accuracy: 0.41000, task: multi, mean loss: 0.53351, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.30051, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.12463, Variance: 0.12468
Semantic Loss - Mean: 1.41488, Variance: 0.00138

Test Epoch: 32 
task: majority, mean loss: 2.64929, accuracy: 0.18900, task: max, mean loss: 2.18771, accuracy: 0.18600, task: top, mean loss: 2.35686, accuracy: 0.17800, task: multi, mean loss: 0.63975, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.95840
Diversity Loss - Mean: -0.11040, Variance: 0.13200
Semantic Loss - Mean: 1.83029, Variance: 0.00148

Train Epoch: 33 
task: majority, mean loss: 1.43774, accuracy: 0.46300, task: max, mean loss: 1.41346, accuracy: 0.45100, task: top, mean loss: 1.54620, accuracy: 0.43400, task: multi, mean loss: 0.52258, multilabel_accuracy: 0.01700, avg. loss over tasks: 1.23000, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.12244, Variance: 0.12363
Semantic Loss - Mean: 1.34421, Variance: 0.00143

Test Epoch: 33 
task: majority, mean loss: 2.84518, accuracy: 0.21400, task: max, mean loss: 1.73728, accuracy: 0.35800, task: top, mean loss: 2.34642, accuracy: 0.27000, task: multi, mean loss: 0.63629, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.89129
Diversity Loss - Mean: -0.12037, Variance: 0.13052
Semantic Loss - Mean: 1.82030, Variance: 0.00187

Train Epoch: 34 
task: majority, mean loss: 1.32196, accuracy: 0.51200, task: max, mean loss: 1.34423, accuracy: 0.49600, task: top, mean loss: 1.41549, accuracy: 0.49300, task: multi, mean loss: 0.51636, multilabel_accuracy: 0.02700, avg. loss over tasks: 1.14951, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.12270, Variance: 0.12253
Semantic Loss - Mean: 1.27826, Variance: 0.00149

Test Epoch: 34 
task: majority, mean loss: 2.45874, accuracy: 0.29300, task: max, mean loss: 1.89207, accuracy: 0.35300, task: top, mean loss: 2.14085, accuracy: 0.33400, task: multi, mean loss: 0.59969, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.77284
Diversity Loss - Mean: -0.12010, Variance: 0.12879
Semantic Loss - Mean: 1.70241, Variance: 0.00195

Train Epoch: 35 
task: majority, mean loss: 1.31256, accuracy: 0.50900, task: max, mean loss: 1.31115, accuracy: 0.53600, task: top, mean loss: 1.41122, accuracy: 0.49200, task: multi, mean loss: 0.51720, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.13803, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.12209, Variance: 0.12144
Semantic Loss - Mean: 1.25954, Variance: 0.00155

Test Epoch: 35 
task: majority, mean loss: 1.73661, accuracy: 0.35900, task: max, mean loss: 1.49226, accuracy: 0.45200, task: top, mean loss: 1.68075, accuracy: 0.41600, task: multi, mean loss: 0.53858, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.36205
Diversity Loss - Mean: -0.12371, Variance: 0.12728
Semantic Loss - Mean: 1.40775, Variance: 0.00201

Train Epoch: 36 
task: majority, mean loss: 1.34754, accuracy: 0.49100, task: max, mean loss: 1.30438, accuracy: 0.53600, task: top, mean loss: 1.37054, accuracy: 0.51100, task: multi, mean loss: 0.51746, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.13498, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.12262, Variance: 0.12034
Semantic Loss - Mean: 1.25506, Variance: 0.00164

Test Epoch: 36 
task: majority, mean loss: 2.50592, accuracy: 0.28700, task: max, mean loss: 1.66752, accuracy: 0.36100, task: top, mean loss: 2.22492, accuracy: 0.27800, task: multi, mean loss: 0.59518, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.74839
Diversity Loss - Mean: -0.11046, Variance: 0.12608
Semantic Loss - Mean: 1.87122, Variance: 0.00211

Train Epoch: 37 
task: majority, mean loss: 1.24226, accuracy: 0.51900, task: max, mean loss: 1.21549, accuracy: 0.57100, task: top, mean loss: 1.29161, accuracy: 0.52900, task: multi, mean loss: 0.51010, multilabel_accuracy: 0.02400, avg. loss over tasks: 1.06487, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.11984, Variance: 0.11934
Semantic Loss - Mean: 1.20484, Variance: 0.00170

Test Epoch: 37 
task: majority, mean loss: 1.59369, accuracy: 0.42600, task: max, mean loss: 1.29969, accuracy: 0.51800, task: top, mean loss: 1.58358, accuracy: 0.43500, task: multi, mean loss: 0.52475, multilabel_accuracy: 0.02000, avg. loss over tasks: 1.25043
Diversity Loss - Mean: -0.12368, Variance: 0.12467
Semantic Loss - Mean: 1.29641, Variance: 0.00210

Train Epoch: 38 
task: majority, mean loss: 1.09361, accuracy: 0.58300, task: max, mean loss: 1.17107, accuracy: 0.59200, task: top, mean loss: 1.15919, accuracy: 0.58000, task: multi, mean loss: 0.50490, multilabel_accuracy: 0.03000, avg. loss over tasks: 0.98219, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.12261, Variance: 0.11830
Semantic Loss - Mean: 1.12124, Variance: 0.00176

Test Epoch: 38 
task: majority, mean loss: 1.90733, accuracy: 0.39000, task: max, mean loss: 1.30098, accuracy: 0.53700, task: top, mean loss: 1.81645, accuracy: 0.39400, task: multi, mean loss: 0.54401, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.39219
Diversity Loss - Mean: -0.12600, Variance: 0.12396
Semantic Loss - Mean: 1.33037, Variance: 0.00211

Train Epoch: 39 
task: majority, mean loss: 1.12444, accuracy: 0.56500, task: max, mean loss: 1.12925, accuracy: 0.60600, task: top, mean loss: 1.16634, accuracy: 0.58600, task: multi, mean loss: 0.50452, multilabel_accuracy: 0.03200, avg. loss over tasks: 0.98114, lr: 0.000765194672484486
Diversity Loss - Mean: -0.12426, Variance: 0.11734
Semantic Loss - Mean: 1.11944, Variance: 0.00183

Test Epoch: 39 
task: majority, mean loss: 1.95030, accuracy: 0.34700, task: max, mean loss: 1.33199, accuracy: 0.50300, task: top, mean loss: 1.98336, accuracy: 0.36600, task: multi, mean loss: 0.54118, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.45171
Diversity Loss - Mean: -0.12636, Variance: 0.12318
Semantic Loss - Mean: 1.56985, Variance: 0.00218

Train Epoch: 40 
task: majority, mean loss: 1.02711, accuracy: 0.59400, task: max, mean loss: 1.05092, accuracy: 0.63300, task: top, mean loss: 1.05443, accuracy: 0.62700, task: multi, mean loss: 0.49877, multilabel_accuracy: 0.03700, avg. loss over tasks: 0.90781, lr: 0.00075025
Diversity Loss - Mean: -0.12503, Variance: 0.11639
Semantic Loss - Mean: 1.06805, Variance: 0.00192

Test Epoch: 40 
task: majority, mean loss: 1.61501, accuracy: 0.45400, task: max, mean loss: 1.29486, accuracy: 0.56000, task: top, mean loss: 1.61343, accuracy: 0.44800, task: multi, mean loss: 0.52717, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.26262
Diversity Loss - Mean: -0.12912, Variance: 0.12215
Semantic Loss - Mean: 1.26519, Variance: 0.00222

Train Epoch: 41 
task: majority, mean loss: 1.01610, accuracy: 0.60700, task: max, mean loss: 1.03564, accuracy: 0.63800, task: top, mean loss: 1.01569, accuracy: 0.63100, task: multi, mean loss: 0.49301, multilabel_accuracy: 0.03800, avg. loss over tasks: 0.89011, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.12582, Variance: 0.11549
Semantic Loss - Mean: 1.03897, Variance: 0.00198

Test Epoch: 41 
task: majority, mean loss: 1.75245, accuracy: 0.42300, task: max, mean loss: 1.14349, accuracy: 0.58400, task: top, mean loss: 1.48752, accuracy: 0.51700, task: multi, mean loss: 0.52117, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.22616
Diversity Loss - Mean: -0.12873, Variance: 0.12110
Semantic Loss - Mean: 1.28943, Variance: 0.00225

Train Epoch: 42 
task: majority, mean loss: 0.91430, accuracy: 0.63200, task: max, mean loss: 0.95183, accuracy: 0.67500, task: top, mean loss: 0.94169, accuracy: 0.66800, task: multi, mean loss: 0.48965, multilabel_accuracy: 0.02700, avg. loss over tasks: 0.82437, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.12646, Variance: 0.11468
Semantic Loss - Mean: 0.98020, Variance: 0.00206

Test Epoch: 42 
task: majority, mean loss: 2.03672, accuracy: 0.37900, task: max, mean loss: 1.57002, accuracy: 0.48700, task: top, mean loss: 1.75180, accuracy: 0.42400, task: multi, mean loss: 0.57572, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.48356
Diversity Loss - Mean: -0.13291, Variance: 0.12030
Semantic Loss - Mean: 1.41691, Variance: 0.00224

Train Epoch: 43 
task: majority, mean loss: 0.91418, accuracy: 0.64000, task: max, mean loss: 0.91889, accuracy: 0.68600, task: top, mean loss: 0.93810, accuracy: 0.66700, task: multi, mean loss: 0.48432, multilabel_accuracy: 0.04100, avg. loss over tasks: 0.81387, lr: 0.0007036649532163622
Diversity Loss - Mean: -0.12634, Variance: 0.11384
Semantic Loss - Mean: 0.97488, Variance: 0.00214

Test Epoch: 43 
task: majority, mean loss: 2.23392, accuracy: 0.32900, task: max, mean loss: 1.35860, accuracy: 0.49600, task: top, mean loss: 2.20426, accuracy: 0.36800, task: multi, mean loss: 0.53324, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.58250
Diversity Loss - Mean: -0.12832, Variance: 0.11947
Semantic Loss - Mean: 1.64547, Variance: 0.00238

Train Epoch: 44 
task: majority, mean loss: 0.93289, accuracy: 0.64800, task: max, mean loss: 0.95041, accuracy: 0.65900, task: top, mean loss: 0.90251, accuracy: 0.67400, task: multi, mean loss: 0.48430, multilabel_accuracy: 0.03800, avg. loss over tasks: 0.81753, lr: 0.000687615993411248
Diversity Loss - Mean: -0.12718, Variance: 0.11308
Semantic Loss - Mean: 0.98600, Variance: 0.00221

Test Epoch: 44 
task: majority, mean loss: 2.01863, accuracy: 0.36100, task: max, mean loss: 1.65307, accuracy: 0.47400, task: top, mean loss: 1.57181, accuracy: 0.48800, task: multi, mean loss: 0.56092, multilabel_accuracy: 0.02300, avg. loss over tasks: 1.45110
Diversity Loss - Mean: -0.13019, Variance: 0.11842
Semantic Loss - Mean: 1.38520, Variance: 0.00240

Train Epoch: 45 
task: majority, mean loss: 0.85997, accuracy: 0.66300, task: max, mean loss: 0.82611, accuracy: 0.72000, task: top, mean loss: 0.75676, accuracy: 0.72200, task: multi, mean loss: 0.47567, multilabel_accuracy: 0.04700, avg. loss over tasks: 0.72963, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.12663, Variance: 0.11233
Semantic Loss - Mean: 0.90438, Variance: 0.00228

Test Epoch: 45 
task: majority, mean loss: 1.22373, accuracy: 0.56900, task: max, mean loss: 1.05672, accuracy: 0.62700, task: top, mean loss: 1.19850, accuracy: 0.61400, task: multi, mean loss: 0.47945, multilabel_accuracy: 0.02500, avg. loss over tasks: 0.98960
Diversity Loss - Mean: -0.13333, Variance: 0.11777
Semantic Loss - Mean: 1.00891, Variance: 0.00241

Train Epoch: 46 
task: majority, mean loss: 0.75934, accuracy: 0.71700, task: max, mean loss: 0.74434, accuracy: 0.73700, task: top, mean loss: 0.66113, accuracy: 0.77100, task: multi, mean loss: 0.45872, multilabel_accuracy: 0.04500, avg. loss over tasks: 0.65588, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.12692, Variance: 0.11162
Semantic Loss - Mean: 0.83997, Variance: 0.00236

Test Epoch: 46 
task: majority, mean loss: 1.38701, accuracy: 0.53200, task: max, mean loss: 1.41098, accuracy: 0.57200, task: top, mean loss: 1.21695, accuracy: 0.61500, task: multi, mean loss: 0.50349, multilabel_accuracy: 0.02900, avg. loss over tasks: 1.12961
Diversity Loss - Mean: -0.13261, Variance: 0.11692
Semantic Loss - Mean: 1.14265, Variance: 0.00244

Train Epoch: 47 
task: majority, mean loss: 0.75810, accuracy: 0.72200, task: max, mean loss: 0.78321, accuracy: 0.74000, task: top, mean loss: 0.62212, accuracy: 0.78400, task: multi, mean loss: 0.46087, multilabel_accuracy: 0.03300, avg. loss over tasks: 0.65608, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.12696, Variance: 0.11095
Semantic Loss - Mean: 0.83529, Variance: 0.00243

Test Epoch: 47 
task: majority, mean loss: 1.07059, accuracy: 0.61800, task: max, mean loss: 1.00006, accuracy: 0.66700, task: top, mean loss: 1.13924, accuracy: 0.66100, task: multi, mean loss: 0.46067, multilabel_accuracy: 0.03500, avg. loss over tasks: 0.91764
Diversity Loss - Mean: -0.13369, Variance: 0.11626
Semantic Loss - Mean: 0.95191, Variance: 0.00244

Train Epoch: 48 
task: majority, mean loss: 0.74601, accuracy: 0.71800, task: max, mean loss: 0.70110, accuracy: 0.76300, task: top, mean loss: 0.62617, accuracy: 0.78100, task: multi, mean loss: 0.45361, multilabel_accuracy: 0.03700, avg. loss over tasks: 0.63172, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.12665, Variance: 0.11031
Semantic Loss - Mean: 0.82398, Variance: 0.00253

Test Epoch: 48 
task: majority, mean loss: 1.08414, accuracy: 0.61600, task: max, mean loss: 1.00951, accuracy: 0.66200, task: top, mean loss: 1.19216, accuracy: 0.63000, task: multi, mean loss: 0.45794, multilabel_accuracy: 0.02900, avg. loss over tasks: 0.93594
Diversity Loss - Mean: -0.13528, Variance: 0.11569
Semantic Loss - Mean: 0.95806, Variance: 0.00244

Train Epoch: 49 
task: majority, mean loss: 0.69161, accuracy: 0.74500, task: max, mean loss: 0.67097, accuracy: 0.76200, task: top, mean loss: 0.58572, accuracy: 0.79300, task: multi, mean loss: 0.44883, multilabel_accuracy: 0.03600, avg. loss over tasks: 0.59928, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.12707, Variance: 0.10972
Semantic Loss - Mean: 0.78324, Variance: 0.00259

Test Epoch: 49 
task: majority, mean loss: 1.37876, accuracy: 0.57400, task: max, mean loss: 1.01321, accuracy: 0.64500, task: top, mean loss: 1.41027, accuracy: 0.62200, task: multi, mean loss: 0.46812, multilabel_accuracy: 0.03200, avg. loss over tasks: 1.06759
Diversity Loss - Mean: -0.13560, Variance: 0.11526
Semantic Loss - Mean: 1.09156, Variance: 0.00248

Train Epoch: 50 
task: majority, mean loss: 0.64119, accuracy: 0.76300, task: max, mean loss: 0.62007, accuracy: 0.79100, task: top, mean loss: 0.48631, accuracy: 0.82900, task: multi, mean loss: 0.44565, multilabel_accuracy: 0.04000, avg. loss over tasks: 0.54830, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.12715, Variance: 0.10912
Semantic Loss - Mean: 0.73791, Variance: 0.00268

Test Epoch: 50 
task: majority, mean loss: 1.55978, accuracy: 0.51000, task: max, mean loss: 1.31605, accuracy: 0.59000, task: top, mean loss: 1.42852, accuracy: 0.59900, task: multi, mean loss: 0.50033, multilabel_accuracy: 0.02500, avg. loss over tasks: 1.20117
Diversity Loss - Mean: -0.13535, Variance: 0.11503
Semantic Loss - Mean: 1.21146, Variance: 0.00250

Train Epoch: 51 
task: majority, mean loss: 0.59655, accuracy: 0.78800, task: max, mean loss: 0.59342, accuracy: 0.79800, task: top, mean loss: 0.38870, accuracy: 0.87300, task: multi, mean loss: 0.43910, multilabel_accuracy: 0.04100, avg. loss over tasks: 0.50444, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.12728, Variance: 0.10857
Semantic Loss - Mean: 0.69880, Variance: 0.00275

Test Epoch: 51 
task: majority, mean loss: 1.61946, accuracy: 0.48000, task: max, mean loss: 1.35273, accuracy: 0.60900, task: top, mean loss: 1.48182, accuracy: 0.58400, task: multi, mean loss: 0.50074, multilabel_accuracy: 0.03100, avg. loss over tasks: 1.23869
Diversity Loss - Mean: -0.13470, Variance: 0.11426
Semantic Loss - Mean: 1.17563, Variance: 0.00254

Train Epoch: 52 
task: majority, mean loss: 0.57042, accuracy: 0.79800, task: max, mean loss: 0.56923, accuracy: 0.81000, task: top, mean loss: 0.40764, accuracy: 0.87500, task: multi, mean loss: 0.43728, multilabel_accuracy: 0.04200, avg. loss over tasks: 0.49614, lr: 0.0005527119674021931
Diversity Loss - Mean: -0.12814, Variance: 0.10807
Semantic Loss - Mean: 0.67501, Variance: 0.00285

Test Epoch: 52 
task: majority, mean loss: 1.15585, accuracy: 0.59700, task: max, mean loss: 1.28454, accuracy: 0.58000, task: top, mean loss: 1.19140, accuracy: 0.66400, task: multi, mean loss: 0.48935, multilabel_accuracy: 0.03000, avg. loss over tasks: 1.03029
Diversity Loss - Mean: -0.13600, Variance: 0.11364
Semantic Loss - Mean: 1.01567, Variance: 0.00256

Train Epoch: 53 
task: majority, mean loss: 0.48672, accuracy: 0.81400, task: max, mean loss: 0.50276, accuracy: 0.81800, task: top, mean loss: 0.30292, accuracy: 0.90500, task: multi, mean loss: 0.43096, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.43084, lr: 0.0005353433586351905
Diversity Loss - Mean: -0.12755, Variance: 0.10760
Semantic Loss - Mean: 0.62700, Variance: 0.00291

Test Epoch: 53 
task: majority, mean loss: 1.03347, accuracy: 0.66300, task: max, mean loss: 1.02181, accuracy: 0.66400, task: top, mean loss: 1.22498, accuracy: 0.69800, task: multi, mean loss: 0.44671, multilabel_accuracy: 0.02600, avg. loss over tasks: 0.93175
Diversity Loss - Mean: -0.13671, Variance: 0.11332
Semantic Loss - Mean: 0.93145, Variance: 0.00258

Train Epoch: 54 
task: majority, mean loss: 0.55772, accuracy: 0.78900, task: max, mean loss: 0.58032, accuracy: 0.80100, task: top, mean loss: 0.44008, accuracy: 0.86700, task: multi, mean loss: 0.43568, multilabel_accuracy: 0.04300, avg. loss over tasks: 0.50345, lr: 0.0005179322986028993
Diversity Loss - Mean: -0.12760, Variance: 0.10715
Semantic Loss - Mean: 0.68447, Variance: 0.00301

Test Epoch: 54 
task: majority, mean loss: 1.56073, accuracy: 0.53300, task: max, mean loss: 1.14603, accuracy: 0.65000, task: top, mean loss: 1.52602, accuracy: 0.61900, task: multi, mean loss: 0.47350, multilabel_accuracy: 0.03400, avg. loss over tasks: 1.17657
Diversity Loss - Mean: -0.13657, Variance: 0.11288
Semantic Loss - Mean: 1.09287, Variance: 0.00262

Train Epoch: 55 
task: majority, mean loss: 0.51785, accuracy: 0.80600, task: max, mean loss: 0.56038, accuracy: 0.81500, task: top, mean loss: 0.31650, accuracy: 0.90100, task: multi, mean loss: 0.42777, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.45563, lr: 0.0005005
Diversity Loss - Mean: -0.12855, Variance: 0.10674
Semantic Loss - Mean: 0.64611, Variance: 0.00308

Test Epoch: 55 
task: majority, mean loss: 1.72844, accuracy: 0.51500, task: max, mean loss: 1.10724, accuracy: 0.64700, task: top, mean loss: 1.28177, accuracy: 0.66500, task: multi, mean loss: 0.47560, multilabel_accuracy: 0.02500, avg. loss over tasks: 1.14826
Diversity Loss - Mean: -0.13699, Variance: 0.11258
Semantic Loss - Mean: 1.09694, Variance: 0.00266

Train Epoch: 56 
task: majority, mean loss: 0.44391, accuracy: 0.84000, task: max, mean loss: 0.44763, accuracy: 0.86100, task: top, mean loss: 0.24737, accuracy: 0.92300, task: multi, mean loss: 0.42055, multilabel_accuracy: 0.04700, avg. loss over tasks: 0.38986, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.12829, Variance: 0.10634
Semantic Loss - Mean: 0.57756, Variance: 0.00314

Test Epoch: 56 
task: majority, mean loss: 1.09283, accuracy: 0.66700, task: max, mean loss: 0.99785, accuracy: 0.68000, task: top, mean loss: 1.21722, accuracy: 0.68800, task: multi, mean loss: 0.44285, multilabel_accuracy: 0.03200, avg. loss over tasks: 0.93769
Diversity Loss - Mean: -0.13633, Variance: 0.11231
Semantic Loss - Mean: 0.93816, Variance: 0.00269

Train Epoch: 57 
task: majority, mean loss: 0.41764, accuracy: 0.85500, task: max, mean loss: 0.42686, accuracy: 0.86600, task: top, mean loss: 0.21230, accuracy: 0.94200, task: multi, mean loss: 0.42013, multilabel_accuracy: 0.05500, avg. loss over tasks: 0.36923, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.12801, Variance: 0.10595
Semantic Loss - Mean: 0.55212, Variance: 0.00319

Test Epoch: 57 
task: majority, mean loss: 1.07834, accuracy: 0.65700, task: max, mean loss: 1.04496, accuracy: 0.68600, task: top, mean loss: 1.12127, accuracy: 0.70300, task: multi, mean loss: 0.44766, multilabel_accuracy: 0.03500, avg. loss over tasks: 0.92306
Diversity Loss - Mean: -0.13679, Variance: 0.11193
Semantic Loss - Mean: 0.90307, Variance: 0.00271

Train Epoch: 58 
task: majority, mean loss: 0.35230, accuracy: 0.88100, task: max, mean loss: 0.38741, accuracy: 0.88200, task: top, mean loss: 0.14713, accuracy: 0.96600, task: multi, mean loss: 0.41304, multilabel_accuracy: 0.03700, avg. loss over tasks: 0.32497, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.12842, Variance: 0.10556
Semantic Loss - Mean: 0.50458, Variance: 0.00324

Test Epoch: 58 
task: majority, mean loss: 1.23413, accuracy: 0.65400, task: max, mean loss: 1.01132, accuracy: 0.70400, task: top, mean loss: 1.23076, accuracy: 0.71600, task: multi, mean loss: 0.44679, multilabel_accuracy: 0.03200, avg. loss over tasks: 0.98075
Diversity Loss - Mean: -0.13688, Variance: 0.11178
Semantic Loss - Mean: 0.98065, Variance: 0.00275

Train Epoch: 59 
task: majority, mean loss: 0.31789, accuracy: 0.89200, task: max, mean loss: 0.34306, accuracy: 0.89400, task: top, mean loss: 0.12008, accuracy: 0.97000, task: multi, mean loss: 0.40868, multilabel_accuracy: 0.04700, avg. loss over tasks: 0.29743, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.12864, Variance: 0.10521
Semantic Loss - Mean: 0.47069, Variance: 0.00327

Test Epoch: 59 
task: majority, mean loss: 1.17569, accuracy: 0.65900, task: max, mean loss: 1.20387, accuracy: 0.66200, task: top, mean loss: 1.17170, accuracy: 0.71700, task: multi, mean loss: 0.45738, multilabel_accuracy: 0.03200, avg. loss over tasks: 1.00216
Diversity Loss - Mean: -0.13724, Variance: 0.11163
Semantic Loss - Mean: 1.00284, Variance: 0.00277

Train Epoch: 60 
task: majority, mean loss: 0.26383, accuracy: 0.91500, task: max, mean loss: 0.31700, accuracy: 0.90100, task: top, mean loss: 0.10490, accuracy: 0.97600, task: multi, mean loss: 0.40318, multilabel_accuracy: 0.04500, avg. loss over tasks: 0.27223, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.12786, Variance: 0.10488
Semantic Loss - Mean: 0.46501, Variance: 0.00333

Test Epoch: 60 
task: majority, mean loss: 0.99920, accuracy: 0.71200, task: max, mean loss: 1.02086, accuracy: 0.71100, task: top, mean loss: 1.19074, accuracy: 0.71600, task: multi, mean loss: 0.42793, multilabel_accuracy: 0.04300, avg. loss over tasks: 0.90968
Diversity Loss - Mean: -0.13730, Variance: 0.11135
Semantic Loss - Mean: 0.89312, Variance: 0.00279

Train Epoch: 61 
task: majority, mean loss: 0.26198, accuracy: 0.90600, task: max, mean loss: 0.29787, accuracy: 0.90700, task: top, mean loss: 0.12544, accuracy: 0.96800, task: multi, mean loss: 0.40426, multilabel_accuracy: 0.05200, avg. loss over tasks: 0.27239, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.12846, Variance: 0.10456
Semantic Loss - Mean: 0.45463, Variance: 0.00337

Test Epoch: 61 
task: majority, mean loss: 1.11938, accuracy: 0.66700, task: max, mean loss: 1.11379, accuracy: 0.68700, task: top, mean loss: 1.15089, accuracy: 0.72000, task: multi, mean loss: 0.44394, multilabel_accuracy: 0.04200, avg. loss over tasks: 0.95700
Diversity Loss - Mean: -0.13712, Variance: 0.11099
Semantic Loss - Mean: 0.93406, Variance: 0.00282

Train Epoch: 62 
task: majority, mean loss: 0.22785, accuracy: 0.92000, task: max, mean loss: 0.28237, accuracy: 0.91700, task: top, mean loss: 0.09749, accuracy: 0.97300, task: multi, mean loss: 0.39679, multilabel_accuracy: 0.06600, avg. loss over tasks: 0.25113, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.12900, Variance: 0.10428
Semantic Loss - Mean: 0.42492, Variance: 0.00342

Test Epoch: 62 
task: majority, mean loss: 1.66047, accuracy: 0.58400, task: max, mean loss: 1.21454, accuracy: 0.67200, task: top, mean loss: 1.44271, accuracy: 0.68500, task: multi, mean loss: 0.46491, multilabel_accuracy: 0.03200, avg. loss over tasks: 1.19566
Diversity Loss - Mean: -0.13768, Variance: 0.11085
Semantic Loss - Mean: 1.17900, Variance: 0.00291

Train Epoch: 63 
task: majority, mean loss: 0.19549, accuracy: 0.93200, task: max, mean loss: 0.25987, accuracy: 0.92500, task: top, mean loss: 0.08400, accuracy: 0.97900, task: multi, mean loss: 0.39512, multilabel_accuracy: 0.06600, avg. loss over tasks: 0.23362, lr: 0.00036281914076940884
Diversity Loss - Mean: -0.12871, Variance: 0.10401
Semantic Loss - Mean: 0.40767, Variance: 0.00345

Test Epoch: 63 
task: majority, mean loss: 1.58512, accuracy: 0.61800, task: max, mean loss: 1.22342, accuracy: 0.67100, task: top, mean loss: 1.43210, accuracy: 0.70600, task: multi, mean loss: 0.47271, multilabel_accuracy: 0.03300, avg. loss over tasks: 1.17834
Diversity Loss - Mean: -0.13766, Variance: 0.11075
Semantic Loss - Mean: 1.11920, Variance: 0.00296

Train Epoch: 64 
task: majority, mean loss: 0.23175, accuracy: 0.91400, task: max, mean loss: 0.26266, accuracy: 0.91500, task: top, mean loss: 0.06492, accuracy: 0.98400, task: multi, mean loss: 0.39516, multilabel_accuracy: 0.06200, avg. loss over tasks: 0.23862, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.12827, Variance: 0.10376
Semantic Loss - Mean: 0.40839, Variance: 0.00350

Test Epoch: 64 
task: majority, mean loss: 1.13703, accuracy: 0.68100, task: max, mean loss: 1.29364, accuracy: 0.68400, task: top, mean loss: 1.18142, accuracy: 0.73500, task: multi, mean loss: 0.45328, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.01634
Diversity Loss - Mean: -0.13781, Variance: 0.11053
Semantic Loss - Mean: 0.97629, Variance: 0.00297

Train Epoch: 65 
task: majority, mean loss: 0.17728, accuracy: 0.93500, task: max, mean loss: 0.22801, accuracy: 0.93000, task: top, mean loss: 0.04577, accuracy: 0.99500, task: multi, mean loss: 0.39482, multilabel_accuracy: 0.06700, avg. loss over tasks: 0.21147, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.12910, Variance: 0.10354
Semantic Loss - Mean: 0.38381, Variance: 0.00353

Test Epoch: 65 
task: majority, mean loss: 1.00435, accuracy: 0.70300, task: max, mean loss: 1.11291, accuracy: 0.69300, task: top, mean loss: 1.20261, accuracy: 0.74100, task: multi, mean loss: 0.42638, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.93656
Diversity Loss - Mean: -0.13813, Variance: 0.11042
Semantic Loss - Mean: 0.89976, Variance: 0.00299

Train Epoch: 66 
task: majority, mean loss: 0.16601, accuracy: 0.94100, task: max, mean loss: 0.19613, accuracy: 0.94100, task: top, mean loss: 0.05001, accuracy: 0.99000, task: multi, mean loss: 0.38754, multilabel_accuracy: 0.07000, avg. loss over tasks: 0.19992, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.12932, Variance: 0.10334
Semantic Loss - Mean: 0.36665, Variance: 0.00356

Test Epoch: 66 
task: majority, mean loss: 1.20800, accuracy: 0.67800, task: max, mean loss: 1.31596, accuracy: 0.68700, task: top, mean loss: 1.36660, accuracy: 0.71700, task: multi, mean loss: 0.46069, multilabel_accuracy: 0.03700, avg. loss over tasks: 1.08781
Diversity Loss - Mean: -0.13844, Variance: 0.11045
Semantic Loss - Mean: 1.02514, Variance: 0.00304

Train Epoch: 67 
task: majority, mean loss: 0.15320, accuracy: 0.95200, task: max, mean loss: 0.20363, accuracy: 0.93700, task: top, mean loss: 0.04025, accuracy: 0.99200, task: multi, mean loss: 0.38691, multilabel_accuracy: 0.06500, avg. loss over tasks: 0.19600, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.12938, Variance: 0.10313
Semantic Loss - Mean: 0.35743, Variance: 0.00358

Test Epoch: 67 
task: majority, mean loss: 1.31718, accuracy: 0.65100, task: max, mean loss: 1.27260, accuracy: 0.67200, task: top, mean loss: 1.22491, accuracy: 0.74200, task: multi, mean loss: 0.44680, multilabel_accuracy: 0.04400, avg. loss over tasks: 1.06538
Diversity Loss - Mean: -0.13815, Variance: 0.11028
Semantic Loss - Mean: 1.03593, Variance: 0.00307

Train Epoch: 68 
task: majority, mean loss: 0.11574, accuracy: 0.96400, task: max, mean loss: 0.17618, accuracy: 0.95100, task: top, mean loss: 0.03235, accuracy: 0.99700, task: multi, mean loss: 0.38520, multilabel_accuracy: 0.07500, avg. loss over tasks: 0.17737, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.12934, Variance: 0.10294
Semantic Loss - Mean: 0.33802, Variance: 0.00359

Test Epoch: 68 
task: majority, mean loss: 1.11697, accuracy: 0.69500, task: max, mean loss: 1.28952, accuracy: 0.68500, task: top, mean loss: 1.22186, accuracy: 0.74200, task: multi, mean loss: 0.43861, multilabel_accuracy: 0.05300, avg. loss over tasks: 1.01674
Diversity Loss - Mean: -0.13840, Variance: 0.11010
Semantic Loss - Mean: 0.97303, Variance: 0.00310

Train Epoch: 69 
task: majority, mean loss: 0.12843, accuracy: 0.95700, task: max, mean loss: 0.16714, accuracy: 0.95600, task: top, mean loss: 0.03578, accuracy: 0.99500, task: multi, mean loss: 0.38109, multilabel_accuracy: 0.07100, avg. loss over tasks: 0.17811, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.12918, Variance: 0.10276
Semantic Loss - Mean: 0.33690, Variance: 0.00361

Test Epoch: 69 
task: majority, mean loss: 1.38683, accuracy: 0.65700, task: max, mean loss: 1.45426, accuracy: 0.65400, task: top, mean loss: 1.20735, accuracy: 0.73900, task: multi, mean loss: 0.45335, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.12545
Diversity Loss - Mean: -0.13835, Variance: 0.10989
Semantic Loss - Mean: 1.08730, Variance: 0.00312

Train Epoch: 70 
task: majority, mean loss: 0.08407, accuracy: 0.97900, task: max, mean loss: 0.16007, accuracy: 0.95600, task: top, mean loss: 0.02316, accuracy: 0.99700, task: multi, mean loss: 0.38156, multilabel_accuracy: 0.07400, avg. loss over tasks: 0.16222, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.12897, Variance: 0.10259
Semantic Loss - Mean: 0.32055, Variance: 0.00363

Test Epoch: 70 
task: majority, mean loss: 1.04449, accuracy: 0.72700, task: max, mean loss: 1.20114, accuracy: 0.71100, task: top, mean loss: 1.22526, accuracy: 0.75100, task: multi, mean loss: 0.42805, multilabel_accuracy: 0.05500, avg. loss over tasks: 0.97473
Diversity Loss - Mean: -0.13868, Variance: 0.10984
Semantic Loss - Mean: 0.92409, Variance: 0.00315

Train Epoch: 71 
task: majority, mean loss: 0.06851, accuracy: 0.98800, task: max, mean loss: 0.14511, accuracy: 0.95300, task: top, mean loss: 0.02228, accuracy: 0.99800, task: multi, mean loss: 0.37608, multilabel_accuracy: 0.06400, avg. loss over tasks: 0.15300, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.13040, Variance: 0.10245
Semantic Loss - Mean: 0.30673, Variance: 0.00364

Test Epoch: 71 
task: majority, mean loss: 1.20505, accuracy: 0.69800, task: max, mean loss: 1.30014, accuracy: 0.68000, task: top, mean loss: 1.27289, accuracy: 0.75700, task: multi, mean loss: 0.43019, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.05207
Diversity Loss - Mean: -0.13868, Variance: 0.10972
Semantic Loss - Mean: 1.00637, Variance: 0.00317

Train Epoch: 72 
task: majority, mean loss: 0.08614, accuracy: 0.97700, task: max, mean loss: 0.12828, accuracy: 0.96400, task: top, mean loss: 0.02315, accuracy: 1.00000, task: multi, mean loss: 0.37670, multilabel_accuracy: 0.08000, avg. loss over tasks: 0.15357, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.13002, Variance: 0.10230
Semantic Loss - Mean: 0.30814, Variance: 0.00365

Test Epoch: 72 
task: majority, mean loss: 1.13224, accuracy: 0.71200, task: max, mean loss: 1.27934, accuracy: 0.69200, task: top, mean loss: 1.22464, accuracy: 0.75400, task: multi, mean loss: 0.43107, multilabel_accuracy: 0.03500, avg. loss over tasks: 1.01682
Diversity Loss - Mean: -0.13879, Variance: 0.10967
Semantic Loss - Mean: 0.95539, Variance: 0.00320

Train Epoch: 73 
task: majority, mean loss: 0.06895, accuracy: 0.98400, task: max, mean loss: 0.10667, accuracy: 0.97000, task: top, mean loss: 0.02018, accuracy: 0.99800, task: multi, mean loss: 0.37379, multilabel_accuracy: 0.07200, avg. loss over tasks: 0.14240, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.12976, Variance: 0.10217
Semantic Loss - Mean: 0.28983, Variance: 0.00366

Test Epoch: 73 
task: majority, mean loss: 1.07631, accuracy: 0.73200, task: max, mean loss: 1.31766, accuracy: 0.68500, task: top, mean loss: 1.24586, accuracy: 0.74900, task: multi, mean loss: 0.42601, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.01646
Diversity Loss - Mean: -0.13894, Variance: 0.10958
Semantic Loss - Mean: 0.96615, Variance: 0.00322

Train Epoch: 74 
task: majority, mean loss: 0.04958, accuracy: 0.99500, task: max, mean loss: 0.09509, accuracy: 0.97800, task: top, mean loss: 0.01995, accuracy: 0.99900, task: multi, mean loss: 0.37190, multilabel_accuracy: 0.07500, avg. loss over tasks: 0.13413, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.12986, Variance: 0.10205
Semantic Loss - Mean: 0.28264, Variance: 0.00367

Test Epoch: 74 
task: majority, mean loss: 1.08395, accuracy: 0.73900, task: max, mean loss: 1.27720, accuracy: 0.70900, task: top, mean loss: 1.26617, accuracy: 0.75000, task: multi, mean loss: 0.42465, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.01299
Diversity Loss - Mean: -0.13893, Variance: 0.10950
Semantic Loss - Mean: 0.95397, Variance: 0.00324

Train Epoch: 75 
task: majority, mean loss: 0.04294, accuracy: 0.99500, task: max, mean loss: 0.08910, accuracy: 0.97800, task: top, mean loss: 0.01622, accuracy: 0.99900, task: multi, mean loss: 0.37169, multilabel_accuracy: 0.07600, avg. loss over tasks: 0.12999, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.12953, Variance: 0.10192
Semantic Loss - Mean: 0.27408, Variance: 0.00368

Test Epoch: 75 
task: majority, mean loss: 1.20617, accuracy: 0.69500, task: max, mean loss: 1.43327, accuracy: 0.68700, task: top, mean loss: 1.32347, accuracy: 0.73500, task: multi, mean loss: 0.44060, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.10088
Diversity Loss - Mean: -0.13930, Variance: 0.10950
Semantic Loss - Mean: 1.01999, Variance: 0.00327

Train Epoch: 76 
task: majority, mean loss: 0.04205, accuracy: 0.99400, task: max, mean loss: 0.08801, accuracy: 0.98400, task: top, mean loss: 0.01421, accuracy: 0.99900, task: multi, mean loss: 0.36706, multilabel_accuracy: 0.08800, avg. loss over tasks: 0.12783, lr: 0.0001662692621237503
Diversity Loss - Mean: -0.12945, Variance: 0.10180
Semantic Loss - Mean: 0.26572, Variance: 0.00367

Test Epoch: 76 
task: majority, mean loss: 1.09950, accuracy: 0.73000, task: max, mean loss: 1.31931, accuracy: 0.71000, task: top, mean loss: 1.28672, accuracy: 0.75100, task: multi, mean loss: 0.42461, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.03254
Diversity Loss - Mean: -0.13924, Variance: 0.10943
Semantic Loss - Mean: 0.97179, Variance: 0.00329

Train Epoch: 77 
task: majority, mean loss: 0.04010, accuracy: 0.99400, task: max, mean loss: 0.07906, accuracy: 0.98200, task: top, mean loss: 0.01416, accuracy: 0.99900, task: multi, mean loss: 0.36833, multilabel_accuracy: 0.07800, avg. loss over tasks: 0.12541, lr: 0.000153518143955731
Diversity Loss - Mean: -0.13016, Variance: 0.10168
Semantic Loss - Mean: 0.26454, Variance: 0.00368

Test Epoch: 77 
task: majority, mean loss: 1.15291, accuracy: 0.71400, task: max, mean loss: 1.35341, accuracy: 0.69300, task: top, mean loss: 1.29152, accuracy: 0.74900, task: multi, mean loss: 0.42665, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.05612
Diversity Loss - Mean: -0.13931, Variance: 0.10938
Semantic Loss - Mean: 0.98444, Variance: 0.00331

Train Epoch: 78 
task: majority, mean loss: 0.03461, accuracy: 0.99500, task: max, mean loss: 0.07790, accuracy: 0.98200, task: top, mean loss: 0.01393, accuracy: 1.00000, task: multi, mean loss: 0.36625, multilabel_accuracy: 0.07400, avg. loss over tasks: 0.12317, lr: 0.00014118976973084374
Diversity Loss - Mean: -0.13021, Variance: 0.10158
Semantic Loss - Mean: 0.26364, Variance: 0.00368

Test Epoch: 78 
task: majority, mean loss: 1.20212, accuracy: 0.71200, task: max, mean loss: 1.35848, accuracy: 0.68600, task: top, mean loss: 1.25689, accuracy: 0.76600, task: multi, mean loss: 0.42809, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.06140
Diversity Loss - Mean: -0.13934, Variance: 0.10932
Semantic Loss - Mean: 0.99601, Variance: 0.00334

Train Epoch: 79 
task: majority, mean loss: 0.03586, accuracy: 0.99600, task: max, mean loss: 0.06215, accuracy: 0.98900, task: top, mean loss: 0.01269, accuracy: 1.00000, task: multi, mean loss: 0.36072, multilabel_accuracy: 0.08400, avg. loss over tasks: 0.11785, lr: 0.0001292991596740417
Diversity Loss - Mean: -0.13047, Variance: 0.10150
Semantic Loss - Mean: 0.25503, Variance: 0.00369

Test Epoch: 79 
task: majority, mean loss: 1.17529, accuracy: 0.72100, task: max, mean loss: 1.50266, accuracy: 0.67800, task: top, mean loss: 1.31570, accuracy: 0.75300, task: multi, mean loss: 0.43585, multilabel_accuracy: 0.05300, avg. loss over tasks: 1.10738
Diversity Loss - Mean: -0.13942, Variance: 0.10924
Semantic Loss - Mean: 1.03110, Variance: 0.00335

Train Epoch: 80 
task: majority, mean loss: 0.02856, accuracy: 0.99700, task: max, mean loss: 0.06617, accuracy: 0.98800, task: top, mean loss: 0.01247, accuracy: 1.00000, task: multi, mean loss: 0.36162, multilabel_accuracy: 0.07800, avg. loss over tasks: 0.11720, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.13049, Variance: 0.10140
Semantic Loss - Mean: 0.25100, Variance: 0.00369

Test Epoch: 80 
task: majority, mean loss: 1.24145, accuracy: 0.69200, task: max, mean loss: 1.39342, accuracy: 0.70400, task: top, mean loss: 1.31485, accuracy: 0.74200, task: multi, mean loss: 0.43011, multilabel_accuracy: 0.05700, avg. loss over tasks: 1.09496
Diversity Loss - Mean: -0.13953, Variance: 0.10924
Semantic Loss - Mean: 1.02180, Variance: 0.00338

Train Epoch: 81 
task: majority, mean loss: 0.02623, accuracy: 0.99800, task: max, mean loss: 0.05917, accuracy: 0.98900, task: top, mean loss: 0.01218, accuracy: 1.00000, task: multi, mean loss: 0.35806, multilabel_accuracy: 0.09500, avg. loss over tasks: 0.11391, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.13015, Variance: 0.10131
Semantic Loss - Mean: 0.25038, Variance: 0.00369

Test Epoch: 81 
task: majority, mean loss: 1.15853, accuracy: 0.72600, task: max, mean loss: 1.40699, accuracy: 0.69500, task: top, mean loss: 1.28412, accuracy: 0.75200, task: multi, mean loss: 0.42591, multilabel_accuracy: 0.06100, avg. loss over tasks: 1.06889
Diversity Loss - Mean: -0.13953, Variance: 0.10918
Semantic Loss - Mean: 0.99911, Variance: 0.00340

Train Epoch: 82 
task: majority, mean loss: 0.02794, accuracy: 0.99800, task: max, mean loss: 0.05646, accuracy: 0.98900, task: top, mean loss: 0.00976, accuracy: 1.00000, task: multi, mean loss: 0.35985, multilabel_accuracy: 0.10000, avg. loss over tasks: 0.11350, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.13022, Variance: 0.10122
Semantic Loss - Mean: 0.24678, Variance: 0.00369

Test Epoch: 82 
task: majority, mean loss: 1.18251, accuracy: 0.71400, task: max, mean loss: 1.40912, accuracy: 0.70600, task: top, mean loss: 1.31903, accuracy: 0.74400, task: multi, mean loss: 0.42733, multilabel_accuracy: 0.05100, avg. loss over tasks: 1.08450
Diversity Loss - Mean: -0.13957, Variance: 0.10913
Semantic Loss - Mean: 1.00687, Variance: 0.00342

Train Epoch: 83 
task: majority, mean loss: 0.02398, accuracy: 1.00000, task: max, mean loss: 0.05391, accuracy: 0.99000, task: top, mean loss: 0.00938, accuracy: 1.00000, task: multi, mean loss: 0.35989, multilabel_accuracy: 0.07800, avg. loss over tasks: 0.11179, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.13059, Variance: 0.10114
Semantic Loss - Mean: 0.24148, Variance: 0.00369

Test Epoch: 83 
task: majority, mean loss: 1.17854, accuracy: 0.72400, task: max, mean loss: 1.42403, accuracy: 0.69900, task: top, mean loss: 1.33151, accuracy: 0.74700, task: multi, mean loss: 0.42569, multilabel_accuracy: 0.05300, avg. loss over tasks: 1.08994
Diversity Loss - Mean: -0.13957, Variance: 0.10907
Semantic Loss - Mean: 1.00720, Variance: 0.00344

Train Epoch: 84 
task: majority, mean loss: 0.01968, accuracy: 1.00000, task: max, mean loss: 0.04918, accuracy: 0.98800, task: top, mean loss: 0.00970, accuracy: 1.00000, task: multi, mean loss: 0.35769, multilabel_accuracy: 0.07700, avg. loss over tasks: 0.10906, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.13048, Variance: 0.10106
Semantic Loss - Mean: 0.23990, Variance: 0.00368

Test Epoch: 84 
task: majority, mean loss: 1.20581, accuracy: 0.72000, task: max, mean loss: 1.42615, accuracy: 0.69700, task: top, mean loss: 1.30030, accuracy: 0.74700, task: multi, mean loss: 0.42768, multilabel_accuracy: 0.05900, avg. loss over tasks: 1.08999
Diversity Loss - Mean: -0.13965, Variance: 0.10901
Semantic Loss - Mean: 1.00499, Variance: 0.00346

Train Epoch: 85 
task: majority, mean loss: 0.02549, accuracy: 0.99600, task: max, mean loss: 0.04586, accuracy: 0.99000, task: top, mean loss: 0.00873, accuracy: 1.00000, task: multi, mean loss: 0.35547, multilabel_accuracy: 0.09300, avg. loss over tasks: 0.10889, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.13075, Variance: 0.10098
Semantic Loss - Mean: 0.24095, Variance: 0.00369

Test Epoch: 85 
task: majority, mean loss: 1.20121, accuracy: 0.72600, task: max, mean loss: 1.49711, accuracy: 0.69000, task: top, mean loss: 1.32133, accuracy: 0.75200, task: multi, mean loss: 0.43181, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.11287
Diversity Loss - Mean: -0.13965, Variance: 0.10894
Semantic Loss - Mean: 1.02638, Variance: 0.00348

Train Epoch: 86 
task: majority, mean loss: 0.01845, accuracy: 1.00000, task: max, mean loss: 0.04689, accuracy: 0.99400, task: top, mean loss: 0.00881, accuracy: 1.00000, task: multi, mean loss: 0.35554, multilabel_accuracy: 0.09400, avg. loss over tasks: 0.10742, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.13072, Variance: 0.10090
Semantic Loss - Mean: 0.23509, Variance: 0.00368

Test Epoch: 86 
task: majority, mean loss: 1.20356, accuracy: 0.71800, task: max, mean loss: 1.48164, accuracy: 0.69300, task: top, mean loss: 1.32850, accuracy: 0.75000, task: multi, mean loss: 0.43052, multilabel_accuracy: 0.06000, avg. loss over tasks: 1.11105
Diversity Loss - Mean: -0.13976, Variance: 0.10890
Semantic Loss - Mean: 1.02356, Variance: 0.00349

Train Epoch: 87 
task: majority, mean loss: 0.02082, accuracy: 0.99900, task: max, mean loss: 0.05003, accuracy: 0.98900, task: top, mean loss: 0.01145, accuracy: 0.99900, task: multi, mean loss: 0.35443, multilabel_accuracy: 0.09200, avg. loss over tasks: 0.10918, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.13127, Variance: 0.10083
Semantic Loss - Mean: 0.23433, Variance: 0.00369

Test Epoch: 87 
task: majority, mean loss: 1.22724, accuracy: 0.71100, task: max, mean loss: 1.45024, accuracy: 0.69500, task: top, mean loss: 1.34486, accuracy: 0.74700, task: multi, mean loss: 0.42760, multilabel_accuracy: 0.06200, avg. loss over tasks: 1.11249
Diversity Loss - Mean: -0.13976, Variance: 0.10888
Semantic Loss - Mean: 1.02876, Variance: 0.00351

Train Epoch: 88 
task: majority, mean loss: 0.02325, accuracy: 0.99900, task: max, mean loss: 0.04314, accuracy: 0.99100, task: top, mean loss: 0.00907, accuracy: 1.00000, task: multi, mean loss: 0.35596, multilabel_accuracy: 0.08400, avg. loss over tasks: 0.10786, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.13071, Variance: 0.10075
Semantic Loss - Mean: 0.23132, Variance: 0.00369

Test Epoch: 88 
task: majority, mean loss: 1.24113, accuracy: 0.69900, task: max, mean loss: 1.50306, accuracy: 0.69600, task: top, mean loss: 1.36129, accuracy: 0.74200, task: multi, mean loss: 0.43204, multilabel_accuracy: 0.05400, avg. loss over tasks: 1.13438
Diversity Loss - Mean: -0.13980, Variance: 0.10886
Semantic Loss - Mean: 1.04518, Variance: 0.00353

Train Epoch: 89 
task: majority, mean loss: 0.01886, accuracy: 1.00000, task: max, mean loss: 0.05454, accuracy: 0.98800, task: top, mean loss: 0.01121, accuracy: 0.99900, task: multi, mean loss: 0.35299, multilabel_accuracy: 0.09200, avg. loss over tasks: 0.10940, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.13067, Variance: 0.10068
Semantic Loss - Mean: 0.23653, Variance: 0.00369

Test Epoch: 89 
task: majority, mean loss: 1.23099, accuracy: 0.70300, task: max, mean loss: 1.41642, accuracy: 0.70900, task: top, mean loss: 1.34760, accuracy: 0.73700, task: multi, mean loss: 0.42605, multilabel_accuracy: 0.06000, avg. loss over tasks: 1.10526
Diversity Loss - Mean: -0.13980, Variance: 0.10883
Semantic Loss - Mean: 1.02313, Variance: 0.00355

Train Epoch: 90 
task: majority, mean loss: 0.01761, accuracy: 1.00000, task: max, mean loss: 0.04269, accuracy: 0.99100, task: top, mean loss: 0.00836, accuracy: 1.00000, task: multi, mean loss: 0.35383, multilabel_accuracy: 0.08600, avg. loss over tasks: 0.10562, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.13101, Variance: 0.10061
Semantic Loss - Mean: 0.22734, Variance: 0.00369

Test Epoch: 90 
task: majority, mean loss: 1.20642, accuracy: 0.71900, task: max, mean loss: 1.47414, accuracy: 0.69300, task: top, mean loss: 1.33609, accuracy: 0.74100, task: multi, mean loss: 0.42772, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.11109
Diversity Loss - Mean: -0.13980, Variance: 0.10880
Semantic Loss - Mean: 1.02733, Variance: 0.00357

Train Epoch: 91 
task: majority, mean loss: 0.02076, accuracy: 0.99600, task: max, mean loss: 0.04020, accuracy: 0.99400, task: top, mean loss: 0.01011, accuracy: 0.99900, task: multi, mean loss: 0.35335, multilabel_accuracy: 0.08400, avg. loss over tasks: 0.10611, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.13060, Variance: 0.10054
Semantic Loss - Mean: 0.23279, Variance: 0.00369

Test Epoch: 91 
task: majority, mean loss: 1.20163, accuracy: 0.72400, task: max, mean loss: 1.47615, accuracy: 0.69200, task: top, mean loss: 1.34320, accuracy: 0.74500, task: multi, mean loss: 0.42807, multilabel_accuracy: 0.05700, avg. loss over tasks: 1.11226
Diversity Loss - Mean: -0.13978, Variance: 0.10876
Semantic Loss - Mean: 1.02477, Variance: 0.00359

Train Epoch: 92 
task: majority, mean loss: 0.01602, accuracy: 1.00000, task: max, mean loss: 0.04274, accuracy: 0.99000, task: top, mean loss: 0.00825, accuracy: 1.00000, task: multi, mean loss: 0.35504, multilabel_accuracy: 0.08100, avg. loss over tasks: 0.10551, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.13157, Variance: 0.10049
Semantic Loss - Mean: 0.22478, Variance: 0.00369

Test Epoch: 92 
task: majority, mean loss: 1.20632, accuracy: 0.71400, task: max, mean loss: 1.49173, accuracy: 0.69500, task: top, mean loss: 1.35724, accuracy: 0.73900, task: multi, mean loss: 0.43019, multilabel_accuracy: 0.05800, avg. loss over tasks: 1.12137
Diversity Loss - Mean: -0.13982, Variance: 0.10873
Semantic Loss - Mean: 1.03307, Variance: 0.00360

Train Epoch: 93 
task: majority, mean loss: 0.01872, accuracy: 0.99900, task: max, mean loss: 0.03670, accuracy: 0.99400, task: top, mean loss: 0.00809, accuracy: 1.00000, task: multi, mean loss: 0.35199, multilabel_accuracy: 0.07700, avg. loss over tasks: 0.10388, lr: 1.583728472513976e-05
Diversity Loss - Mean: -0.13075, Variance: 0.10042
Semantic Loss - Mean: 0.22941, Variance: 0.00368

Test Epoch: 93 
task: majority, mean loss: 1.22205, accuracy: 0.71800, task: max, mean loss: 1.48560, accuracy: 0.69200, task: top, mean loss: 1.34805, accuracy: 0.74000, task: multi, mean loss: 0.42798, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.12092
Diversity Loss - Mean: -0.13984, Variance: 0.10870
Semantic Loss - Mean: 1.03466, Variance: 0.00362

Train Epoch: 94 
task: majority, mean loss: 0.01770, accuracy: 0.99900, task: max, mean loss: 0.03483, accuracy: 0.99300, task: top, mean loss: 0.00826, accuracy: 1.00000, task: multi, mean loss: 0.35099, multilabel_accuracy: 0.09100, avg. loss over tasks: 0.10295, lr: 1.1915273433464114e-05
Diversity Loss - Mean: -0.13098, Variance: 0.10036
Semantic Loss - Mean: 0.22933, Variance: 0.00368

Test Epoch: 94 
task: majority, mean loss: 1.23267, accuracy: 0.71300, task: max, mean loss: 1.49275, accuracy: 0.69100, task: top, mean loss: 1.34417, accuracy: 0.74200, task: multi, mean loss: 0.42885, multilabel_accuracy: 0.05600, avg. loss over tasks: 1.12461
Diversity Loss - Mean: -0.13987, Variance: 0.10867
Semantic Loss - Mean: 1.04029, Variance: 0.00364

Train Epoch: 95 
task: majority, mean loss: 0.01662, accuracy: 1.00000, task: max, mean loss: 0.04315, accuracy: 0.99200, task: top, mean loss: 0.00878, accuracy: 0.99900, task: multi, mean loss: 0.35158, multilabel_accuracy: 0.09000, avg. loss over tasks: 0.10503, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.13083, Variance: 0.10031
Semantic Loss - Mean: 0.22451, Variance: 0.00368

Test Epoch: 95 
task: majority, mean loss: 1.21579, accuracy: 0.71600, task: max, mean loss: 1.49041, accuracy: 0.69400, task: top, mean loss: 1.35347, accuracy: 0.74400, task: multi, mean loss: 0.42857, multilabel_accuracy: 0.05800, avg. loss over tasks: 1.12206
Diversity Loss - Mean: -0.13985, Variance: 0.10865
Semantic Loss - Mean: 1.03633, Variance: 0.00366

Train Epoch: 96 
task: majority, mean loss: 0.01654, accuracy: 1.00000, task: max, mean loss: 0.04018, accuracy: 0.99400, task: top, mean loss: 0.00826, accuracy: 1.00000, task: multi, mean loss: 0.35157, multilabel_accuracy: 0.08400, avg. loss over tasks: 0.10414, lr: 5.861099663585604e-06
Diversity Loss - Mean: -0.13110, Variance: 0.10025
Semantic Loss - Mean: 0.22564, Variance: 0.00367

Test Epoch: 96 
task: majority, mean loss: 1.22478, accuracy: 0.71700, task: max, mean loss: 1.49571, accuracy: 0.69000, task: top, mean loss: 1.34117, accuracy: 0.74400, task: multi, mean loss: 0.42833, multilabel_accuracy: 0.05800, avg. loss over tasks: 1.12250
Diversity Loss - Mean: -0.13985, Variance: 0.10862
Semantic Loss - Mean: 1.03780, Variance: 0.00367

Train Epoch: 97 
task: majority, mean loss: 0.01735, accuracy: 1.00000, task: max, mean loss: 0.03309, accuracy: 0.99300, task: top, mean loss: 0.00829, accuracy: 1.00000, task: multi, mean loss: 0.35265, multilabel_accuracy: 0.09700, avg. loss over tasks: 0.10284, lr: 3.736313263547436e-06
Diversity Loss - Mean: -0.13082, Variance: 0.10019
Semantic Loss - Mean: 0.22544, Variance: 0.00367

Test Epoch: 97 
task: majority, mean loss: 1.21636, accuracy: 0.72100, task: max, mean loss: 1.48736, accuracy: 0.69600, task: top, mean loss: 1.34622, accuracy: 0.74700, task: multi, mean loss: 0.42813, multilabel_accuracy: 0.06000, avg. loss over tasks: 1.11952
Diversity Loss - Mean: -0.13985, Variance: 0.10858
Semantic Loss - Mean: 1.03374, Variance: 0.00369

Train Epoch: 98 
task: majority, mean loss: 0.01534, accuracy: 1.00000, task: max, mean loss: 0.03240, accuracy: 0.99500, task: top, mean loss: 0.00787, accuracy: 1.00000, task: multi, mean loss: 0.35296, multilabel_accuracy: 0.09100, avg. loss over tasks: 0.10214, lr: 2.2167568952178134e-06
Diversity Loss - Mean: -0.13121, Variance: 0.10014
Semantic Loss - Mean: 0.22085, Variance: 0.00366

Test Epoch: 98 
task: majority, mean loss: 1.22218, accuracy: 0.71700, task: max, mean loss: 1.48648, accuracy: 0.69500, task: top, mean loss: 1.35466, accuracy: 0.74100, task: multi, mean loss: 0.42819, multilabel_accuracy: 0.05700, avg. loss over tasks: 1.12288
Diversity Loss - Mean: -0.13987, Variance: 0.10855
Semantic Loss - Mean: 1.03808, Variance: 0.00371

Train Epoch: 99 
task: majority, mean loss: 0.01615, accuracy: 1.00000, task: max, mean loss: 0.04044, accuracy: 0.99000, task: top, mean loss: 0.00833, accuracy: 1.00000, task: multi, mean loss: 0.35449, multilabel_accuracy: 0.08600, avg. loss over tasks: 0.10485, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.13083, Variance: 0.10008
Semantic Loss - Mean: 0.22864, Variance: 0.00366

Test Epoch: 99 
task: majority, mean loss: 1.22695, accuracy: 0.71500, task: max, mean loss: 1.48451, accuracy: 0.69400, task: top, mean loss: 1.35096, accuracy: 0.74000, task: multi, mean loss: 0.42752, multilabel_accuracy: 0.05800, avg. loss over tasks: 1.12249
Diversity Loss - Mean: -0.13986, Variance: 0.10853
Semantic Loss - Mean: 1.03728, Variance: 0.00372

Train Epoch: 100 
task: majority, mean loss: 0.01594, accuracy: 1.00000, task: max, mean loss: 0.03340, accuracy: 0.99400, task: top, mean loss: 0.00834, accuracy: 1.00000, task: multi, mean loss: 0.34978, multilabel_accuracy: 0.08600, avg. loss over tasks: 0.10187, lr: 1e-06
Diversity Loss - Mean: -0.13129, Variance: 0.10003
Semantic Loss - Mean: 0.22255, Variance: 0.00365

Test Epoch: 100 
task: majority, mean loss: 1.22373, accuracy: 0.71200, task: max, mean loss: 1.49019, accuracy: 0.69200, task: top, mean loss: 1.35563, accuracy: 0.74200, task: multi, mean loss: 0.42853, multilabel_accuracy: 0.05900, avg. loss over tasks: 1.12452
Diversity Loss - Mean: -0.13987, Variance: 0.10850
Semantic Loss - Mean: 1.03779, Variance: 0.00374

