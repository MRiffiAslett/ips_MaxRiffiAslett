Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.35593, accuracy: 0.12600, task: max, mean loss: 2.20980, accuracy: 0.24200, task: top, mean loss: 2.35648, accuracy: 0.10200, task: multi, mean loss: 0.69731, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.90488, lr: 0.0001
Diversity Loss - Mean: -0.11029, Variance: 0.07576
Semantic Loss - Mean: 1.99265, Variance: 0.00715

Test Epoch: 1 
task: majority, mean loss: 2.31355, accuracy: 0.09900, task: max, mean loss: 1.91468, accuracy: 0.27500, task: top, mean loss: 2.31484, accuracy: 0.09800, task: multi, mean loss: 0.63018, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79331
Diversity Loss - Mean: -0.14094, Variance: 0.09276
Semantic Loss - Mean: 1.90645, Variance: 0.00430

Train Epoch: 2 
task: majority, mean loss: 2.32657, accuracy: 0.11400, task: max, mean loss: 1.86327, accuracy: 0.26200, task: top, mean loss: 2.32615, accuracy: 0.10300, task: multi, mean loss: 0.61409, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78252, lr: 0.0002
Diversity Loss - Mean: -0.14167, Variance: 0.09461
Semantic Loss - Mean: 1.83738, Variance: 0.00434

Test Epoch: 2 
task: majority, mean loss: 2.32032, accuracy: 0.10000, task: max, mean loss: 1.90186, accuracy: 0.21300, task: top, mean loss: 2.31746, accuracy: 0.09900, task: multi, mean loss: 0.60184, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78537
Diversity Loss - Mean: -0.14193, Variance: 0.11999
Semantic Loss - Mean: 1.79404, Variance: 0.00227

Train Epoch: 3 
task: majority, mean loss: 2.33474, accuracy: 0.09200, task: max, mean loss: 1.85614, accuracy: 0.24600, task: top, mean loss: 2.33496, accuracy: 0.09700, task: multi, mean loss: 0.60647, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78308, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14167, Variance: 0.11557
Semantic Loss - Mean: 1.77717, Variance: 0.00298

Test Epoch: 3 
task: majority, mean loss: 2.33033, accuracy: 0.10200, task: max, mean loss: 1.86633, accuracy: 0.27400, task: top, mean loss: 2.31118, accuracy: 0.09700, task: multi, mean loss: 0.60219, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77751
Diversity Loss - Mean: -0.14135, Variance: 0.13854
Semantic Loss - Mean: 1.77436, Variance: 0.00153

Train Epoch: 4 
task: majority, mean loss: 2.34283, accuracy: 0.09100, task: max, mean loss: 1.84568, accuracy: 0.25100, task: top, mean loss: 2.32403, accuracy: 0.12600, task: multi, mean loss: 0.60702, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77989, lr: 0.0004
Diversity Loss - Mean: -0.14146, Variance: 0.12906
Semantic Loss - Mean: 1.76979, Variance: 0.00228

Test Epoch: 4 
task: majority, mean loss: 2.32887, accuracy: 0.10000, task: max, mean loss: 1.86303, accuracy: 0.27000, task: top, mean loss: 2.33733, accuracy: 0.10000, task: multi, mean loss: 0.60399, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78330
Diversity Loss - Mean: -0.14191, Variance: 0.14562
Semantic Loss - Mean: 1.77579, Variance: 0.00115

Train Epoch: 5 
task: majority, mean loss: 2.33086, accuracy: 0.10400, task: max, mean loss: 1.83677, accuracy: 0.24800, task: top, mean loss: 2.33101, accuracy: 0.08900, task: multi, mean loss: 0.60574, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77609, lr: 0.0005
Diversity Loss - Mean: -0.14188, Variance: 0.13610
Semantic Loss - Mean: 1.76820, Variance: 0.00185

Test Epoch: 5 
task: majority, mean loss: 2.31794, accuracy: 0.10200, task: max, mean loss: 1.85896, accuracy: 0.27400, task: top, mean loss: 2.31503, accuracy: 0.10100, task: multi, mean loss: 0.60206, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77350
Diversity Loss - Mean: -0.14061, Variance: 0.14978
Semantic Loss - Mean: 1.77232, Variance: 0.00093

Train Epoch: 6 
task: majority, mean loss: 2.32680, accuracy: 0.11100, task: max, mean loss: 1.84489, accuracy: 0.23800, task: top, mean loss: 2.33148, accuracy: 0.09700, task: multi, mean loss: 0.60641, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77740, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.14167, Variance: 0.14033
Semantic Loss - Mean: 1.76896, Variance: 0.00157

Test Epoch: 6 
task: majority, mean loss: 2.33287, accuracy: 0.09000, task: max, mean loss: 1.86056, accuracy: 0.26900, task: top, mean loss: 2.32831, accuracy: 0.10100, task: multi, mean loss: 0.60219, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78098
Diversity Loss - Mean: -0.14210, Variance: 0.15045
Semantic Loss - Mean: 1.77223, Variance: 0.00078

Train Epoch: 7 
task: majority, mean loss: 2.32437, accuracy: 0.09300, task: max, mean loss: 1.85400, accuracy: 0.25300, task: top, mean loss: 2.32321, accuracy: 0.09900, task: multi, mean loss: 0.60675, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77708, lr: 0.0007
Diversity Loss - Mean: -0.14155, Variance: 0.14178
Semantic Loss - Mean: 1.76800, Variance: 0.00136

Test Epoch: 7 
task: majority, mean loss: 2.31418, accuracy: 0.12500, task: max, mean loss: 1.91458, accuracy: 0.16500, task: top, mean loss: 2.34130, accuracy: 0.12900, task: multi, mean loss: 0.60443, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79362
Diversity Loss - Mean: -0.13618, Variance: 0.15022
Semantic Loss - Mean: 1.77984, Variance: 0.00067

Train Epoch: 8 
task: majority, mean loss: 2.31612, accuracy: 0.11400, task: max, mean loss: 1.84277, accuracy: 0.24900, task: top, mean loss: 2.32322, accuracy: 0.11500, task: multi, mean loss: 0.60641, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77213, lr: 0.0008
Diversity Loss - Mean: -0.14070, Variance: 0.14263
Semantic Loss - Mean: 1.76795, Variance: 0.00121

Test Epoch: 8 
task: majority, mean loss: 2.30988, accuracy: 0.12300, task: max, mean loss: 1.88102, accuracy: 0.21300, task: top, mean loss: 2.32851, accuracy: 0.10900, task: multi, mean loss: 0.60190, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78033
Diversity Loss - Mean: -0.13721, Variance: 0.14865
Semantic Loss - Mean: 1.77732, Variance: 0.00059

Train Epoch: 9 
task: majority, mean loss: 2.29022, accuracy: 0.12900, task: max, mean loss: 1.84695, accuracy: 0.24900, task: top, mean loss: 2.30899, accuracy: 0.13000, task: multi, mean loss: 0.60663, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76320, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.13911, Variance: 0.14291
Semantic Loss - Mean: 1.76783, Variance: 0.00109

Test Epoch: 9 
task: majority, mean loss: 2.36608, accuracy: 0.11100, task: max, mean loss: 1.89246, accuracy: 0.16800, task: top, mean loss: 2.37995, accuracy: 0.09800, task: multi, mean loss: 0.60633, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.81121
Diversity Loss - Mean: -0.13788, Variance: 0.14572
Semantic Loss - Mean: 1.78084, Variance: 0.00054

Train Epoch: 10 
task: majority, mean loss: 2.20446, accuracy: 0.16400, task: max, mean loss: 1.84193, accuracy: 0.25800, task: top, mean loss: 2.23595, accuracy: 0.15500, task: multi, mean loss: 0.59651, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71971, lr: 0.001
Diversity Loss - Mean: -0.13819, Variance: 0.14251
Semantic Loss - Mean: 1.75114, Variance: 0.00104

Test Epoch: 10 
task: majority, mean loss: 2.80686, accuracy: 0.09400, task: max, mean loss: 1.87158, accuracy: 0.26400, task: top, mean loss: 2.59523, accuracy: 0.10000, task: multi, mean loss: 0.62839, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.97552
Diversity Loss - Mean: -0.12378, Variance: 0.14532
Semantic Loss - Mean: 1.86110, Variance: 0.00076

Train Epoch: 11 
task: majority, mean loss: 2.23777, accuracy: 0.14500, task: max, mean loss: 1.84564, accuracy: 0.25500, task: top, mean loss: 2.25323, accuracy: 0.16400, task: multi, mean loss: 0.59777, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73360, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.13590, Variance: 0.14212
Semantic Loss - Mean: 1.73799, Variance: 0.00103

Test Epoch: 11 
task: majority, mean loss: 2.32452, accuracy: 0.11900, task: max, mean loss: 1.87128, accuracy: 0.27400, task: top, mean loss: 2.36254, accuracy: 0.11200, task: multi, mean loss: 0.61390, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79306
Diversity Loss - Mean: -0.13441, Variance: 0.14412
Semantic Loss - Mean: 1.79152, Variance: 0.00090

Train Epoch: 12 
task: majority, mean loss: 2.15559, accuracy: 0.16700, task: max, mean loss: 1.80679, accuracy: 0.25700, task: top, mean loss: 2.21867, accuracy: 0.14000, task: multi, mean loss: 0.58765, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.69217, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.13605, Variance: 0.14143
Semantic Loss - Mean: 1.70739, Variance: 0.00105

Test Epoch: 12 
task: majority, mean loss: 2.19485, accuracy: 0.16500, task: max, mean loss: 1.86537, accuracy: 0.21300, task: top, mean loss: 2.25654, accuracy: 0.13100, task: multi, mean loss: 0.58436, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72528
Diversity Loss - Mean: -0.13714, Variance: 0.14463
Semantic Loss - Mean: 1.76044, Variance: 0.00105

Train Epoch: 13 
task: majority, mean loss: 2.15667, accuracy: 0.18000, task: max, mean loss: 1.78665, accuracy: 0.27800, task: top, mean loss: 2.19125, accuracy: 0.18200, task: multi, mean loss: 0.58553, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68003, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.13716, Variance: 0.14132
Semantic Loss - Mean: 1.69441, Variance: 0.00102

Test Epoch: 13 
task: majority, mean loss: 2.17931, accuracy: 0.15800, task: max, mean loss: 1.83647, accuracy: 0.24000, task: top, mean loss: 2.23764, accuracy: 0.14600, task: multi, mean loss: 0.58035, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70844
Diversity Loss - Mean: -0.14194, Variance: 0.14469
Semantic Loss - Mean: 1.71040, Variance: 0.00098

Train Epoch: 14 
task: majority, mean loss: 2.13824, accuracy: 0.17100, task: max, mean loss: 1.80544, accuracy: 0.25600, task: top, mean loss: 2.18223, accuracy: 0.15400, task: multi, mean loss: 0.58579, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67792, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.13728, Variance: 0.14113
Semantic Loss - Mean: 1.68613, Variance: 0.00099

Test Epoch: 14 
task: majority, mean loss: 2.20726, accuracy: 0.15000, task: max, mean loss: 1.83695, accuracy: 0.29100, task: top, mean loss: 2.24600, accuracy: 0.14600, task: multi, mean loss: 0.58423, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71861
Diversity Loss - Mean: -0.13996, Variance: 0.14445
Semantic Loss - Mean: 1.72470, Variance: 0.00092

Train Epoch: 15 
task: majority, mean loss: 2.12983, accuracy: 0.16300, task: max, mean loss: 1.76751, accuracy: 0.27500, task: top, mean loss: 2.18532, accuracy: 0.16700, task: multi, mean loss: 0.57753, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.66505, lr: 0.000992411472629598
Diversity Loss - Mean: -0.13693, Variance: 0.14053
Semantic Loss - Mean: 1.66821, Variance: 0.00095

Test Epoch: 15 
task: majority, mean loss: 2.77486, accuracy: 0.09400, task: max, mean loss: 1.90588, accuracy: 0.15500, task: top, mean loss: 2.54045, accuracy: 0.10000, task: multi, mean loss: 0.64823, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.96736
Diversity Loss - Mean: -0.14114, Variance: 0.14989
Semantic Loss - Mean: 2.04451, Variance: 0.00092

Train Epoch: 16 
task: majority, mean loss: 2.10313, accuracy: 0.20100, task: max, mean loss: 1.76304, accuracy: 0.27900, task: top, mean loss: 2.16186, accuracy: 0.17900, task: multi, mean loss: 0.58037, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65210, lr: 0.000989084726566536
Diversity Loss - Mean: -0.13772, Variance: 0.13975
Semantic Loss - Mean: 1.65916, Variance: 0.00092

Test Epoch: 16 
task: majority, mean loss: 2.16937, accuracy: 0.16200, task: max, mean loss: 1.85911, accuracy: 0.28300, task: top, mean loss: 2.24367, accuracy: 0.15600, task: multi, mean loss: 0.58182, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.71349
Diversity Loss - Mean: -0.14220, Variance: 0.14891
Semantic Loss - Mean: 1.71073, Variance: 0.00086

Train Epoch: 17 
task: majority, mean loss: 2.07121, accuracy: 0.19800, task: max, mean loss: 1.74639, accuracy: 0.29100, task: top, mean loss: 2.13050, accuracy: 0.17900, task: multi, mean loss: 0.57410, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.63055, lr: 0.00098516271527486
Diversity Loss - Mean: -0.13745, Variance: 0.13911
Semantic Loss - Mean: 1.64404, Variance: 0.00089

Test Epoch: 17 
task: majority, mean loss: 2.32505, accuracy: 0.13500, task: max, mean loss: 1.81219, accuracy: 0.27600, task: top, mean loss: 2.29406, accuracy: 0.13300, task: multi, mean loss: 0.58266, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.75349
Diversity Loss - Mean: -0.14205, Variance: 0.14925
Semantic Loss - Mean: 1.74331, Variance: 0.00082

Train Epoch: 18 
task: majority, mean loss: 2.07219, accuracy: 0.20300, task: max, mean loss: 1.75149, accuracy: 0.27000, task: top, mean loss: 2.11807, accuracy: 0.20200, task: multi, mean loss: 0.57745, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.62980, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.13903, Variance: 0.13865
Semantic Loss - Mean: 1.63958, Variance: 0.00087

Test Epoch: 18 
task: majority, mean loss: 2.33091, accuracy: 0.16400, task: max, mean loss: 1.83532, accuracy: 0.27200, task: top, mean loss: 2.40533, accuracy: 0.14100, task: multi, mean loss: 0.59018, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.79044
Diversity Loss - Mean: -0.14211, Variance: 0.14967
Semantic Loss - Mean: 1.78808, Variance: 0.00078

Train Epoch: 19 
task: majority, mean loss: 2.05979, accuracy: 0.19800, task: max, mean loss: 1.74864, accuracy: 0.29500, task: top, mean loss: 2.09981, accuracy: 0.19400, task: multi, mean loss: 0.57276, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.62025, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.13839, Variance: 0.13815
Semantic Loss - Mean: 1.63733, Variance: 0.00085

Test Epoch: 19 
task: majority, mean loss: 2.27128, accuracy: 0.15600, task: max, mean loss: 1.88753, accuracy: 0.27100, task: top, mean loss: 2.33115, accuracy: 0.14500, task: multi, mean loss: 0.60367, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77341
Diversity Loss - Mean: -0.14212, Variance: 0.14886
Semantic Loss - Mean: 1.74921, Variance: 0.00075

Train Epoch: 20 
task: majority, mean loss: 2.03878, accuracy: 0.19500, task: max, mean loss: 1.74963, accuracy: 0.29500, task: top, mean loss: 2.09501, accuracy: 0.18100, task: multi, mean loss: 0.57162, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.61376, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.13790, Variance: 0.13767
Semantic Loss - Mean: 1.62347, Variance: 0.00084

Test Epoch: 20 
task: majority, mean loss: 2.44342, accuracy: 0.12700, task: max, mean loss: 1.86175, accuracy: 0.21000, task: top, mean loss: 2.32094, accuracy: 0.13800, task: multi, mean loss: 0.60148, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.80690
Diversity Loss - Mean: -0.14166, Variance: 0.15013
Semantic Loss - Mean: 1.83454, Variance: 0.00073

Train Epoch: 21 
task: majority, mean loss: 2.05983, accuracy: 0.18800, task: max, mean loss: 1.75855, accuracy: 0.29700, task: top, mean loss: 2.13048, accuracy: 0.17200, task: multi, mean loss: 0.57400, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.63071, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.13754, Variance: 0.13717
Semantic Loss - Mean: 1.64232, Variance: 0.00083

Test Epoch: 21 
task: majority, mean loss: 2.47370, accuracy: 0.11700, task: max, mean loss: 1.86741, accuracy: 0.22700, task: top, mean loss: 2.40274, accuracy: 0.11900, task: multi, mean loss: 0.61752, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.84034
Diversity Loss - Mean: -0.14208, Variance: 0.15098
Semantic Loss - Mean: 1.80700, Variance: 0.00072

Train Epoch: 22 
task: majority, mean loss: 2.11288, accuracy: 0.18000, task: max, mean loss: 1.74509, accuracy: 0.30500, task: top, mean loss: 2.13508, accuracy: 0.18200, task: multi, mean loss: 0.57800, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.64276, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.13794, Variance: 0.13660
Semantic Loss - Mean: 1.65511, Variance: 0.00082

Test Epoch: 22 
task: majority, mean loss: 2.56378, accuracy: 0.09700, task: max, mean loss: 1.85854, accuracy: 0.20800, task: top, mean loss: 2.40000, accuracy: 0.11000, task: multi, mean loss: 0.61651, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.85971
Diversity Loss - Mean: -0.14164, Variance: 0.15286
Semantic Loss - Mean: 1.87789, Variance: 0.00072

Train Epoch: 23 
task: majority, mean loss: 2.08189, accuracy: 0.18600, task: max, mean loss: 1.75245, accuracy: 0.29000, task: top, mean loss: 2.12485, accuracy: 0.18400, task: multi, mean loss: 0.57573, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.63373, lr: 0.000949447626126434
Diversity Loss - Mean: -0.13733, Variance: 0.13602
Semantic Loss - Mean: 1.64531, Variance: 0.00080

Test Epoch: 23 
task: majority, mean loss: 2.70797, accuracy: 0.10300, task: max, mean loss: 2.03920, accuracy: 0.27000, task: top, mean loss: 2.60874, accuracy: 0.10600, task: multi, mean loss: 0.66054, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.00411
Diversity Loss - Mean: -0.14187, Variance: 0.15282
Semantic Loss - Mean: 1.95990, Variance: 0.00070

Train Epoch: 24 
task: majority, mean loss: 2.02822, accuracy: 0.20900, task: max, mean loss: 1.73416, accuracy: 0.29200, task: top, mean loss: 2.06691, accuracy: 0.19700, task: multi, mean loss: 0.57009, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.59984, lr: 0.000941532322633034
Diversity Loss - Mean: -0.13841, Variance: 0.13526
Semantic Loss - Mean: 1.61178, Variance: 0.00079

Test Epoch: 24 
task: majority, mean loss: 2.12198, accuracy: 0.16400, task: max, mean loss: 1.80777, accuracy: 0.27800, task: top, mean loss: 2.20680, accuracy: 0.16000, task: multi, mean loss: 0.56849, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.67626
Diversity Loss - Mean: -0.14215, Variance: 0.15156
Semantic Loss - Mean: 1.68004, Variance: 0.00068

Train Epoch: 25 
task: majority, mean loss: 2.00624, accuracy: 0.20100, task: max, mean loss: 1.72165, accuracy: 0.31300, task: top, mean loss: 2.03594, accuracy: 0.20800, task: multi, mean loss: 0.56820, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.58301, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.13866, Variance: 0.13449
Semantic Loss - Mean: 1.60066, Variance: 0.00078

Test Epoch: 25 
task: majority, mean loss: 2.21004, accuracy: 0.16800, task: max, mean loss: 1.84348, accuracy: 0.28500, task: top, mean loss: 2.28802, accuracy: 0.15300, task: multi, mean loss: 0.58142, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.73074
Diversity Loss - Mean: -0.14206, Variance: 0.15048
Semantic Loss - Mean: 1.70975, Variance: 0.00066

Train Epoch: 26 
task: majority, mean loss: 1.98859, accuracy: 0.20200, task: max, mean loss: 1.73092, accuracy: 0.30400, task: top, mean loss: 2.04952, accuracy: 0.17900, task: multi, mean loss: 0.56868, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.58443, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.13812, Variance: 0.13382
Semantic Loss - Mean: 1.60224, Variance: 0.00078

Test Epoch: 26 
task: majority, mean loss: 2.32543, accuracy: 0.17400, task: max, mean loss: 1.82196, accuracy: 0.28100, task: top, mean loss: 2.30495, accuracy: 0.17300, task: multi, mean loss: 0.58357, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.75898
Diversity Loss - Mean: -0.14220, Variance: 0.15015
Semantic Loss - Mean: 1.76133, Variance: 0.00064

Train Epoch: 27 
task: majority, mean loss: 1.96475, accuracy: 0.22800, task: max, mean loss: 1.72505, accuracy: 0.32600, task: top, mean loss: 2.00305, accuracy: 0.20900, task: multi, mean loss: 0.56710, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.56499, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.13813, Variance: 0.13310
Semantic Loss - Mean: 1.58527, Variance: 0.00078

Test Epoch: 27 
task: majority, mean loss: 2.27018, accuracy: 0.15500, task: max, mean loss: 1.91808, accuracy: 0.27000, task: top, mean loss: 2.31151, accuracy: 0.12600, task: multi, mean loss: 0.59176, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.77288
Diversity Loss - Mean: -0.14221, Variance: 0.14914
Semantic Loss - Mean: 1.73306, Variance: 0.00063

Train Epoch: 28 
task: majority, mean loss: 2.01812, accuracy: 0.18000, task: max, mean loss: 1.72543, accuracy: 0.33600, task: top, mean loss: 2.04600, accuracy: 0.20100, task: multi, mean loss: 0.57293, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.59062, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.13843, Variance: 0.13244
Semantic Loss - Mean: 1.60407, Variance: 0.00078

Test Epoch: 28 
task: majority, mean loss: 2.88369, accuracy: 0.09200, task: max, mean loss: 1.95076, accuracy: 0.16500, task: top, mean loss: 2.68094, accuracy: 0.09200, task: multi, mean loss: 0.64160, multilabel_accuracy: 0.00100, avg. loss over tasks: 2.03925
Diversity Loss - Mean: -0.14186, Variance: 0.15114
Semantic Loss - Mean: 2.00030, Variance: 0.00062

Train Epoch: 29 
task: majority, mean loss: 2.02799, accuracy: 0.22100, task: max, mean loss: 1.71802, accuracy: 0.32300, task: top, mean loss: 2.04967, accuracy: 0.19100, task: multi, mean loss: 0.57065, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59158, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.13710, Variance: 0.13164
Semantic Loss - Mean: 1.61206, Variance: 0.00078

Test Epoch: 29 
task: majority, mean loss: 2.21401, accuracy: 0.12800, task: max, mean loss: 1.88053, accuracy: 0.28000, task: top, mean loss: 2.18575, accuracy: 0.15900, task: multi, mean loss: 0.57815, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.71461
Diversity Loss - Mean: -0.14224, Variance: 0.15002
Semantic Loss - Mean: 1.71241, Variance: 0.00061

Train Epoch: 30 
task: majority, mean loss: 1.98550, accuracy: 0.21500, task: max, mean loss: 1.70499, accuracy: 0.33400, task: top, mean loss: 2.00426, accuracy: 0.20200, task: multi, mean loss: 0.56444, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.56480, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.13808, Variance: 0.13092
Semantic Loss - Mean: 1.58320, Variance: 0.00077

Test Epoch: 30 
task: majority, mean loss: 2.21007, accuracy: 0.15400, task: max, mean loss: 1.81329, accuracy: 0.27500, task: top, mean loss: 2.23833, accuracy: 0.16800, task: multi, mean loss: 0.57687, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.70964
Diversity Loss - Mean: -0.14230, Variance: 0.14936
Semantic Loss - Mean: 1.71037, Variance: 0.00060

Train Epoch: 31 
task: majority, mean loss: 1.98335, accuracy: 0.21900, task: max, mean loss: 1.69460, accuracy: 0.35100, task: top, mean loss: 1.99358, accuracy: 0.21900, task: multi, mean loss: 0.56787, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.55985, lr: 0.0008717008403259585
Diversity Loss - Mean: -0.13754, Variance: 0.13021
Semantic Loss - Mean: 1.58043, Variance: 0.00077

Test Epoch: 31 
task: majority, mean loss: 2.24322, accuracy: 0.17300, task: max, mean loss: 1.84605, accuracy: 0.28900, task: top, mean loss: 2.30425, accuracy: 0.14300, task: multi, mean loss: 0.57589, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.74235
Diversity Loss - Mean: -0.14211, Variance: 0.14870
Semantic Loss - Mean: 1.74820, Variance: 0.00059

Train Epoch: 32 
task: majority, mean loss: 1.93295, accuracy: 0.24500, task: max, mean loss: 1.68846, accuracy: 0.36200, task: top, mean loss: 1.94014, accuracy: 0.22700, task: multi, mean loss: 0.56557, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.53178, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.13743, Variance: 0.12956
Semantic Loss - Mean: 1.55123, Variance: 0.00077

Test Epoch: 32 
task: majority, mean loss: 2.32653, accuracy: 0.14200, task: max, mean loss: 1.81299, accuracy: 0.27100, task: top, mean loss: 2.35406, accuracy: 0.14400, task: multi, mean loss: 0.58851, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77052
Diversity Loss - Mean: -0.14213, Variance: 0.14850
Semantic Loss - Mean: 1.76732, Variance: 0.00058

Train Epoch: 33 
task: majority, mean loss: 1.88588, accuracy: 0.27000, task: max, mean loss: 1.66157, accuracy: 0.37300, task: top, mean loss: 1.94430, accuracy: 0.23500, task: multi, mean loss: 0.56395, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.51392, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.13766, Variance: 0.12893
Semantic Loss - Mean: 1.53802, Variance: 0.00077

Test Epoch: 33 
task: majority, mean loss: 2.57688, accuracy: 0.13900, task: max, mean loss: 1.89396, accuracy: 0.24800, task: top, mean loss: 2.44405, accuracy: 0.13500, task: multi, mean loss: 0.60293, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.87946
Diversity Loss - Mean: -0.14229, Variance: 0.14832
Semantic Loss - Mean: 1.83860, Variance: 0.00059

Train Epoch: 34 
task: majority, mean loss: 1.86916, accuracy: 0.26700, task: max, mean loss: 1.65203, accuracy: 0.36800, task: top, mean loss: 1.90640, accuracy: 0.25300, task: multi, mean loss: 0.56296, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.49764, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.13770, Variance: 0.12838
Semantic Loss - Mean: 1.52254, Variance: 0.00077

Test Epoch: 34 
task: majority, mean loss: 2.68549, accuracy: 0.13100, task: max, mean loss: 2.02313, accuracy: 0.27400, task: top, mean loss: 2.39403, accuracy: 0.16500, task: multi, mean loss: 0.62291, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.93139
Diversity Loss - Mean: -0.14221, Variance: 0.14745
Semantic Loss - Mean: 1.87392, Variance: 0.00059

Train Epoch: 35 
task: majority, mean loss: 1.90468, accuracy: 0.25300, task: max, mean loss: 1.64252, accuracy: 0.38300, task: top, mean loss: 1.93388, accuracy: 0.24400, task: multi, mean loss: 0.56519, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.51157, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.13718, Variance: 0.12779
Semantic Loss - Mean: 1.53570, Variance: 0.00078

Test Epoch: 35 
task: majority, mean loss: 2.23695, accuracy: 0.17700, task: max, mean loss: 1.90901, accuracy: 0.29600, task: top, mean loss: 2.23478, accuracy: 0.17400, task: multi, mean loss: 0.58097, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.74043
Diversity Loss - Mean: -0.14229, Variance: 0.14645
Semantic Loss - Mean: 1.71260, Variance: 0.00059

Train Epoch: 36 
task: majority, mean loss: 1.86137, accuracy: 0.27600, task: max, mean loss: 1.63827, accuracy: 0.39200, task: top, mean loss: 1.88117, accuracy: 0.26100, task: multi, mean loss: 0.56409, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.48622, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.13722, Variance: 0.12720
Semantic Loss - Mean: 1.51436, Variance: 0.00078

Test Epoch: 36 
task: majority, mean loss: 2.35745, accuracy: 0.15200, task: max, mean loss: 1.96469, accuracy: 0.27200, task: top, mean loss: 2.36857, accuracy: 0.14500, task: multi, mean loss: 0.59507, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.82144
Diversity Loss - Mean: -0.14196, Variance: 0.14562
Semantic Loss - Mean: 1.80988, Variance: 0.00060

Train Epoch: 37 
task: majority, mean loss: 1.85006, accuracy: 0.27300, task: max, mean loss: 1.61911, accuracy: 0.38700, task: top, mean loss: 1.83648, accuracy: 0.26400, task: multi, mean loss: 0.56420, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.46746, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.13636, Variance: 0.12658
Semantic Loss - Mean: 1.50581, Variance: 0.00080

Test Epoch: 37 
task: majority, mean loss: 2.07831, accuracy: 0.21700, task: max, mean loss: 1.79233, accuracy: 0.31200, task: top, mean loss: 2.17020, accuracy: 0.23300, task: multi, mean loss: 0.56513, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65149
Diversity Loss - Mean: -0.14176, Variance: 0.14466
Semantic Loss - Mean: 1.65053, Variance: 0.00060

Train Epoch: 38 
task: majority, mean loss: 1.74801, accuracy: 0.31300, task: max, mean loss: 1.58025, accuracy: 0.42700, task: top, mean loss: 1.77201, accuracy: 0.29100, task: multi, mean loss: 0.55706, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.41433, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.13574, Variance: 0.12600
Semantic Loss - Mean: 1.46464, Variance: 0.00081

Test Epoch: 38 
task: majority, mean loss: 2.66151, accuracy: 0.17600, task: max, mean loss: 1.87203, accuracy: 0.30100, task: top, mean loss: 2.35710, accuracy: 0.18600, task: multi, mean loss: 0.59403, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.87117
Diversity Loss - Mean: -0.14161, Variance: 0.14460
Semantic Loss - Mean: 1.87249, Variance: 0.00062

Train Epoch: 39 
task: majority, mean loss: 1.86773, accuracy: 0.27300, task: max, mean loss: 1.59550, accuracy: 0.41700, task: top, mean loss: 1.86838, accuracy: 0.26600, task: multi, mean loss: 0.56114, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.47319, lr: 0.000765194672484486
Diversity Loss - Mean: -0.13444, Variance: 0.12560
Semantic Loss - Mean: 1.50970, Variance: 0.00082

Test Epoch: 39 
task: majority, mean loss: 2.32814, accuracy: 0.20800, task: max, mean loss: 1.82868, accuracy: 0.32800, task: top, mean loss: 2.30957, accuracy: 0.20700, task: multi, mean loss: 0.57490, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.76032
Diversity Loss - Mean: -0.14173, Variance: 0.14464
Semantic Loss - Mean: 1.72913, Variance: 0.00062

Train Epoch: 40 
task: majority, mean loss: 1.77453, accuracy: 0.33500, task: max, mean loss: 1.53768, accuracy: 0.44800, task: top, mean loss: 1.77235, accuracy: 0.29800, task: multi, mean loss: 0.55430, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.40971, lr: 0.00075025
Diversity Loss - Mean: -0.13428, Variance: 0.12511
Semantic Loss - Mean: 1.46198, Variance: 0.00084

Test Epoch: 40 
task: majority, mean loss: 2.51405, accuracy: 0.16800, task: max, mean loss: 1.91211, accuracy: 0.30300, task: top, mean loss: 2.34023, accuracy: 0.19500, task: multi, mean loss: 0.59089, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.83932
Diversity Loss - Mean: -0.14102, Variance: 0.14381
Semantic Loss - Mean: 1.81155, Variance: 0.00064

Train Epoch: 41 
task: majority, mean loss: 1.73562, accuracy: 0.34900, task: max, mean loss: 1.45977, accuracy: 0.49600, task: top, mean loss: 1.71691, accuracy: 0.33700, task: multi, mean loss: 0.54573, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.36451, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.13458, Variance: 0.12458
Semantic Loss - Mean: 1.42943, Variance: 0.00086

Test Epoch: 41 
task: majority, mean loss: 2.24162, accuracy: 0.24300, task: max, mean loss: 1.78749, accuracy: 0.35700, task: top, mean loss: 2.28717, accuracy: 0.21800, task: multi, mean loss: 0.56576, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.72051
Diversity Loss - Mean: -0.14121, Variance: 0.14372
Semantic Loss - Mean: 1.71408, Variance: 0.00066

Train Epoch: 42 
task: majority, mean loss: 1.68705, accuracy: 0.36400, task: max, mean loss: 1.46150, accuracy: 0.48100, task: top, mean loss: 1.69229, accuracy: 0.33600, task: multi, mean loss: 0.54515, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.34650, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.13370, Variance: 0.12403
Semantic Loss - Mean: 1.41850, Variance: 0.00088

Test Epoch: 42 
task: majority, mean loss: 3.19846, accuracy: 0.10400, task: max, mean loss: 1.98606, accuracy: 0.24300, task: top, mean loss: 2.80929, accuracy: 0.13800, task: multi, mean loss: 0.64417, multilabel_accuracy: 0.00100, avg. loss over tasks: 2.15949
Diversity Loss - Mean: -0.14058, Variance: 0.14473
Semantic Loss - Mean: 2.18440, Variance: 0.00071

Train Epoch: 43 
task: majority, mean loss: 1.63455, accuracy: 0.39200, task: max, mean loss: 1.39281, accuracy: 0.50300, task: top, mean loss: 1.62581, accuracy: 0.36900, task: multi, mean loss: 0.53924, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.29810, lr: 0.0007036649532163622
Diversity Loss - Mean: -0.13357, Variance: 0.12343
Semantic Loss - Mean: 1.37911, Variance: 0.00091

Test Epoch: 43 
task: majority, mean loss: 2.11974, accuracy: 0.25500, task: max, mean loss: 1.74389, accuracy: 0.35400, task: top, mean loss: 2.08444, accuracy: 0.25200, task: multi, mean loss: 0.56854, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.62915
Diversity Loss - Mean: -0.14042, Variance: 0.14343
Semantic Loss - Mean: 1.62153, Variance: 0.00072

Train Epoch: 44 
task: majority, mean loss: 1.67772, accuracy: 0.36300, task: max, mean loss: 1.38440, accuracy: 0.51600, task: top, mean loss: 1.66212, accuracy: 0.37900, task: multi, mean loss: 0.54403, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.31707, lr: 0.000687615993411248
Diversity Loss - Mean: -0.13274, Variance: 0.12272
Semantic Loss - Mean: 1.39508, Variance: 0.00094

Test Epoch: 44 
task: majority, mean loss: 2.02211, accuracy: 0.27100, task: max, mean loss: 1.60250, accuracy: 0.41400, task: top, mean loss: 2.16384, accuracy: 0.28700, task: multi, mean loss: 0.54566, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.58353
Diversity Loss - Mean: -0.14038, Variance: 0.14255
Semantic Loss - Mean: 1.65365, Variance: 0.00073

Train Epoch: 45 
task: majority, mean loss: 1.63217, accuracy: 0.38400, task: max, mean loss: 1.31391, accuracy: 0.55600, task: top, mean loss: 1.56275, accuracy: 0.42200, task: multi, mean loss: 0.53916, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.26200, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.13235, Variance: 0.12202
Semantic Loss - Mean: 1.34879, Variance: 0.00097

Test Epoch: 45 
task: majority, mean loss: 1.87678, accuracy: 0.34400, task: max, mean loss: 1.55180, accuracy: 0.44200, task: top, mean loss: 1.99776, accuracy: 0.32500, task: multi, mean loss: 0.54209, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.49211
Diversity Loss - Mean: -0.14109, Variance: 0.14154
Semantic Loss - Mean: 1.52429, Variance: 0.00074

Train Epoch: 46 
task: majority, mean loss: 1.54242, accuracy: 0.42300, task: max, mean loss: 1.23312, accuracy: 0.58000, task: top, mean loss: 1.49522, accuracy: 0.46300, task: multi, mean loss: 0.53291, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.20092, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.13295, Variance: 0.12133
Semantic Loss - Mean: 1.29297, Variance: 0.00101

Test Epoch: 46 
task: majority, mean loss: 2.21595, accuracy: 0.29600, task: max, mean loss: 1.91711, accuracy: 0.44300, task: top, mean loss: 2.25940, accuracy: 0.29400, task: multi, mean loss: 0.57550, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.74199
Diversity Loss - Mean: -0.14108, Variance: 0.14143
Semantic Loss - Mean: 1.76112, Variance: 0.00078

Train Epoch: 47 
task: majority, mean loss: 1.56885, accuracy: 0.43600, task: max, mean loss: 1.22376, accuracy: 0.58000, task: top, mean loss: 1.52431, accuracy: 0.42800, task: multi, mean loss: 0.53202, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.21223, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.13281, Variance: 0.12070
Semantic Loss - Mean: 1.31626, Variance: 0.00107

Test Epoch: 47 
task: majority, mean loss: 1.85682, accuracy: 0.35300, task: max, mean loss: 1.48885, accuracy: 0.47600, task: top, mean loss: 1.98600, accuracy: 0.36300, task: multi, mean loss: 0.53962, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.46782
Diversity Loss - Mean: -0.14120, Variance: 0.14050
Semantic Loss - Mean: 1.46516, Variance: 0.00079

Train Epoch: 48 
task: majority, mean loss: 1.43501, accuracy: 0.48600, task: max, mean loss: 1.13334, accuracy: 0.61400, task: top, mean loss: 1.41640, accuracy: 0.49400, task: multi, mean loss: 0.52464, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.12735, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.13186, Variance: 0.12005
Semantic Loss - Mean: 1.22601, Variance: 0.00110

Test Epoch: 48 
task: majority, mean loss: 2.37298, accuracy: 0.23200, task: max, mean loss: 2.07776, accuracy: 0.42500, task: top, mean loss: 2.24361, accuracy: 0.29700, task: multi, mean loss: 0.58892, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.82082
Diversity Loss - Mean: -0.14109, Variance: 0.14008
Semantic Loss - Mean: 1.82599, Variance: 0.00081

Train Epoch: 49 
task: majority, mean loss: 1.48899, accuracy: 0.46100, task: max, mean loss: 1.10600, accuracy: 0.61800, task: top, mean loss: 1.46169, accuracy: 0.47600, task: multi, mean loss: 0.52252, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.14480, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.13237, Variance: 0.11947
Semantic Loss - Mean: 1.24094, Variance: 0.00115

Test Epoch: 49 
task: majority, mean loss: 1.98810, accuracy: 0.35600, task: max, mean loss: 1.49821, accuracy: 0.49600, task: top, mean loss: 2.06061, accuracy: 0.36700, task: multi, mean loss: 0.54579, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.52318
Diversity Loss - Mean: -0.14140, Variance: 0.13935
Semantic Loss - Mean: 1.52964, Variance: 0.00083

Train Epoch: 50 
task: majority, mean loss: 1.42009, accuracy: 0.49700, task: max, mean loss: 1.13049, accuracy: 0.62500, task: top, mean loss: 1.38203, accuracy: 0.52100, task: multi, mean loss: 0.51972, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.11308, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.13237, Variance: 0.11888
Semantic Loss - Mean: 1.21999, Variance: 0.00119

Test Epoch: 50 
task: majority, mean loss: 2.41767, accuracy: 0.27500, task: max, mean loss: 1.54428, accuracy: 0.47500, task: top, mean loss: 2.26932, accuracy: 0.31600, task: multi, mean loss: 0.55492, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.69655
Diversity Loss - Mean: -0.14118, Variance: 0.13917
Semantic Loss - Mean: 1.71555, Variance: 0.00084

Train Epoch: 51 
task: majority, mean loss: 1.38955, accuracy: 0.48400, task: max, mean loss: 1.06283, accuracy: 0.64800, task: top, mean loss: 1.32704, accuracy: 0.53300, task: multi, mean loss: 0.51494, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.07359, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.13237, Variance: 0.11831
Semantic Loss - Mean: 1.17734, Variance: 0.00123

Test Epoch: 51 
task: majority, mean loss: 2.43256, accuracy: 0.33500, task: max, mean loss: 1.74149, accuracy: 0.47200, task: top, mean loss: 2.36360, accuracy: 0.32900, task: multi, mean loss: 0.56358, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.77531
Diversity Loss - Mean: -0.14115, Variance: 0.13864
Semantic Loss - Mean: 1.78186, Variance: 0.00087

Train Epoch: 52 
task: majority, mean loss: 1.30831, accuracy: 0.53600, task: max, mean loss: 0.98317, accuracy: 0.67400, task: top, mean loss: 1.28024, accuracy: 0.54900, task: multi, mean loss: 0.50925, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.02025, lr: 0.0005527119674021931
Diversity Loss - Mean: -0.13282, Variance: 0.11782
Semantic Loss - Mean: 1.12944, Variance: 0.00127

Test Epoch: 52 
task: majority, mean loss: 2.29067, accuracy: 0.33600, task: max, mean loss: 1.52289, accuracy: 0.51100, task: top, mean loss: 2.24987, accuracy: 0.38000, task: multi, mean loss: 0.53863, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.65051
Diversity Loss - Mean: -0.14106, Variance: 0.13800
Semantic Loss - Mean: 1.63677, Variance: 0.00089

Train Epoch: 53 
task: majority, mean loss: 1.28266, accuracy: 0.54300, task: max, mean loss: 0.93210, accuracy: 0.68800, task: top, mean loss: 1.22330, accuracy: 0.58400, task: multi, mean loss: 0.50561, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.98592, lr: 0.0005353433586351905
Diversity Loss - Mean: -0.13234, Variance: 0.11736
Semantic Loss - Mean: 1.10253, Variance: 0.00132

Test Epoch: 53 
task: majority, mean loss: 2.41373, accuracy: 0.30500, task: max, mean loss: 1.55652, accuracy: 0.51100, task: top, mean loss: 2.29414, accuracy: 0.36300, task: multi, mean loss: 0.55669, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.70527
Diversity Loss - Mean: -0.14119, Variance: 0.13730
Semantic Loss - Mean: 1.66909, Variance: 0.00092

Train Epoch: 54 
task: majority, mean loss: 1.28395, accuracy: 0.55400, task: max, mean loss: 0.94354, accuracy: 0.69000, task: top, mean loss: 1.18098, accuracy: 0.58200, task: multi, mean loss: 0.50500, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.97837, lr: 0.0005179322986028993
Diversity Loss - Mean: -0.13220, Variance: 0.11690
Semantic Loss - Mean: 1.08926, Variance: 0.00137

Test Epoch: 54 
task: majority, mean loss: 2.03571, accuracy: 0.39800, task: max, mean loss: 1.38918, accuracy: 0.54600, task: top, mean loss: 2.17553, accuracy: 0.39800, task: multi, mean loss: 0.52629, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.53168
Diversity Loss - Mean: -0.14093, Variance: 0.13658
Semantic Loss - Mean: 1.51120, Variance: 0.00094

Train Epoch: 55 
task: majority, mean loss: 1.31005, accuracy: 0.54900, task: max, mean loss: 0.91563, accuracy: 0.69000, task: top, mean loss: 1.19139, accuracy: 0.59400, task: multi, mean loss: 0.50148, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.97964, lr: 0.0005005
Diversity Loss - Mean: -0.13169, Variance: 0.11644
Semantic Loss - Mean: 1.10015, Variance: 0.00141

Test Epoch: 55 
task: majority, mean loss: 2.02461, accuracy: 0.35500, task: max, mean loss: 1.41929, accuracy: 0.55800, task: top, mean loss: 2.15190, accuracy: 0.38900, task: multi, mean loss: 0.52688, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.53067
Diversity Loss - Mean: -0.14136, Variance: 0.13620
Semantic Loss - Mean: 1.55639, Variance: 0.00096

Train Epoch: 56 
task: majority, mean loss: 1.21441, accuracy: 0.56800, task: max, mean loss: 0.87459, accuracy: 0.70200, task: top, mean loss: 1.07828, accuracy: 0.62100, task: multi, mean loss: 0.49547, multilabel_accuracy: 0.00100, avg. loss over tasks: 0.91569, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.13199, Variance: 0.11602
Semantic Loss - Mean: 1.03145, Variance: 0.00145

Test Epoch: 56 
task: majority, mean loss: 2.02865, accuracy: 0.37400, task: max, mean loss: 1.48446, accuracy: 0.55400, task: top, mean loss: 2.15295, accuracy: 0.40900, task: multi, mean loss: 0.53104, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.54928
Diversity Loss - Mean: -0.14138, Variance: 0.13577
Semantic Loss - Mean: 1.54821, Variance: 0.00099

Train Epoch: 57 
task: majority, mean loss: 1.13556, accuracy: 0.59400, task: max, mean loss: 0.81723, accuracy: 0.72600, task: top, mean loss: 1.02407, accuracy: 0.66100, task: multi, mean loss: 0.49072, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.86689, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.13156, Variance: 0.11565
Semantic Loss - Mean: 0.99370, Variance: 0.00149

Test Epoch: 57 
task: majority, mean loss: 2.25384, accuracy: 0.33500, task: max, mean loss: 1.51282, accuracy: 0.51300, task: top, mean loss: 2.35899, accuracy: 0.34600, task: multi, mean loss: 0.53454, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.66505
Diversity Loss - Mean: -0.14148, Variance: 0.13525
Semantic Loss - Mean: 1.62603, Variance: 0.00100

Train Epoch: 58 
task: majority, mean loss: 1.08078, accuracy: 0.61800, task: max, mean loss: 0.80070, accuracy: 0.73900, task: top, mean loss: 0.99447, accuracy: 0.65500, task: multi, mean loss: 0.48834, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.84107, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.13221, Variance: 0.11527
Semantic Loss - Mean: 0.96280, Variance: 0.00153

Test Epoch: 58 
task: majority, mean loss: 2.20953, accuracy: 0.36300, task: max, mean loss: 1.35018, accuracy: 0.56100, task: top, mean loss: 2.17425, accuracy: 0.40200, task: multi, mean loss: 0.51831, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.56307
Diversity Loss - Mean: -0.14142, Variance: 0.13484
Semantic Loss - Mean: 1.55917, Variance: 0.00102

Train Epoch: 59 
task: majority, mean loss: 1.09550, accuracy: 0.62300, task: max, mean loss: 0.77360, accuracy: 0.74300, task: top, mean loss: 0.90699, accuracy: 0.69500, task: multi, mean loss: 0.48657, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.81566, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.13231, Variance: 0.11491
Semantic Loss - Mean: 0.94774, Variance: 0.00158

Test Epoch: 59 
task: majority, mean loss: 2.33641, accuracy: 0.35100, task: max, mean loss: 1.33886, accuracy: 0.58900, task: top, mean loss: 2.34639, accuracy: 0.38200, task: multi, mean loss: 0.51200, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.63342
Diversity Loss - Mean: -0.14138, Variance: 0.13453
Semantic Loss - Mean: 1.64220, Variance: 0.00105

Train Epoch: 60 
task: majority, mean loss: 1.01110, accuracy: 0.63800, task: max, mean loss: 0.72752, accuracy: 0.76500, task: top, mean loss: 0.85238, accuracy: 0.72200, task: multi, mean loss: 0.48035, multilabel_accuracy: 0.00100, avg. loss over tasks: 0.76784, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.13104, Variance: 0.11457
Semantic Loss - Mean: 0.89678, Variance: 0.00162

Test Epoch: 60 
task: majority, mean loss: 2.14802, accuracy: 0.40900, task: max, mean loss: 1.48790, accuracy: 0.56100, task: top, mean loss: 2.28681, accuracy: 0.41100, task: multi, mean loss: 0.52945, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.61304
Diversity Loss - Mean: -0.14137, Variance: 0.13389
Semantic Loss - Mean: 1.58041, Variance: 0.00106

Train Epoch: 61 
task: majority, mean loss: 0.96138, accuracy: 0.66000, task: max, mean loss: 0.71837, accuracy: 0.75700, task: top, mean loss: 0.82290, accuracy: 0.72500, task: multi, mean loss: 0.48197, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.74616, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.13117, Variance: 0.11427
Semantic Loss - Mean: 0.88111, Variance: 0.00167

Test Epoch: 61 
task: majority, mean loss: 2.66306, accuracy: 0.36700, task: max, mean loss: 1.78786, accuracy: 0.52700, task: top, mean loss: 2.72573, accuracy: 0.37200, task: multi, mean loss: 0.54467, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.93033
Diversity Loss - Mean: -0.14146, Variance: 0.13357
Semantic Loss - Mean: 1.84110, Variance: 0.00109

Train Epoch: 62 
task: majority, mean loss: 0.96987, accuracy: 0.64000, task: max, mean loss: 0.72350, accuracy: 0.74500, task: top, mean loss: 0.82129, accuracy: 0.72700, task: multi, mean loss: 0.47871, multilabel_accuracy: 0.00300, avg. loss over tasks: 0.74834, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.13163, Variance: 0.11394
Semantic Loss - Mean: 0.87790, Variance: 0.00171

Test Epoch: 62 
task: majority, mean loss: 3.51987, accuracy: 0.19700, task: max, mean loss: 1.85326, accuracy: 0.48800, task: top, mean loss: 2.99957, accuracy: 0.29700, task: multi, mean loss: 0.56807, multilabel_accuracy: 0.00800, avg. loss over tasks: 2.23519
Diversity Loss - Mean: -0.14142, Variance: 0.13323
Semantic Loss - Mean: 2.12151, Variance: 0.00111

Train Epoch: 63 
task: majority, mean loss: 0.98088, accuracy: 0.64100, task: max, mean loss: 0.70973, accuracy: 0.77000, task: top, mean loss: 0.77672, accuracy: 0.74300, task: multi, mean loss: 0.47410, multilabel_accuracy: 0.00200, avg. loss over tasks: 0.73536, lr: 0.00036281914076940884
Diversity Loss - Mean: -0.13098, Variance: 0.11360
Semantic Loss - Mean: 0.86965, Variance: 0.00175

Test Epoch: 63 
task: majority, mean loss: 2.50982, accuracy: 0.32000, task: max, mean loss: 1.91502, accuracy: 0.48700, task: top, mean loss: 2.50919, accuracy: 0.38500, task: multi, mean loss: 0.56935, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.87585
Diversity Loss - Mean: -0.14125, Variance: 0.13247
Semantic Loss - Mean: 1.80861, Variance: 0.00115

Train Epoch: 64 
task: majority, mean loss: 0.93549, accuracy: 0.66700, task: max, mean loss: 0.67145, accuracy: 0.76900, task: top, mean loss: 0.72481, accuracy: 0.75500, task: multi, mean loss: 0.47237, multilabel_accuracy: 0.00700, avg. loss over tasks: 0.70103, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.13103, Variance: 0.11327
Semantic Loss - Mean: 0.82686, Variance: 0.00178

Test Epoch: 64 
task: majority, mean loss: 2.20569, accuracy: 0.40100, task: max, mean loss: 1.42182, accuracy: 0.57100, task: top, mean loss: 2.37897, accuracy: 0.43300, task: multi, mean loss: 0.51918, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.63141
Diversity Loss - Mean: -0.14144, Variance: 0.13200
Semantic Loss - Mean: 1.62144, Variance: 0.00117

Train Epoch: 65 
task: majority, mean loss: 0.85751, accuracy: 0.70400, task: max, mean loss: 0.62852, accuracy: 0.78600, task: top, mean loss: 0.62602, accuracy: 0.80500, task: multi, mean loss: 0.46868, multilabel_accuracy: 0.00400, avg. loss over tasks: 0.64518, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.13121, Variance: 0.11298
Semantic Loss - Mean: 0.78202, Variance: 0.00182

Test Epoch: 65 
task: majority, mean loss: 2.55719, accuracy: 0.33500, task: max, mean loss: 1.73604, accuracy: 0.51700, task: top, mean loss: 2.56983, accuracy: 0.40500, task: multi, mean loss: 0.55767, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.85518
Diversity Loss - Mean: -0.14131, Variance: 0.13133
Semantic Loss - Mean: 1.75852, Variance: 0.00119

Train Epoch: 66 
task: majority, mean loss: 0.81630, accuracy: 0.70000, task: max, mean loss: 0.58898, accuracy: 0.79700, task: top, mean loss: 0.63747, accuracy: 0.79000, task: multi, mean loss: 0.46406, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.62670, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.13101, Variance: 0.11270
Semantic Loss - Mean: 0.75475, Variance: 0.00183

Test Epoch: 66 
task: majority, mean loss: 2.25765, accuracy: 0.41100, task: max, mean loss: 1.39894, accuracy: 0.60100, task: top, mean loss: 2.42611, accuracy: 0.44500, task: multi, mean loss: 0.51588, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.64965
Diversity Loss - Mean: -0.14147, Variance: 0.13089
Semantic Loss - Mean: 1.61995, Variance: 0.00122

Train Epoch: 67 
task: majority, mean loss: 0.76067, accuracy: 0.72600, task: max, mean loss: 0.56177, accuracy: 0.80100, task: top, mean loss: 0.55707, accuracy: 0.84000, task: multi, mean loss: 0.45940, multilabel_accuracy: 0.00700, avg. loss over tasks: 0.58473, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.13111, Variance: 0.11245
Semantic Loss - Mean: 0.72317, Variance: 0.00187

Test Epoch: 67 
task: majority, mean loss: 2.41625, accuracy: 0.40700, task: max, mean loss: 1.49490, accuracy: 0.59900, task: top, mean loss: 2.61083, accuracy: 0.43200, task: multi, mean loss: 0.52391, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.76147
Diversity Loss - Mean: -0.14166, Variance: 0.13068
Semantic Loss - Mean: 1.72348, Variance: 0.00125

Train Epoch: 68 
task: majority, mean loss: 0.74421, accuracy: 0.72900, task: max, mean loss: 0.54101, accuracy: 0.81900, task: top, mean loss: 0.56464, accuracy: 0.82600, task: multi, mean loss: 0.45834, multilabel_accuracy: 0.00800, avg. loss over tasks: 0.57705, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.13086, Variance: 0.11219
Semantic Loss - Mean: 0.71791, Variance: 0.00190

Test Epoch: 68 
task: majority, mean loss: 2.46460, accuracy: 0.38900, task: max, mean loss: 1.51391, accuracy: 0.57400, task: top, mean loss: 2.62579, accuracy: 0.42600, task: multi, mean loss: 0.52712, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.78286
Diversity Loss - Mean: -0.14150, Variance: 0.13027
Semantic Loss - Mean: 1.74183, Variance: 0.00127

Train Epoch: 69 
task: majority, mean loss: 0.72548, accuracy: 0.75000, task: max, mean loss: 0.54659, accuracy: 0.82200, task: top, mean loss: 0.53637, accuracy: 0.84000, task: multi, mean loss: 0.45890, multilabel_accuracy: 0.01000, avg. loss over tasks: 0.56684, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.13138, Variance: 0.11196
Semantic Loss - Mean: 0.70942, Variance: 0.00194

Test Epoch: 69 
task: majority, mean loss: 2.46694, accuracy: 0.41200, task: max, mean loss: 1.61284, accuracy: 0.58200, task: top, mean loss: 2.67879, accuracy: 0.43900, task: multi, mean loss: 0.52972, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.82207
Diversity Loss - Mean: -0.14165, Variance: 0.13000
Semantic Loss - Mean: 1.76819, Variance: 0.00130

Train Epoch: 70 
task: majority, mean loss: 0.69352, accuracy: 0.75600, task: max, mean loss: 0.51340, accuracy: 0.82700, task: top, mean loss: 0.49507, accuracy: 0.85200, task: multi, mean loss: 0.45616, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.53954, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.13124, Variance: 0.11174
Semantic Loss - Mean: 0.68244, Variance: 0.00198

Test Epoch: 70 
task: majority, mean loss: 2.61927, accuracy: 0.38100, task: max, mean loss: 1.51663, accuracy: 0.58400, task: top, mean loss: 2.69520, accuracy: 0.42300, task: multi, mean loss: 0.52641, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.83938
Diversity Loss - Mean: -0.14142, Variance: 0.12960
Semantic Loss - Mean: 1.76075, Variance: 0.00133

Train Epoch: 71 
task: majority, mean loss: 0.67396, accuracy: 0.75800, task: max, mean loss: 0.51403, accuracy: 0.82100, task: top, mean loss: 0.49344, accuracy: 0.86900, task: multi, mean loss: 0.45492, multilabel_accuracy: 0.00900, avg. loss over tasks: 0.53409, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.13135, Variance: 0.11153
Semantic Loss - Mean: 0.66665, Variance: 0.00201

Test Epoch: 71 
task: majority, mean loss: 2.45807, accuracy: 0.40500, task: max, mean loss: 1.55850, accuracy: 0.57700, task: top, mean loss: 2.70629, accuracy: 0.44000, task: multi, mean loss: 0.52908, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.81299
Diversity Loss - Mean: -0.14166, Variance: 0.12931
Semantic Loss - Mean: 1.74998, Variance: 0.00136

Train Epoch: 72 
task: majority, mean loss: 0.66776, accuracy: 0.76600, task: max, mean loss: 0.50469, accuracy: 0.82600, task: top, mean loss: 0.50564, accuracy: 0.85100, task: multi, mean loss: 0.45143, multilabel_accuracy: 0.00800, avg. loss over tasks: 0.53238, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.13093, Variance: 0.11135
Semantic Loss - Mean: 0.66150, Variance: 0.00204

Test Epoch: 72 
task: majority, mean loss: 2.50517, accuracy: 0.38900, task: max, mean loss: 1.59927, accuracy: 0.58400, task: top, mean loss: 2.68404, accuracy: 0.44700, task: multi, mean loss: 0.53037, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.82971
Diversity Loss - Mean: -0.14159, Variance: 0.12894
Semantic Loss - Mean: 1.75595, Variance: 0.00138

Train Epoch: 73 
task: majority, mean loss: 0.60525, accuracy: 0.78500, task: max, mean loss: 0.43648, accuracy: 0.85200, task: top, mean loss: 0.42993, accuracy: 0.87400, task: multi, mean loss: 0.44689, multilabel_accuracy: 0.01100, avg. loss over tasks: 0.47964, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.13097, Variance: 0.11116
Semantic Loss - Mean: 0.61992, Variance: 0.00207

Test Epoch: 73 
task: majority, mean loss: 2.75379, accuracy: 0.36800, task: max, mean loss: 1.58196, accuracy: 0.59400, task: top, mean loss: 2.80268, accuracy: 0.42900, task: multi, mean loss: 0.52968, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.91703
Diversity Loss - Mean: -0.14171, Variance: 0.12879
Semantic Loss - Mean: 1.88808, Variance: 0.00142

Train Epoch: 74 
task: majority, mean loss: 0.58003, accuracy: 0.79000, task: max, mean loss: 0.44123, accuracy: 0.84100, task: top, mean loss: 0.40418, accuracy: 0.88500, task: multi, mean loss: 0.44703, multilabel_accuracy: 0.00800, avg. loss over tasks: 0.46812, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.13104, Variance: 0.11097
Semantic Loss - Mean: 0.61064, Variance: 0.00210

Test Epoch: 74 
task: majority, mean loss: 2.61120, accuracy: 0.40500, task: max, mean loss: 1.76434, accuracy: 0.57500, task: top, mean loss: 2.78709, accuracy: 0.45300, task: multi, mean loss: 0.53967, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.92558
Diversity Loss - Mean: -0.14172, Variance: 0.12865
Semantic Loss - Mean: 1.86550, Variance: 0.00143

Train Epoch: 75 
task: majority, mean loss: 0.53739, accuracy: 0.80600, task: max, mean loss: 0.39596, accuracy: 0.86400, task: top, mean loss: 0.34705, accuracy: 0.91800, task: multi, mean loss: 0.44462, multilabel_accuracy: 0.01000, avg. loss over tasks: 0.43125, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.13035, Variance: 0.11079
Semantic Loss - Mean: 0.57422, Variance: 0.00212

Test Epoch: 75 
task: majority, mean loss: 2.99643, accuracy: 0.38200, task: max, mean loss: 2.17514, accuracy: 0.53300, task: top, mean loss: 3.05625, accuracy: 0.42100, task: multi, mean loss: 0.57124, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.19976
Diversity Loss - Mean: -0.14181, Variance: 0.12862
Semantic Loss - Mean: 2.12077, Variance: 0.00146

Train Epoch: 76 
task: majority, mean loss: 0.49803, accuracy: 0.83000, task: max, mean loss: 0.39800, accuracy: 0.86300, task: top, mean loss: 0.34051, accuracy: 0.92100, task: multi, mean loss: 0.44487, multilabel_accuracy: 0.00500, avg. loss over tasks: 0.42035, lr: 0.0001662692621237503
Diversity Loss - Mean: -0.13026, Variance: 0.11064
Semantic Loss - Mean: 0.56259, Variance: 0.00214

Test Epoch: 76 
task: majority, mean loss: 2.86933, accuracy: 0.38700, task: max, mean loss: 1.70204, accuracy: 0.58600, task: top, mean loss: 2.87305, accuracy: 0.42600, task: multi, mean loss: 0.53680, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.99530
Diversity Loss - Mean: -0.14178, Variance: 0.12851
Semantic Loss - Mean: 1.94489, Variance: 0.00148

Train Epoch: 77 
task: majority, mean loss: 0.52072, accuracy: 0.82100, task: max, mean loss: 0.38949, accuracy: 0.86700, task: top, mean loss: 0.33986, accuracy: 0.91900, task: multi, mean loss: 0.44343, multilabel_accuracy: 0.01300, avg. loss over tasks: 0.42338, lr: 0.000153518143955731
Diversity Loss - Mean: -0.13058, Variance: 0.11050
Semantic Loss - Mean: 0.56468, Variance: 0.00216

Test Epoch: 77 
task: majority, mean loss: 2.79104, accuracy: 0.40100, task: max, mean loss: 1.84644, accuracy: 0.57100, task: top, mean loss: 2.95024, accuracy: 0.43800, task: multi, mean loss: 0.54531, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.03326
Diversity Loss - Mean: -0.14172, Variance: 0.12838
Semantic Loss - Mean: 1.95445, Variance: 0.00150

Train Epoch: 78 
task: majority, mean loss: 0.48318, accuracy: 0.83200, task: max, mean loss: 0.37642, accuracy: 0.87700, task: top, mean loss: 0.32606, accuracy: 0.91700, task: multi, mean loss: 0.44266, multilabel_accuracy: 0.01000, avg. loss over tasks: 0.40708, lr: 0.00014118976973084374
Diversity Loss - Mean: -0.13081, Variance: 0.11036
Semantic Loss - Mean: 0.54656, Variance: 0.00218

Test Epoch: 78 
task: majority, mean loss: 2.76910, accuracy: 0.40600, task: max, mean loss: 1.79359, accuracy: 0.57300, task: top, mean loss: 2.91601, accuracy: 0.44800, task: multi, mean loss: 0.53964, multilabel_accuracy: 0.00900, avg. loss over tasks: 2.00458
Diversity Loss - Mean: -0.14174, Variance: 0.12822
Semantic Loss - Mean: 1.93012, Variance: 0.00153

Train Epoch: 79 
task: majority, mean loss: 0.45474, accuracy: 0.85100, task: max, mean loss: 0.35911, accuracy: 0.87300, task: top, mean loss: 0.29339, accuracy: 0.93000, task: multi, mean loss: 0.43944, multilabel_accuracy: 0.01100, avg. loss over tasks: 0.38667, lr: 0.0001292991596740417
Diversity Loss - Mean: -0.13129, Variance: 0.11025
Semantic Loss - Mean: 0.52600, Variance: 0.00220

Test Epoch: 79 
task: majority, mean loss: 2.76934, accuracy: 0.39800, task: max, mean loss: 1.76127, accuracy: 0.55800, task: top, mean loss: 2.88147, accuracy: 0.45000, task: multi, mean loss: 0.53737, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.98736
Diversity Loss - Mean: -0.14170, Variance: 0.12803
Semantic Loss - Mean: 1.92487, Variance: 0.00155

Train Epoch: 80 
task: majority, mean loss: 0.42025, accuracy: 0.86100, task: max, mean loss: 0.36299, accuracy: 0.87100, task: top, mean loss: 0.27684, accuracy: 0.93900, task: multi, mean loss: 0.43949, multilabel_accuracy: 0.01300, avg. loss over tasks: 0.37489, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.13066, Variance: 0.11013
Semantic Loss - Mean: 0.51271, Variance: 0.00222

Test Epoch: 80 
task: majority, mean loss: 2.92122, accuracy: 0.38400, task: max, mean loss: 1.68795, accuracy: 0.59800, task: top, mean loss: 2.97551, accuracy: 0.43500, task: multi, mean loss: 0.53168, multilabel_accuracy: 0.00900, avg. loss over tasks: 2.02909
Diversity Loss - Mean: -0.14177, Variance: 0.12788
Semantic Loss - Mean: 1.96110, Variance: 0.00156

Train Epoch: 81 
task: majority, mean loss: 0.41714, accuracy: 0.85100, task: max, mean loss: 0.33715, accuracy: 0.87800, task: top, mean loss: 0.28619, accuracy: 0.94100, task: multi, mean loss: 0.43948, multilabel_accuracy: 0.01200, avg. loss over tasks: 0.36999, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.13101, Variance: 0.11002
Semantic Loss - Mean: 0.51328, Variance: 0.00224

Test Epoch: 81 
task: majority, mean loss: 2.83953, accuracy: 0.39700, task: max, mean loss: 1.76623, accuracy: 0.57400, task: top, mean loss: 2.98858, accuracy: 0.44200, task: multi, mean loss: 0.53662, multilabel_accuracy: 0.00800, avg. loss over tasks: 2.03274
Diversity Loss - Mean: -0.14179, Variance: 0.12774
Semantic Loss - Mean: 1.95050, Variance: 0.00159

Train Epoch: 82 
task: majority, mean loss: 0.40876, accuracy: 0.85400, task: max, mean loss: 0.33735, accuracy: 0.89300, task: top, mean loss: 0.26074, accuracy: 0.94600, task: multi, mean loss: 0.43800, multilabel_accuracy: 0.01400, avg. loss over tasks: 0.36121, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.13053, Variance: 0.10990
Semantic Loss - Mean: 0.50520, Variance: 0.00227

Test Epoch: 82 
task: majority, mean loss: 2.93794, accuracy: 0.39000, task: max, mean loss: 1.78722, accuracy: 0.57600, task: top, mean loss: 3.00274, accuracy: 0.44000, task: multi, mean loss: 0.53869, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.06665
Diversity Loss - Mean: -0.14174, Variance: 0.12755
Semantic Loss - Mean: 1.98309, Variance: 0.00162

Train Epoch: 83 
task: majority, mean loss: 0.38309, accuracy: 0.86500, task: max, mean loss: 0.32529, accuracy: 0.88700, task: top, mean loss: 0.23533, accuracy: 0.95400, task: multi, mean loss: 0.43745, multilabel_accuracy: 0.01600, avg. loss over tasks: 0.34529, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.13132, Variance: 0.10982
Semantic Loss - Mean: 0.48518, Variance: 0.00228

Test Epoch: 83 
task: majority, mean loss: 2.94002, accuracy: 0.40300, task: max, mean loss: 1.86047, accuracy: 0.58300, task: top, mean loss: 3.08062, accuracy: 0.43600, task: multi, mean loss: 0.54329, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.10610
Diversity Loss - Mean: -0.14178, Variance: 0.12744
Semantic Loss - Mean: 2.00309, Variance: 0.00164

Train Epoch: 84 
task: majority, mean loss: 0.36900, accuracy: 0.87800, task: max, mean loss: 0.31122, accuracy: 0.88900, task: top, mean loss: 0.22986, accuracy: 0.95800, task: multi, mean loss: 0.43384, multilabel_accuracy: 0.01000, avg. loss over tasks: 0.33598, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.13097, Variance: 0.10972
Semantic Loss - Mean: 0.47812, Variance: 0.00230

Test Epoch: 84 
task: majority, mean loss: 2.95407, accuracy: 0.39200, task: max, mean loss: 1.83011, accuracy: 0.58100, task: top, mean loss: 3.02323, accuracy: 0.43800, task: multi, mean loss: 0.54059, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.08700
Diversity Loss - Mean: -0.14180, Variance: 0.12731
Semantic Loss - Mean: 2.00186, Variance: 0.00166

Train Epoch: 85 
task: majority, mean loss: 0.37705, accuracy: 0.86700, task: max, mean loss: 0.31266, accuracy: 0.89900, task: top, mean loss: 0.24119, accuracy: 0.95100, task: multi, mean loss: 0.43474, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.34141, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.13072, Variance: 0.10962
Semantic Loss - Mean: 0.47994, Variance: 0.00231

Test Epoch: 85 
task: majority, mean loss: 2.99540, accuracy: 0.40900, task: max, mean loss: 1.95215, accuracy: 0.56900, task: top, mean loss: 3.10540, accuracy: 0.43400, task: multi, mean loss: 0.55084, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.15095
Diversity Loss - Mean: -0.14183, Variance: 0.12723
Semantic Loss - Mean: 2.06372, Variance: 0.00168

Train Epoch: 86 
task: majority, mean loss: 0.34978, accuracy: 0.88100, task: max, mean loss: 0.31187, accuracy: 0.89200, task: top, mean loss: 0.22077, accuracy: 0.95700, task: multi, mean loss: 0.43410, multilabel_accuracy: 0.01600, avg. loss over tasks: 0.32913, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.13112, Variance: 0.10953
Semantic Loss - Mean: 0.46580, Variance: 0.00233

Test Epoch: 86 
task: majority, mean loss: 2.95225, accuracy: 0.40300, task: max, mean loss: 1.89389, accuracy: 0.57800, task: top, mean loss: 3.07424, accuracy: 0.44900, task: multi, mean loss: 0.54586, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.11656
Diversity Loss - Mean: -0.14182, Variance: 0.12711
Semantic Loss - Mean: 2.02637, Variance: 0.00170

Train Epoch: 87 
task: majority, mean loss: 0.33297, accuracy: 0.88900, task: max, mean loss: 0.30162, accuracy: 0.90000, task: top, mean loss: 0.21205, accuracy: 0.96400, task: multi, mean loss: 0.43324, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.31997, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.13110, Variance: 0.10945
Semantic Loss - Mean: 0.46106, Variance: 0.00235

Test Epoch: 87 
task: majority, mean loss: 3.01800, accuracy: 0.38200, task: max, mean loss: 1.81972, accuracy: 0.58200, task: top, mean loss: 3.09637, accuracy: 0.43200, task: multi, mean loss: 0.54036, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.11861
Diversity Loss - Mean: -0.14180, Variance: 0.12697
Semantic Loss - Mean: 2.03590, Variance: 0.00172

Train Epoch: 88 
task: majority, mean loss: 0.32225, accuracy: 0.88800, task: max, mean loss: 0.28812, accuracy: 0.90600, task: top, mean loss: 0.21402, accuracy: 0.96300, task: multi, mean loss: 0.43222, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.31415, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.13088, Variance: 0.10935
Semantic Loss - Mean: 0.45408, Variance: 0.00236

Test Epoch: 88 
task: majority, mean loss: 2.98247, accuracy: 0.40800, task: max, mean loss: 1.91240, accuracy: 0.57500, task: top, mean loss: 3.09660, accuracy: 0.44200, task: multi, mean loss: 0.54747, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.13473
Diversity Loss - Mean: -0.14183, Variance: 0.12687
Semantic Loss - Mean: 2.04701, Variance: 0.00173

Train Epoch: 89 
task: majority, mean loss: 0.32201, accuracy: 0.89900, task: max, mean loss: 0.28136, accuracy: 0.91000, task: top, mean loss: 0.20560, accuracy: 0.96300, task: multi, mean loss: 0.43236, multilabel_accuracy: 0.01800, avg. loss over tasks: 0.31034, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.13103, Variance: 0.10927
Semantic Loss - Mean: 0.44992, Variance: 0.00238

Test Epoch: 89 
task: majority, mean loss: 2.98329, accuracy: 0.39300, task: max, mean loss: 1.89659, accuracy: 0.56900, task: top, mean loss: 3.09295, accuracy: 0.44000, task: multi, mean loss: 0.54663, multilabel_accuracy: 0.00500, avg. loss over tasks: 2.12987
Diversity Loss - Mean: -0.14180, Variance: 0.12674
Semantic Loss - Mean: 2.04008, Variance: 0.00175

Train Epoch: 90 
task: majority, mean loss: 0.30914, accuracy: 0.90500, task: max, mean loss: 0.27910, accuracy: 0.91000, task: top, mean loss: 0.20352, accuracy: 0.96100, task: multi, mean loss: 0.43055, multilabel_accuracy: 0.01800, avg. loss over tasks: 0.30558, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.13062, Variance: 0.10918
Semantic Loss - Mean: 0.44902, Variance: 0.00240

Test Epoch: 90 
task: majority, mean loss: 2.97745, accuracy: 0.39500, task: max, mean loss: 1.89580, accuracy: 0.57100, task: top, mean loss: 3.10218, accuracy: 0.44200, task: multi, mean loss: 0.54623, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.13042
Diversity Loss - Mean: -0.14179, Variance: 0.12661
Semantic Loss - Mean: 2.03382, Variance: 0.00177

Train Epoch: 91 
task: majority, mean loss: 0.30454, accuracy: 0.89700, task: max, mean loss: 0.27748, accuracy: 0.90600, task: top, mean loss: 0.18847, accuracy: 0.97300, task: multi, mean loss: 0.43160, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.30052, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.13028, Variance: 0.10908
Semantic Loss - Mean: 0.44199, Variance: 0.00241

Test Epoch: 91 
task: majority, mean loss: 3.00125, accuracy: 0.39400, task: max, mean loss: 1.90659, accuracy: 0.57900, task: top, mean loss: 3.10942, accuracy: 0.44700, task: multi, mean loss: 0.54749, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.14119
Diversity Loss - Mean: -0.14181, Variance: 0.12650
Semantic Loss - Mean: 2.04530, Variance: 0.00179

Train Epoch: 92 
task: majority, mean loss: 0.30375, accuracy: 0.91000, task: max, mean loss: 0.29215, accuracy: 0.89600, task: top, mean loss: 0.19372, accuracy: 0.96800, task: multi, mean loss: 0.43144, multilabel_accuracy: 0.01700, avg. loss over tasks: 0.30526, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.13131, Variance: 0.10901
Semantic Loss - Mean: 0.43931, Variance: 0.00242

Test Epoch: 92 
task: majority, mean loss: 3.00834, accuracy: 0.40500, task: max, mean loss: 1.92546, accuracy: 0.57800, task: top, mean loss: 3.11839, accuracy: 0.44500, task: multi, mean loss: 0.54799, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.15005
Diversity Loss - Mean: -0.14181, Variance: 0.12639
Semantic Loss - Mean: 2.05312, Variance: 0.00181

Train Epoch: 93 
task: majority, mean loss: 0.29653, accuracy: 0.90700, task: max, mean loss: 0.28538, accuracy: 0.90200, task: top, mean loss: 0.18724, accuracy: 0.97000, task: multi, mean loss: 0.43095, multilabel_accuracy: 0.01700, avg. loss over tasks: 0.30003, lr: 1.583728472513976e-05
Diversity Loss - Mean: -0.13102, Variance: 0.10893
Semantic Loss - Mean: 0.43658, Variance: 0.00243

Test Epoch: 93 
task: majority, mean loss: 3.03050, accuracy: 0.39700, task: max, mean loss: 1.90297, accuracy: 0.57900, task: top, mean loss: 3.11991, accuracy: 0.44300, task: multi, mean loss: 0.54676, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.15004
Diversity Loss - Mean: -0.14181, Variance: 0.12628
Semantic Loss - Mean: 2.05291, Variance: 0.00183

Train Epoch: 94 
task: majority, mean loss: 0.29712, accuracy: 0.90700, task: max, mean loss: 0.25730, accuracy: 0.91600, task: top, mean loss: 0.19119, accuracy: 0.96900, task: multi, mean loss: 0.42985, multilabel_accuracy: 0.01700, avg. loss over tasks: 0.29386, lr: 1.1915273433464114e-05
Diversity Loss - Mean: -0.13149, Variance: 0.10886
Semantic Loss - Mean: 0.43556, Variance: 0.00245

Test Epoch: 94 
task: majority, mean loss: 3.04748, accuracy: 0.39400, task: max, mean loss: 1.90850, accuracy: 0.57700, task: top, mean loss: 3.12654, accuracy: 0.44100, task: multi, mean loss: 0.54762, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.15753
Diversity Loss - Mean: -0.14181, Variance: 0.12618
Semantic Loss - Mean: 2.06158, Variance: 0.00184

Train Epoch: 95 
task: majority, mean loss: 0.29439, accuracy: 0.90500, task: max, mean loss: 0.25680, accuracy: 0.91800, task: top, mean loss: 0.18921, accuracy: 0.96300, task: multi, mean loss: 0.42952, multilabel_accuracy: 0.01600, avg. loss over tasks: 0.29248, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.13060, Variance: 0.10878
Semantic Loss - Mean: 0.43269, Variance: 0.00246

Test Epoch: 95 
task: majority, mean loss: 3.04237, accuracy: 0.39900, task: max, mean loss: 1.90513, accuracy: 0.58400, task: top, mean loss: 3.13315, accuracy: 0.44500, task: multi, mean loss: 0.54701, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.15691
Diversity Loss - Mean: -0.14181, Variance: 0.12608
Semantic Loss - Mean: 2.05748, Variance: 0.00186

Train Epoch: 96 
task: majority, mean loss: 0.29558, accuracy: 0.90600, task: max, mean loss: 0.26444, accuracy: 0.91500, task: top, mean loss: 0.18399, accuracy: 0.96800, task: multi, mean loss: 0.43099, multilabel_accuracy: 0.01800, avg. loss over tasks: 0.29375, lr: 5.861099663585604e-06
Diversity Loss - Mean: -0.13087, Variance: 0.10872
Semantic Loss - Mean: 0.42755, Variance: 0.00247

Test Epoch: 96 
task: majority, mean loss: 3.04618, accuracy: 0.39600, task: max, mean loss: 1.91156, accuracy: 0.58100, task: top, mean loss: 3.13690, accuracy: 0.44100, task: multi, mean loss: 0.54733, multilabel_accuracy: 0.01000, avg. loss over tasks: 2.16050
Diversity Loss - Mean: -0.14182, Variance: 0.12598
Semantic Loss - Mean: 2.06370, Variance: 0.00188

Train Epoch: 97 
task: majority, mean loss: 0.29964, accuracy: 0.91300, task: max, mean loss: 0.26409, accuracy: 0.91300, task: top, mean loss: 0.17490, accuracy: 0.97200, task: multi, mean loss: 0.43019, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.29220, lr: 3.736313263547436e-06
Diversity Loss - Mean: -0.13073, Variance: 0.10865
Semantic Loss - Mean: 0.43326, Variance: 0.00248

Test Epoch: 97 
task: majority, mean loss: 3.03353, accuracy: 0.39600, task: max, mean loss: 1.92988, accuracy: 0.58000, task: top, mean loss: 3.13527, accuracy: 0.44900, task: multi, mean loss: 0.54867, multilabel_accuracy: 0.00400, avg. loss over tasks: 2.16184
Diversity Loss - Mean: -0.14180, Variance: 0.12588
Semantic Loss - Mean: 2.06107, Variance: 0.00189

Train Epoch: 98 
task: majority, mean loss: 0.29368, accuracy: 0.91200, task: max, mean loss: 0.26912, accuracy: 0.91700, task: top, mean loss: 0.19147, accuracy: 0.96300, task: multi, mean loss: 0.43106, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.29633, lr: 2.2167568952178134e-06
Diversity Loss - Mean: -0.13106, Variance: 0.10858
Semantic Loss - Mean: 0.43178, Variance: 0.00249

Test Epoch: 98 
task: majority, mean loss: 3.03684, accuracy: 0.39700, task: max, mean loss: 1.91961, accuracy: 0.58100, task: top, mean loss: 3.13306, accuracy: 0.44300, task: multi, mean loss: 0.54819, multilabel_accuracy: 0.00700, avg. loss over tasks: 2.15942
Diversity Loss - Mean: -0.14181, Variance: 0.12578
Semantic Loss - Mean: 2.06037, Variance: 0.00191

Train Epoch: 99 
task: majority, mean loss: 0.29142, accuracy: 0.91200, task: max, mean loss: 0.26638, accuracy: 0.92400, task: top, mean loss: 0.18942, accuracy: 0.96800, task: multi, mean loss: 0.42879, multilabel_accuracy: 0.01400, avg. loss over tasks: 0.29400, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.13134, Variance: 0.10851
Semantic Loss - Mean: 0.43136, Variance: 0.00250

Test Epoch: 99 
task: majority, mean loss: 3.04140, accuracy: 0.39600, task: max, mean loss: 1.90632, accuracy: 0.57900, task: top, mean loss: 3.13165, accuracy: 0.44500, task: multi, mean loss: 0.54751, multilabel_accuracy: 0.00600, avg. loss over tasks: 2.15672
Diversity Loss - Mean: -0.14181, Variance: 0.12569
Semantic Loss - Mean: 2.05993, Variance: 0.00192

Train Epoch: 100 
task: majority, mean loss: 0.29372, accuracy: 0.90500, task: max, mean loss: 0.25381, accuracy: 0.91400, task: top, mean loss: 0.18635, accuracy: 0.96800, task: multi, mean loss: 0.42914, multilabel_accuracy: 0.01600, avg. loss over tasks: 0.29075, lr: 1e-06
Diversity Loss - Mean: -0.13113, Variance: 0.10844
Semantic Loss - Mean: 0.43334, Variance: 0.00252

Test Epoch: 100 
task: majority, mean loss: 3.04275, accuracy: 0.39400, task: max, mean loss: 1.90855, accuracy: 0.58000, task: top, mean loss: 3.13413, accuracy: 0.44300, task: multi, mean loss: 0.54752, multilabel_accuracy: 0.00800, avg. loss over tasks: 2.15824
Diversity Loss - Mean: -0.14182, Variance: 0.12560
Semantic Loss - Mean: 2.06150, Variance: 0.00194

