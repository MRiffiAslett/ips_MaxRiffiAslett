Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 900,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 30,
 'mask_p': 0.2,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.33609, accuracy: 0.10420, task: max, mean loss: 2.01532, accuracy: 0.24820, task: top, mean loss: 2.33928, accuracy: 0.09720, task: multi, mean loss: 0.65038, multilabel_accuracy: 0.00120, avg. loss over tasks: 1.83527, lr: 0.0001
Diversity Loss - Mean: -0.11698, Variance: 0.08616
Semantic Loss - Mean: 1.89968, Variance: 0.00385

Test Epoch: 1 
task: majority, mean loss: 2.31525, accuracy: 0.09200, task: max, mean loss: 1.87286, accuracy: 0.21300, task: top, mean loss: 2.30653, accuracy: 0.10800, task: multi, mean loss: 0.60280, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77436
Diversity Loss - Mean: -0.14222, Variance: 0.11685
Semantic Loss - Mean: 1.78450, Variance: 0.00020

Train Epoch: 2 
task: majority, mean loss: 2.32835, accuracy: 0.10020, task: max, mean loss: 1.82881, accuracy: 0.26040, task: top, mean loss: 2.32520, accuracy: 0.10280, task: multi, mean loss: 0.60400, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77159, lr: 0.0002
Diversity Loss - Mean: -0.14194, Variance: 0.10797
Semantic Loss - Mean: 1.76808, Variance: 0.00201

Test Epoch: 2 
task: majority, mean loss: 2.32302, accuracy: 0.08900, task: max, mean loss: 1.86228, accuracy: 0.27400, task: top, mean loss: 2.32274, accuracy: 0.10100, task: multi, mean loss: 0.60090, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77723
Diversity Loss - Mean: -0.14217, Variance: 0.12644
Semantic Loss - Mean: 1.77210, Variance: 0.00011

Train Epoch: 3 
task: majority, mean loss: 2.31782, accuracy: 0.10640, task: max, mean loss: 1.82886, accuracy: 0.26700, task: top, mean loss: 2.32394, accuracy: 0.09920, task: multi, mean loss: 0.60430, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76873, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14191, Variance: 0.11660
Semantic Loss - Mean: 1.76459, Variance: 0.00139

Test Epoch: 3 
task: majority, mean loss: 2.35290, accuracy: 0.10900, task: max, mean loss: 1.86437, accuracy: 0.27400, task: top, mean loss: 2.32381, accuracy: 0.10900, task: multi, mean loss: 0.60340, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78612
Diversity Loss - Mean: -0.13615, Variance: 0.12837
Semantic Loss - Mean: 1.77651, Variance: 0.00012

Train Epoch: 4 
task: majority, mean loss: 2.24458, accuracy: 0.13780, task: max, mean loss: 1.82565, accuracy: 0.26180, task: top, mean loss: 2.29265, accuracy: 0.12220, task: multi, mean loss: 0.60255, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.74136, lr: 0.0004
Diversity Loss - Mean: -0.13967, Variance: 0.11791
Semantic Loss - Mean: 1.75514, Variance: 0.00109

Test Epoch: 4 
task: majority, mean loss: 2.17534, accuracy: 0.17000, task: max, mean loss: 1.86557, accuracy: 0.26800, task: top, mean loss: 2.24461, accuracy: 0.17500, task: multi, mean loss: 0.59553, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72026
Diversity Loss - Mean: -0.14085, Variance: 0.12907
Semantic Loss - Mean: 1.73855, Variance: 0.00017

Train Epoch: 5 
task: majority, mean loss: 2.17627, accuracy: 0.18300, task: max, mean loss: 1.80036, accuracy: 0.27660, task: top, mean loss: 2.25034, accuracy: 0.15480, task: multi, mean loss: 0.59205, multilabel_accuracy: 0.00060, avg. loss over tasks: 1.70476, lr: 0.0005
Diversity Loss - Mean: -0.13858, Variance: 0.12322
Semantic Loss - Mean: 1.71788, Variance: 0.00097

Test Epoch: 5 
task: majority, mean loss: 2.19151, accuracy: 0.18000, task: max, mean loss: 1.84040, accuracy: 0.27300, task: top, mean loss: 2.26036, accuracy: 0.14800, task: multi, mean loss: 0.59125, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72088
Diversity Loss - Mean: -0.14219, Variance: 0.13382
Semantic Loss - Mean: 1.72809, Variance: 0.00016

Train Epoch: 6 
task: majority, mean loss: 2.11972, accuracy: 0.20500, task: max, mean loss: 1.78673, accuracy: 0.27300, task: top, mean loss: 2.21773, accuracy: 0.16860, task: multi, mean loss: 0.58334, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.67688, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.13936, Variance: 0.12841
Semantic Loss - Mean: 1.68887, Variance: 0.00089

Test Epoch: 6 
task: majority, mean loss: 2.18054, accuracy: 0.21100, task: max, mean loss: 1.84698, accuracy: 0.27200, task: top, mean loss: 2.24667, accuracy: 0.19000, task: multi, mean loss: 0.59368, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.71697
Diversity Loss - Mean: -0.14087, Variance: 0.13807
Semantic Loss - Mean: 1.71820, Variance: 0.00025

Train Epoch: 7 
task: majority, mean loss: 2.10279, accuracy: 0.24020, task: max, mean loss: 1.76758, accuracy: 0.28740, task: top, mean loss: 2.20690, accuracy: 0.18860, task: multi, mean loss: 0.58045, multilabel_accuracy: 0.00160, avg. loss over tasks: 1.66443, lr: 0.0007
Diversity Loss - Mean: -0.13805, Variance: 0.13045
Semantic Loss - Mean: 1.68963, Variance: 0.00085

Test Epoch: 7 
task: majority, mean loss: 2.12394, accuracy: 0.23500, task: max, mean loss: 1.81947, accuracy: 0.28300, task: top, mean loss: 2.24649, accuracy: 0.16800, task: multi, mean loss: 0.58122, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.69278
Diversity Loss - Mean: -0.13996, Variance: 0.14000
Semantic Loss - Mean: 1.71218, Variance: 0.00028

Train Epoch: 8 
task: majority, mean loss: 2.03322, accuracy: 0.28680, task: max, mean loss: 1.74064, accuracy: 0.30900, task: top, mean loss: 2.13590, accuracy: 0.24000, task: multi, mean loss: 0.56902, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.61969, lr: 0.0008
Diversity Loss - Mean: -0.13668, Variance: 0.13097
Semantic Loss - Mean: 1.65431, Variance: 0.00086

Test Epoch: 8 
task: majority, mean loss: 2.12244, accuracy: 0.19400, task: max, mean loss: 1.82106, accuracy: 0.28400, task: top, mean loss: 2.16796, accuracy: 0.21200, task: multi, mean loss: 0.57940, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.67272
Diversity Loss - Mean: -0.14014, Variance: 0.14110
Semantic Loss - Mean: 1.68154, Variance: 0.00031

Train Epoch: 9 
task: majority, mean loss: 1.92446, accuracy: 0.33660, task: max, mean loss: 1.67628, accuracy: 0.35080, task: top, mean loss: 2.06183, accuracy: 0.27880, task: multi, mean loss: 0.56283, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.55635, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.13636, Variance: 0.13105
Semantic Loss - Mean: 1.59928, Variance: 0.00089

Test Epoch: 9 
task: majority, mean loss: 2.03133, accuracy: 0.28100, task: max, mean loss: 1.76567, accuracy: 0.32600, task: top, mean loss: 2.16404, accuracy: 0.22900, task: multi, mean loss: 0.56870, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.63243
Diversity Loss - Mean: -0.14036, Variance: 0.14196
Semantic Loss - Mean: 1.64231, Variance: 0.00037

Train Epoch: 10 
task: majority, mean loss: 1.84198, accuracy: 0.37980, task: max, mean loss: 1.57715, accuracy: 0.39240, task: top, mean loss: 1.98999, accuracy: 0.30920, task: multi, mean loss: 0.55177, multilabel_accuracy: 0.00420, avg. loss over tasks: 1.49022, lr: 0.001
Diversity Loss - Mean: -0.13665, Variance: 0.13112
Semantic Loss - Mean: 1.53224, Variance: 0.00093

Test Epoch: 10 
task: majority, mean loss: 2.18884, accuracy: 0.26800, task: max, mean loss: 1.77963, accuracy: 0.31800, task: top, mean loss: 2.27310, accuracy: 0.23200, task: multi, mean loss: 0.58828, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.70746
Diversity Loss - Mean: -0.14160, Variance: 0.14457
Semantic Loss - Mean: 1.73632, Variance: 0.00042

Train Epoch: 11 
task: majority, mean loss: 1.77806, accuracy: 0.40640, task: max, mean loss: 1.50849, accuracy: 0.43280, task: top, mean loss: 1.95772, accuracy: 0.33000, task: multi, mean loss: 0.54316, multilabel_accuracy: 0.00560, avg. loss over tasks: 1.44685, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.13679, Variance: 0.13110
Semantic Loss - Mean: 1.49378, Variance: 0.00098

Test Epoch: 11 
task: majority, mean loss: 1.86829, accuracy: 0.38400, task: max, mean loss: 1.60452, accuracy: 0.39400, task: top, mean loss: 1.98708, accuracy: 0.32000, task: multi, mean loss: 0.55115, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.50276
Diversity Loss - Mean: -0.14190, Variance: 0.14436
Semantic Loss - Mean: 1.55036, Variance: 0.00043

Train Epoch: 12 
task: majority, mean loss: 1.75534, accuracy: 0.43260, task: max, mean loss: 1.47803, accuracy: 0.44160, task: top, mean loss: 1.95079, accuracy: 0.34420, task: multi, mean loss: 0.53514, multilabel_accuracy: 0.00760, avg. loss over tasks: 1.42983, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.13606, Variance: 0.13105
Semantic Loss - Mean: 1.47140, Variance: 0.00104

Test Epoch: 12 
task: majority, mean loss: 1.73434, accuracy: 0.45400, task: max, mean loss: 1.44512, accuracy: 0.45200, task: top, mean loss: 1.91722, accuracy: 0.35500, task: multi, mean loss: 0.52491, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.40540
Diversity Loss - Mean: -0.14160, Variance: 0.14431
Semantic Loss - Mean: 1.42509, Variance: 0.00044

Train Epoch: 13 
task: majority, mean loss: 1.71798, accuracy: 0.43800, task: max, mean loss: 1.43583, accuracy: 0.46020, task: top, mean loss: 1.86459, accuracy: 0.38740, task: multi, mean loss: 0.52864, multilabel_accuracy: 0.00740, avg. loss over tasks: 1.38676, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.13591, Variance: 0.13105
Semantic Loss - Mean: 1.42938, Variance: 0.00110

Test Epoch: 13 
task: majority, mean loss: 1.69326, accuracy: 0.43800, task: max, mean loss: 1.46766, accuracy: 0.44800, task: top, mean loss: 1.90656, accuracy: 0.36900, task: multi, mean loss: 0.52741, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.39872
Diversity Loss - Mean: -0.14178, Variance: 0.14423
Semantic Loss - Mean: 1.42143, Variance: 0.00046

Train Epoch: 14 
task: majority, mean loss: 1.66971, accuracy: 0.46040, task: max, mean loss: 1.42711, accuracy: 0.46060, task: top, mean loss: 1.88124, accuracy: 0.37780, task: multi, mean loss: 0.52394, multilabel_accuracy: 0.00940, avg. loss over tasks: 1.37550, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.13616, Variance: 0.13091
Semantic Loss - Mean: 1.42557, Variance: 0.00114

Test Epoch: 14 
task: majority, mean loss: 1.74488, accuracy: 0.42400, task: max, mean loss: 1.48531, accuracy: 0.44700, task: top, mean loss: 1.95537, accuracy: 0.32500, task: multi, mean loss: 0.53223, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.42945
Diversity Loss - Mean: -0.14144, Variance: 0.14472
Semantic Loss - Mean: 1.44538, Variance: 0.00048

Train Epoch: 15 
task: majority, mean loss: 1.66776, accuracy: 0.47080, task: max, mean loss: 1.40361, accuracy: 0.46900, task: top, mean loss: 1.82195, accuracy: 0.40220, task: multi, mean loss: 0.51762, multilabel_accuracy: 0.00860, avg. loss over tasks: 1.35274, lr: 0.000992411472629598
Diversity Loss - Mean: -0.13610, Variance: 0.13047
Semantic Loss - Mean: 1.40837, Variance: 0.00119

Test Epoch: 15 
task: majority, mean loss: 1.64568, accuracy: 0.47400, task: max, mean loss: 1.41333, accuracy: 0.45100, task: top, mean loss: 1.82334, accuracy: 0.37700, task: multi, mean loss: 0.51189, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.34856
Diversity Loss - Mean: -0.14179, Variance: 0.14409
Semantic Loss - Mean: 1.38452, Variance: 0.00048

Train Epoch: 16 
task: majority, mean loss: 1.61203, accuracy: 0.48720, task: max, mean loss: 1.38576, accuracy: 0.47560, task: top, mean loss: 1.79335, accuracy: 0.41820, task: multi, mean loss: 0.51148, multilabel_accuracy: 0.01140, avg. loss over tasks: 1.32565, lr: 0.000989084726566536
Diversity Loss - Mean: -0.13651, Variance: 0.12992
Semantic Loss - Mean: 1.38172, Variance: 0.00125

Test Epoch: 16 
task: majority, mean loss: 1.68883, accuracy: 0.47400, task: max, mean loss: 1.47301, accuracy: 0.43200, task: top, mean loss: 1.83946, accuracy: 0.39600, task: multi, mean loss: 0.51643, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.37943
Diversity Loss - Mean: -0.14218, Variance: 0.14322
Semantic Loss - Mean: 1.40137, Variance: 0.00048

Train Epoch: 17 
task: majority, mean loss: 1.58954, accuracy: 0.49260, task: max, mean loss: 1.35523, accuracy: 0.49220, task: top, mean loss: 1.74770, accuracy: 0.44320, task: multi, mean loss: 0.50594, multilabel_accuracy: 0.01560, avg. loss over tasks: 1.29960, lr: 0.00098516271527486
Diversity Loss - Mean: -0.13645, Variance: 0.12905
Semantic Loss - Mean: 1.35873, Variance: 0.00130

Test Epoch: 17 
task: majority, mean loss: 1.80865, accuracy: 0.43600, task: max, mean loss: 1.48456, accuracy: 0.45600, task: top, mean loss: 1.90824, accuracy: 0.39400, task: multi, mean loss: 0.53929, multilabel_accuracy: 0.02200, avg. loss over tasks: 1.43518
Diversity Loss - Mean: -0.14198, Variance: 0.14240
Semantic Loss - Mean: 1.41667, Variance: 0.00051

Train Epoch: 18 
task: majority, mean loss: 1.53822, accuracy: 0.51980, task: max, mean loss: 1.33456, accuracy: 0.50260, task: top, mean loss: 1.72275, accuracy: 0.45260, task: multi, mean loss: 0.50168, multilabel_accuracy: 0.01400, avg. loss over tasks: 1.27430, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.13633, Variance: 0.12835
Semantic Loss - Mean: 1.33678, Variance: 0.00135

Test Epoch: 18 
task: majority, mean loss: 1.52346, accuracy: 0.52200, task: max, mean loss: 1.38175, accuracy: 0.45900, task: top, mean loss: 1.76937, accuracy: 0.41500, task: multi, mean loss: 0.49966, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.29356
Diversity Loss - Mean: -0.14206, Variance: 0.14115
Semantic Loss - Mean: 1.32766, Variance: 0.00051

Train Epoch: 19 
task: majority, mean loss: 1.45503, accuracy: 0.54520, task: max, mean loss: 1.32437, accuracy: 0.50360, task: top, mean loss: 1.69651, accuracy: 0.46420, task: multi, mean loss: 0.49261, multilabel_accuracy: 0.02120, avg. loss over tasks: 1.24213, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.13617, Variance: 0.12769
Semantic Loss - Mean: 1.30725, Variance: 0.00140

Test Epoch: 19 
task: majority, mean loss: 1.55684, accuracy: 0.49500, task: max, mean loss: 1.39186, accuracy: 0.49000, task: top, mean loss: 1.73909, accuracy: 0.44600, task: multi, mean loss: 0.49793, multilabel_accuracy: 0.02200, avg. loss over tasks: 1.29643
Diversity Loss - Mean: -0.14201, Variance: 0.13995
Semantic Loss - Mean: 1.31987, Variance: 0.00051

Train Epoch: 20 
task: majority, mean loss: 1.44434, accuracy: 0.54660, task: max, mean loss: 1.28797, accuracy: 0.52140, task: top, mean loss: 1.65173, accuracy: 0.48060, task: multi, mean loss: 0.48138, multilabel_accuracy: 0.02500, avg. loss over tasks: 1.21636, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.13616, Variance: 0.12709
Semantic Loss - Mean: 1.28595, Variance: 0.00145

Test Epoch: 20 
task: majority, mean loss: 1.56037, accuracy: 0.49200, task: max, mean loss: 1.43194, accuracy: 0.47600, task: top, mean loss: 1.76038, accuracy: 0.41700, task: multi, mean loss: 0.49423, multilabel_accuracy: 0.01900, avg. loss over tasks: 1.31173
Diversity Loss - Mean: -0.14223, Variance: 0.13918
Semantic Loss - Mean: 1.36501, Variance: 0.00053

Train Epoch: 21 
task: majority, mean loss: 1.42405, accuracy: 0.54860, task: max, mean loss: 1.30584, accuracy: 0.50760, task: top, mean loss: 1.63892, accuracy: 0.49060, task: multi, mean loss: 0.47417, multilabel_accuracy: 0.02820, avg. loss over tasks: 1.21074, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.13649, Variance: 0.12662
Semantic Loss - Mean: 1.28664, Variance: 0.00151

Test Epoch: 21 
task: majority, mean loss: 1.37831, accuracy: 0.57200, task: max, mean loss: 1.33505, accuracy: 0.49200, task: top, mean loss: 1.62704, accuracy: 0.48700, task: multi, mean loss: 0.46203, multilabel_accuracy: 0.03800, avg. loss over tasks: 1.20061
Diversity Loss - Mean: -0.14209, Variance: 0.13858
Semantic Loss - Mean: 1.24276, Variance: 0.00054

Train Epoch: 22 
task: majority, mean loss: 1.37539, accuracy: 0.57740, task: max, mean loss: 1.29581, accuracy: 0.51420, task: top, mean loss: 1.63627, accuracy: 0.49360, task: multi, mean loss: 0.46795, multilabel_accuracy: 0.03280, avg. loss over tasks: 1.19385, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.13679, Variance: 0.12627
Semantic Loss - Mean: 1.26840, Variance: 0.00155

Test Epoch: 22 
task: majority, mean loss: 1.43873, accuracy: 0.54800, task: max, mean loss: 1.36593, accuracy: 0.52300, task: top, mean loss: 1.68257, accuracy: 0.47700, task: multi, mean loss: 0.48625, multilabel_accuracy: 0.03900, avg. loss over tasks: 1.24337
Diversity Loss - Mean: -0.14161, Variance: 0.13815
Semantic Loss - Mean: 1.30067, Variance: 0.00056

Train Epoch: 23 
task: majority, mean loss: 1.32917, accuracy: 0.58460, task: max, mean loss: 1.25281, accuracy: 0.53200, task: top, mean loss: 1.60323, accuracy: 0.50040, task: multi, mean loss: 0.45617, multilabel_accuracy: 0.03960, avg. loss over tasks: 1.16034, lr: 0.000949447626126434
Diversity Loss - Mean: -0.13657, Variance: 0.12573
Semantic Loss - Mean: 1.24785, Variance: 0.00161

Test Epoch: 23 
task: majority, mean loss: 1.36279, accuracy: 0.56900, task: max, mean loss: 1.31298, accuracy: 0.52900, task: top, mean loss: 1.71212, accuracy: 0.46700, task: multi, mean loss: 0.45389, multilabel_accuracy: 0.03700, avg. loss over tasks: 1.21044
Diversity Loss - Mean: -0.14204, Variance: 0.13720
Semantic Loss - Mean: 1.26377, Variance: 0.00059

Train Epoch: 24 
task: majority, mean loss: 1.29508, accuracy: 0.59260, task: max, mean loss: 1.23751, accuracy: 0.53940, task: top, mean loss: 1.57805, accuracy: 0.51460, task: multi, mean loss: 0.44946, multilabel_accuracy: 0.05200, avg. loss over tasks: 1.14002, lr: 0.000941532322633034
Diversity Loss - Mean: -0.13666, Variance: 0.12528
Semantic Loss - Mean: 1.22585, Variance: 0.00165

Test Epoch: 24 
task: majority, mean loss: 1.37098, accuracy: 0.58100, task: max, mean loss: 1.33608, accuracy: 0.51200, task: top, mean loss: 1.61481, accuracy: 0.50900, task: multi, mean loss: 0.45839, multilabel_accuracy: 0.05500, avg. loss over tasks: 1.19506
Diversity Loss - Mean: -0.14185, Variance: 0.13672
Semantic Loss - Mean: 1.22213, Variance: 0.00062

Train Epoch: 25 
task: majority, mean loss: 1.26396, accuracy: 0.60640, task: max, mean loss: 1.22223, accuracy: 0.54700, task: top, mean loss: 1.54909, accuracy: 0.52180, task: multi, mean loss: 0.44432, multilabel_accuracy: 0.05200, avg. loss over tasks: 1.11990, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.13716, Variance: 0.12503
Semantic Loss - Mean: 1.20519, Variance: 0.00169

Test Epoch: 25 
task: majority, mean loss: 1.32499, accuracy: 0.59500, task: max, mean loss: 1.30064, accuracy: 0.52900, task: top, mean loss: 1.61058, accuracy: 0.49800, task: multi, mean loss: 0.43813, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.16858
Diversity Loss - Mean: -0.14219, Variance: 0.13632
Semantic Loss - Mean: 1.21364, Variance: 0.00063

Train Epoch: 26 
task: majority, mean loss: 1.26716, accuracy: 0.60100, task: max, mean loss: 1.24984, accuracy: 0.53040, task: top, mean loss: 1.57140, accuracy: 0.51580, task: multi, mean loss: 0.44182, multilabel_accuracy: 0.05720, avg. loss over tasks: 1.13256, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.13702, Variance: 0.12485
Semantic Loss - Mean: 1.21715, Variance: 0.00174

Test Epoch: 26 
task: majority, mean loss: 1.38364, accuracy: 0.56600, task: max, mean loss: 1.32887, accuracy: 0.51600, task: top, mean loss: 1.62995, accuracy: 0.49800, task: multi, mean loss: 0.46265, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.20128
Diversity Loss - Mean: -0.14206, Variance: 0.13612
Semantic Loss - Mean: 1.22200, Variance: 0.00063

Train Epoch: 27 
task: majority, mean loss: 1.21822, accuracy: 0.62040, task: max, mean loss: 1.21119, accuracy: 0.55200, task: top, mean loss: 1.54634, accuracy: 0.53540, task: multi, mean loss: 0.43804, multilabel_accuracy: 0.06260, avg. loss over tasks: 1.10345, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.13711, Variance: 0.12463
Semantic Loss - Mean: 1.18371, Variance: 0.00177

Test Epoch: 27 
task: majority, mean loss: 1.23997, accuracy: 0.61100, task: max, mean loss: 1.24527, accuracy: 0.53600, task: top, mean loss: 1.61551, accuracy: 0.50100, task: multi, mean loss: 0.43155, multilabel_accuracy: 0.05800, avg. loss over tasks: 1.13307
Diversity Loss - Mean: -0.14199, Variance: 0.13569
Semantic Loss - Mean: 1.19036, Variance: 0.00063

Train Epoch: 28 
task: majority, mean loss: 1.22318, accuracy: 0.61760, task: max, mean loss: 1.21589, accuracy: 0.54480, task: top, mean loss: 1.54597, accuracy: 0.53100, task: multi, mean loss: 0.43482, multilabel_accuracy: 0.06780, avg. loss over tasks: 1.10496, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.13751, Variance: 0.12461
Semantic Loss - Mean: 1.17926, Variance: 0.00180

Test Epoch: 28 
task: majority, mean loss: 1.44314, accuracy: 0.57000, task: max, mean loss: 1.27469, accuracy: 0.53300, task: top, mean loss: 1.70497, accuracy: 0.48800, task: multi, mean loss: 0.44503, multilabel_accuracy: 0.06700, avg. loss over tasks: 1.21696
Diversity Loss - Mean: -0.14192, Variance: 0.13520
Semantic Loss - Mean: 1.23342, Variance: 0.00064

Train Epoch: 29 
task: majority, mean loss: 1.21221, accuracy: 0.62160, task: max, mean loss: 1.20727, accuracy: 0.54720, task: top, mean loss: 1.54531, accuracy: 0.52400, task: multi, mean loss: 0.42949, multilabel_accuracy: 0.06920, avg. loss over tasks: 1.09857, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.13739, Variance: 0.12457
Semantic Loss - Mean: 1.17530, Variance: 0.00183

Test Epoch: 29 
task: majority, mean loss: 1.45207, accuracy: 0.51800, task: max, mean loss: 1.24619, accuracy: 0.53900, task: top, mean loss: 1.68718, accuracy: 0.45900, task: multi, mean loss: 0.46024, multilabel_accuracy: 0.05900, avg. loss over tasks: 1.21142
Diversity Loss - Mean: -0.14236, Variance: 0.13540
Semantic Loss - Mean: 1.25848, Variance: 0.00064

Train Epoch: 30 
task: majority, mean loss: 1.22470, accuracy: 0.61440, task: max, mean loss: 1.19776, accuracy: 0.55720, task: top, mean loss: 1.51862, accuracy: 0.54300, task: multi, mean loss: 0.42939, multilabel_accuracy: 0.07400, avg. loss over tasks: 1.09262, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.13784, Variance: 0.12472
Semantic Loss - Mean: 1.16625, Variance: 0.00185

Test Epoch: 30 
task: majority, mean loss: 1.23133, accuracy: 0.60500, task: max, mean loss: 1.25193, accuracy: 0.53200, task: top, mean loss: 1.61890, accuracy: 0.49600, task: multi, mean loss: 0.42123, multilabel_accuracy: 0.07900, avg. loss over tasks: 1.13085
Diversity Loss - Mean: -0.14233, Variance: 0.13579
Semantic Loss - Mean: 1.15895, Variance: 0.00064

Train Epoch: 31 
task: majority, mean loss: 1.19712, accuracy: 0.62780, task: max, mean loss: 1.19375, accuracy: 0.55520, task: top, mean loss: 1.51231, accuracy: 0.53640, task: multi, mean loss: 0.42712, multilabel_accuracy: 0.07580, avg. loss over tasks: 1.08258, lr: 0.0008717008403259584
Diversity Loss - Mean: -0.13802, Variance: 0.12500
Semantic Loss - Mean: 1.15682, Variance: 0.00188

Test Epoch: 31 
task: majority, mean loss: 1.26495, accuracy: 0.59300, task: max, mean loss: 1.23117, accuracy: 0.53800, task: top, mean loss: 1.60678, accuracy: 0.50300, task: multi, mean loss: 0.41669, multilabel_accuracy: 0.07400, avg. loss over tasks: 1.12990
Diversity Loss - Mean: -0.14243, Variance: 0.13599
Semantic Loss - Mean: 1.15574, Variance: 0.00063

Train Epoch: 32 
task: majority, mean loss: 1.21030, accuracy: 0.62080, task: max, mean loss: 1.20385, accuracy: 0.54280, task: top, mean loss: 1.54320, accuracy: 0.52840, task: multi, mean loss: 0.42536, multilabel_accuracy: 0.06680, avg. loss over tasks: 1.09568, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.13816, Variance: 0.12534
Semantic Loss - Mean: 1.16785, Variance: 0.00190

Test Epoch: 32 
task: majority, mean loss: 1.21228, accuracy: 0.62300, task: max, mean loss: 1.29643, accuracy: 0.51400, task: top, mean loss: 1.57967, accuracy: 0.50900, task: multi, mean loss: 0.43204, multilabel_accuracy: 0.05900, avg. loss over tasks: 1.13011
Diversity Loss - Mean: -0.14256, Variance: 0.13665
Semantic Loss - Mean: 1.17139, Variance: 0.00062

Train Epoch: 33 
task: majority, mean loss: 1.17111, accuracy: 0.63380, task: max, mean loss: 1.19317, accuracy: 0.55900, task: top, mean loss: 1.50644, accuracy: 0.54480, task: multi, mean loss: 0.42515, multilabel_accuracy: 0.07520, avg. loss over tasks: 1.07397, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.13788, Variance: 0.12577
Semantic Loss - Mean: 1.14767, Variance: 0.00192

Test Epoch: 33 
task: majority, mean loss: 1.21832, accuracy: 0.61500, task: max, mean loss: 1.22060, accuracy: 0.53500, task: top, mean loss: 1.55953, accuracy: 0.51300, task: multi, mean loss: 0.41721, multilabel_accuracy: 0.07900, avg. loss over tasks: 1.10391
Diversity Loss - Mean: -0.14232, Variance: 0.13707
Semantic Loss - Mean: 1.13043, Variance: 0.00062

Train Epoch: 34 
task: majority, mean loss: 1.17939, accuracy: 0.62460, task: max, mean loss: 1.16910, accuracy: 0.56580, task: top, mean loss: 1.48909, accuracy: 0.53800, task: multi, mean loss: 0.41675, multilabel_accuracy: 0.08500, avg. loss over tasks: 1.06358, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.13800, Variance: 0.12622
Semantic Loss - Mean: 1.13648, Variance: 0.00194

Test Epoch: 34 
task: majority, mean loss: 1.19695, accuracy: 0.62000, task: max, mean loss: 1.27220, accuracy: 0.52500, task: top, mean loss: 1.61017, accuracy: 0.51300, task: multi, mean loss: 0.42520, multilabel_accuracy: 0.07800, avg. loss over tasks: 1.12613
Diversity Loss - Mean: -0.14233, Variance: 0.13733
Semantic Loss - Mean: 1.14719, Variance: 0.00061

Train Epoch: 35 
task: majority, mean loss: 1.15136, accuracy: 0.64180, task: max, mean loss: 1.16479, accuracy: 0.57160, task: top, mean loss: 1.48851, accuracy: 0.55260, task: multi, mean loss: 0.41616, multilabel_accuracy: 0.08220, avg. loss over tasks: 1.05520, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.13814, Variance: 0.12680
Semantic Loss - Mean: 1.12489, Variance: 0.00196

Test Epoch: 35 
task: majority, mean loss: 1.19731, accuracy: 0.61700, task: max, mean loss: 1.28180, accuracy: 0.50300, task: top, mean loss: 1.55366, accuracy: 0.52000, task: multi, mean loss: 0.41574, multilabel_accuracy: 0.09500, avg. loss over tasks: 1.11213
Diversity Loss - Mean: -0.14243, Variance: 0.13819
Semantic Loss - Mean: 1.13731, Variance: 0.00060

Train Epoch: 36 
task: majority, mean loss: 1.13639, accuracy: 0.64240, task: max, mean loss: 1.15337, accuracy: 0.57040, task: top, mean loss: 1.49572, accuracy: 0.54440, task: multi, mean loss: 0.41512, multilabel_accuracy: 0.08800, avg. loss over tasks: 1.05015, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.13818, Variance: 0.12744
Semantic Loss - Mean: 1.12193, Variance: 0.00197

Test Epoch: 36 
task: majority, mean loss: 1.31078, accuracy: 0.61400, task: max, mean loss: 1.24026, accuracy: 0.54600, task: top, mean loss: 1.64262, accuracy: 0.52800, task: multi, mean loss: 0.42528, multilabel_accuracy: 0.11600, avg. loss over tasks: 1.15474
Diversity Loss - Mean: -0.14214, Variance: 0.13821
Semantic Loss - Mean: 1.16016, Variance: 0.00061

Train Epoch: 37 
task: majority, mean loss: 1.16144, accuracy: 0.62340, task: max, mean loss: 1.17420, accuracy: 0.56640, task: top, mean loss: 1.47732, accuracy: 0.55260, task: multi, mean loss: 0.41179, multilabel_accuracy: 0.09200, avg. loss over tasks: 1.05619, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.13827, Variance: 0.12813
Semantic Loss - Mean: 1.13016, Variance: 0.00198

Test Epoch: 37 
task: majority, mean loss: 1.26020, accuracy: 0.60200, task: max, mean loss: 1.22984, accuracy: 0.55300, task: top, mean loss: 1.52577, accuracy: 0.54200, task: multi, mean loss: 0.40684, multilabel_accuracy: 0.09600, avg. loss over tasks: 1.10566
Diversity Loss - Mean: -0.14227, Variance: 0.13854
Semantic Loss - Mean: 1.12029, Variance: 0.00060

Train Epoch: 38 
task: majority, mean loss: 1.13487, accuracy: 0.64480, task: max, mean loss: 1.16811, accuracy: 0.56560, task: top, mean loss: 1.48906, accuracy: 0.54640, task: multi, mean loss: 0.41049, multilabel_accuracy: 0.09160, avg. loss over tasks: 1.05063, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.13811, Variance: 0.12878
Semantic Loss - Mean: 1.12252, Variance: 0.00199

Test Epoch: 38 
task: majority, mean loss: 1.27962, accuracy: 0.59800, task: max, mean loss: 1.26513, accuracy: 0.52400, task: top, mean loss: 1.73102, accuracy: 0.48500, task: multi, mean loss: 0.44319, multilabel_accuracy: 0.07600, avg. loss over tasks: 1.17974
Diversity Loss - Mean: -0.14233, Variance: 0.13899
Semantic Loss - Mean: 1.18962, Variance: 0.00060

Train Epoch: 39 
task: majority, mean loss: 1.12752, accuracy: 0.63900, task: max, mean loss: 1.15742, accuracy: 0.57120, task: top, mean loss: 1.47768, accuracy: 0.55280, task: multi, mean loss: 0.41006, multilabel_accuracy: 0.09480, avg. loss over tasks: 1.04317, lr: 0.000765194672484486
Diversity Loss - Mean: -0.13852, Variance: 0.12960
Semantic Loss - Mean: 1.11109, Variance: 0.00201

Test Epoch: 39 
task: majority, mean loss: 1.17597, accuracy: 0.60900, task: max, mean loss: 1.21965, accuracy: 0.54500, task: top, mean loss: 1.51008, accuracy: 0.52900, task: multi, mean loss: 0.40540, multilabel_accuracy: 0.10400, avg. loss over tasks: 1.07778
Diversity Loss - Mean: -0.14256, Variance: 0.14019
Semantic Loss - Mean: 1.10338, Variance: 0.00059

Train Epoch: 40 
task: majority, mean loss: 1.12525, accuracy: 0.64700, task: max, mean loss: 1.17801, accuracy: 0.56100, task: top, mean loss: 1.45768, accuracy: 0.55760, task: multi, mean loss: 0.41118, multilabel_accuracy: 0.10080, avg. loss over tasks: 1.04303, lr: 0.00075025
Diversity Loss - Mean: -0.13851, Variance: 0.13053
Semantic Loss - Mean: 1.11227, Variance: 0.00202

Test Epoch: 40 
task: majority, mean loss: 1.19106, accuracy: 0.61000, task: max, mean loss: 1.24185, accuracy: 0.55500, task: top, mean loss: 1.58172, accuracy: 0.52900, task: multi, mean loss: 0.40785, multilabel_accuracy: 0.09600, avg. loss over tasks: 1.10562
Diversity Loss - Mean: -0.14247, Variance: 0.14081
Semantic Loss - Mean: 1.11866, Variance: 0.00059

Train Epoch: 41 
task: majority, mean loss: 1.11492, accuracy: 0.64540, task: max, mean loss: 1.14016, accuracy: 0.58540, task: top, mean loss: 1.42924, accuracy: 0.56520, task: multi, mean loss: 0.40498, multilabel_accuracy: 0.10060, avg. loss over tasks: 1.02232, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.13858, Variance: 0.13156
Semantic Loss - Mean: 1.09316, Variance: 0.00203

Test Epoch: 41 
task: majority, mean loss: 1.22030, accuracy: 0.62300, task: max, mean loss: 1.19100, accuracy: 0.56200, task: top, mean loss: 1.54672, accuracy: 0.52200, task: multi, mean loss: 0.40960, multilabel_accuracy: 0.10900, avg. loss over tasks: 1.09190
Diversity Loss - Mean: -0.14252, Variance: 0.14176
Semantic Loss - Mean: 1.10980, Variance: 0.00058

Train Epoch: 42 
task: majority, mean loss: 1.08513, accuracy: 0.65700, task: max, mean loss: 1.14543, accuracy: 0.57080, task: top, mean loss: 1.47016, accuracy: 0.55980, task: multi, mean loss: 0.40613, multilabel_accuracy: 0.10440, avg. loss over tasks: 1.02671, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.13888, Variance: 0.13268
Semantic Loss - Mean: 1.09421, Variance: 0.00204

Test Epoch: 42 
task: majority, mean loss: 1.12066, accuracy: 0.63600, task: max, mean loss: 1.20240, accuracy: 0.55800, task: top, mean loss: 1.48507, accuracy: 0.55500, task: multi, mean loss: 0.40648, multilabel_accuracy: 0.10600, avg. loss over tasks: 1.05366
Diversity Loss - Mean: -0.14261, Variance: 0.14351
Semantic Loss - Mean: 1.09079, Variance: 0.00058

Train Epoch: 43 
task: majority, mean loss: 1.07405, accuracy: 0.65180, task: max, mean loss: 1.11933, accuracy: 0.58900, task: top, mean loss: 1.43901, accuracy: 0.56640, task: multi, mean loss: 0.40203, multilabel_accuracy: 0.09740, avg. loss over tasks: 1.00861, lr: 0.0007036649532163623
Diversity Loss - Mean: -0.13882, Variance: 0.13384
Semantic Loss - Mean: 1.08009, Variance: 0.00205

Test Epoch: 43 
task: majority, mean loss: 1.19830, accuracy: 0.64100, task: max, mean loss: 1.23307, accuracy: 0.55600, task: top, mean loss: 1.52960, accuracy: 0.54900, task: multi, mean loss: 0.41138, multilabel_accuracy: 0.09900, avg. loss over tasks: 1.09309
Diversity Loss - Mean: -0.14265, Variance: 0.14519
Semantic Loss - Mean: 1.12173, Variance: 0.00057

Train Epoch: 44 
task: majority, mean loss: 1.09123, accuracy: 0.64640, task: max, mean loss: 1.12693, accuracy: 0.58560, task: top, mean loss: 1.42025, accuracy: 0.55920, task: multi, mean loss: 0.40133, multilabel_accuracy: 0.10460, avg. loss over tasks: 1.00993, lr: 0.0006876159934112482
Diversity Loss - Mean: -0.13889, Variance: 0.13500
Semantic Loss - Mean: 1.07834, Variance: 0.00206

Test Epoch: 44 
task: majority, mean loss: 1.33505, accuracy: 0.59900, task: max, mean loss: 1.31491, accuracy: 0.55400, task: top, mean loss: 1.63668, accuracy: 0.53200, task: multi, mean loss: 0.43029, multilabel_accuracy: 0.10100, avg. loss over tasks: 1.17923
Diversity Loss - Mean: -0.14224, Variance: 0.14565
Semantic Loss - Mean: 1.18382, Variance: 0.00057

Train Epoch: 45 
task: majority, mean loss: 1.05178, accuracy: 0.66300, task: max, mean loss: 1.13449, accuracy: 0.57940, task: top, mean loss: 1.43935, accuracy: 0.56860, task: multi, mean loss: 0.40350, multilabel_accuracy: 0.10640, avg. loss over tasks: 1.00728, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.13877, Variance: 0.13616
Semantic Loss - Mean: 1.07469, Variance: 0.00207

Test Epoch: 45 
task: majority, mean loss: 1.19398, accuracy: 0.63200, task: max, mean loss: 1.26293, accuracy: 0.53400, task: top, mean loss: 1.57741, accuracy: 0.51800, task: multi, mean loss: 0.42019, multilabel_accuracy: 0.09100, avg. loss over tasks: 1.11363
Diversity Loss - Mean: -0.14263, Variance: 0.14730
Semantic Loss - Mean: 1.13136, Variance: 0.00056

Train Epoch: 46 
task: majority, mean loss: 1.06307, accuracy: 0.66160, task: max, mean loss: 1.09621, accuracy: 0.59960, task: top, mean loss: 1.43966, accuracy: 0.56560, task: multi, mean loss: 0.39884, multilabel_accuracy: 0.10560, avg. loss over tasks: 0.99945, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.13904, Variance: 0.13734
Semantic Loss - Mean: 1.06715, Variance: 0.00208

Test Epoch: 46 
task: majority, mean loss: 1.15462, accuracy: 0.62100, task: max, mean loss: 1.21946, accuracy: 0.56900, task: top, mean loss: 1.54798, accuracy: 0.52900, task: multi, mean loss: 0.39804, multilabel_accuracy: 0.13800, avg. loss over tasks: 1.08003
Diversity Loss - Mean: -0.14261, Variance: 0.14860
Semantic Loss - Mean: 1.08830, Variance: 0.00056

Train Epoch: 47 
task: majority, mean loss: 1.05537, accuracy: 0.65580, task: max, mean loss: 1.10751, accuracy: 0.59020, task: top, mean loss: 1.39720, accuracy: 0.58060, task: multi, mean loss: 0.39661, multilabel_accuracy: 0.11000, avg. loss over tasks: 0.98917, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.13917, Variance: 0.13873
Semantic Loss - Mean: 1.05931, Variance: 0.00208

Test Epoch: 47 
task: majority, mean loss: 1.11860, accuracy: 0.64100, task: max, mean loss: 1.24281, accuracy: 0.53600, task: top, mean loss: 1.53201, accuracy: 0.53400, task: multi, mean loss: 0.40211, multilabel_accuracy: 0.10600, avg. loss over tasks: 1.07388
Diversity Loss - Mean: -0.14250, Variance: 0.14979
Semantic Loss - Mean: 1.08459, Variance: 0.00056

Train Epoch: 48 
task: majority, mean loss: 1.05076, accuracy: 0.66520, task: max, mean loss: 1.09626, accuracy: 0.59480, task: top, mean loss: 1.42055, accuracy: 0.57260, task: multi, mean loss: 0.39737, multilabel_accuracy: 0.10640, avg. loss over tasks: 0.99124, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.13881, Variance: 0.13999
Semantic Loss - Mean: 1.06098, Variance: 0.00209

Test Epoch: 48 
task: majority, mean loss: 1.10445, accuracy: 0.66700, task: max, mean loss: 1.17529, accuracy: 0.57200, task: top, mean loss: 1.54176, accuracy: 0.54200, task: multi, mean loss: 0.39605, multilabel_accuracy: 0.11700, avg. loss over tasks: 1.05439
Diversity Loss - Mean: -0.14266, Variance: 0.15143
Semantic Loss - Mean: 1.08114, Variance: 0.00055

Train Epoch: 49 
task: majority, mean loss: 1.06732, accuracy: 0.65820, task: max, mean loss: 1.08745, accuracy: 0.60360, task: top, mean loss: 1.37566, accuracy: 0.58620, task: multi, mean loss: 0.39159, multilabel_accuracy: 0.12020, avg. loss over tasks: 0.98051, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.13891, Variance: 0.14127
Semantic Loss - Mean: 1.05149, Variance: 0.00210

Test Epoch: 49 
task: majority, mean loss: 1.19223, accuracy: 0.61500, task: max, mean loss: 1.20203, accuracy: 0.56500, task: top, mean loss: 1.53631, accuracy: 0.55800, task: multi, mean loss: 0.40441, multilabel_accuracy: 0.12300, avg. loss over tasks: 1.08374
Diversity Loss - Mean: -0.14249, Variance: 0.15220
Semantic Loss - Mean: 1.08977, Variance: 0.00055

Train Epoch: 50 
task: majority, mean loss: 1.02230, accuracy: 0.67220, task: max, mean loss: 1.09881, accuracy: 0.58880, task: top, mean loss: 1.41411, accuracy: 0.57360, task: multi, mean loss: 0.39346, multilabel_accuracy: 0.12120, avg. loss over tasks: 0.98217, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.13902, Variance: 0.14258
Semantic Loss - Mean: 1.05065, Variance: 0.00211

Test Epoch: 50 
task: majority, mean loss: 1.11929, accuracy: 0.65400, task: max, mean loss: 1.14913, accuracy: 0.56900, task: top, mean loss: 1.52787, accuracy: 0.53700, task: multi, mean loss: 0.39164, multilabel_accuracy: 0.13300, avg. loss over tasks: 1.04698
Diversity Loss - Mean: -0.14263, Variance: 0.15364
Semantic Loss - Mean: 1.06352, Variance: 0.00054

Train Epoch: 51 
task: majority, mean loss: 1.03636, accuracy: 0.66740, task: max, mean loss: 1.09421, accuracy: 0.58780, task: top, mean loss: 1.41400, accuracy: 0.57620, task: multi, mean loss: 0.39466, multilabel_accuracy: 0.11620, avg. loss over tasks: 0.98481, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.13912, Variance: 0.14397
Semantic Loss - Mean: 1.05396, Variance: 0.00212

Test Epoch: 51 
task: majority, mean loss: 1.13388, accuracy: 0.63500, task: max, mean loss: 1.24804, accuracy: 0.52500, task: top, mean loss: 1.53393, accuracy: 0.52200, task: multi, mean loss: 0.39718, multilabel_accuracy: 0.11800, avg. loss over tasks: 1.07826
Diversity Loss - Mean: -0.14267, Variance: 0.15531
Semantic Loss - Mean: 1.09703, Variance: 0.00053

Train Epoch: 52 
task: majority, mean loss: 1.03157, accuracy: 0.67220, task: max, mean loss: 1.09661, accuracy: 0.59240, task: top, mean loss: 1.41437, accuracy: 0.57000, task: multi, mean loss: 0.39424, multilabel_accuracy: 0.11580, avg. loss over tasks: 0.98420, lr: 0.000552711967402193
Diversity Loss - Mean: -0.13919, Variance: 0.14546
Semantic Loss - Mean: 1.04958, Variance: 0.00212

Test Epoch: 52 
task: majority, mean loss: 1.15592, accuracy: 0.62200, task: max, mean loss: 1.22734, accuracy: 0.56200, task: top, mean loss: 1.50608, accuracy: 0.52900, task: multi, mean loss: 0.39943, multilabel_accuracy: 0.12600, avg. loss over tasks: 1.07219
Diversity Loss - Mean: -0.14264, Variance: 0.15685
Semantic Loss - Mean: 1.07774, Variance: 0.00053

Train Epoch: 53 
task: majority, mean loss: 1.04682, accuracy: 0.66880, task: max, mean loss: 1.08636, accuracy: 0.60140, task: top, mean loss: 1.40037, accuracy: 0.57880, task: multi, mean loss: 0.39110, multilabel_accuracy: 0.11960, avg. loss over tasks: 0.98116, lr: 0.0005353433586351906
Diversity Loss - Mean: -0.13926, Variance: 0.14698
Semantic Loss - Mean: 1.04852, Variance: 0.00213

Test Epoch: 53 
task: majority, mean loss: 1.23978, accuracy: 0.62300, task: max, mean loss: 1.19249, accuracy: 0.58000, task: top, mean loss: 1.55571, accuracy: 0.55500, task: multi, mean loss: 0.41354, multilabel_accuracy: 0.11400, avg. loss over tasks: 1.10038
Diversity Loss - Mean: -0.14254, Variance: 0.15786
Semantic Loss - Mean: 1.09341, Variance: 0.00053

Train Epoch: 54 
task: majority, mean loss: 1.02185, accuracy: 0.67220, task: max, mean loss: 1.05498, accuracy: 0.61440, task: top, mean loss: 1.36385, accuracy: 0.59400, task: multi, mean loss: 0.38850, multilabel_accuracy: 0.11920, avg. loss over tasks: 0.95729, lr: 0.0005179322986028992
Diversity Loss - Mean: -0.13909, Variance: 0.14841
Semantic Loss - Mean: 1.02514, Variance: 0.00214

Test Epoch: 54 
task: majority, mean loss: 1.07447, accuracy: 0.65300, task: max, mean loss: 1.13807, accuracy: 0.57800, task: top, mean loss: 1.52152, accuracy: 0.54500, task: multi, mean loss: 0.39385, multilabel_accuracy: 0.11100, avg. loss over tasks: 1.03198
Diversity Loss - Mean: -0.14268, Variance: 0.15946
Semantic Loss - Mean: 1.04666, Variance: 0.00052

Train Epoch: 55 
task: majority, mean loss: 0.98923, accuracy: 0.68540, task: max, mean loss: 1.07051, accuracy: 0.60360, task: top, mean loss: 1.37345, accuracy: 0.59120, task: multi, mean loss: 0.38575, multilabel_accuracy: 0.12520, avg. loss over tasks: 0.95474, lr: 0.0005005
Diversity Loss - Mean: -0.13924, Variance: 0.14991
Semantic Loss - Mean: 1.02361, Variance: 0.00214

Test Epoch: 55 
task: majority, mean loss: 1.08873, accuracy: 0.66700, task: max, mean loss: 1.19363, accuracy: 0.56800, task: top, mean loss: 1.51993, accuracy: 0.54700, task: multi, mean loss: 0.40787, multilabel_accuracy: 0.12400, avg. loss over tasks: 1.05254
Diversity Loss - Mean: -0.14261, Variance: 0.16071
Semantic Loss - Mean: 1.04974, Variance: 0.00052

Train Epoch: 56 
task: majority, mean loss: 1.00839, accuracy: 0.67760, task: max, mean loss: 1.10036, accuracy: 0.58860, task: top, mean loss: 1.39382, accuracy: 0.58340, task: multi, mean loss: 0.39188, multilabel_accuracy: 0.11500, avg. loss over tasks: 0.97362, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.13932, Variance: 0.15139
Semantic Loss - Mean: 1.03722, Variance: 0.00214

Test Epoch: 56 
task: majority, mean loss: 1.11318, accuracy: 0.63400, task: max, mean loss: 1.16009, accuracy: 0.58000, task: top, mean loss: 1.46439, accuracy: 0.57000, task: multi, mean loss: 0.38625, multilabel_accuracy: 0.14100, avg. loss over tasks: 1.03098
Diversity Loss - Mean: -0.14262, Variance: 0.16206
Semantic Loss - Mean: 1.03816, Variance: 0.00051

Train Epoch: 57 
task: majority, mean loss: 0.97066, accuracy: 0.69340, task: max, mean loss: 1.05763, accuracy: 0.61340, task: top, mean loss: 1.38058, accuracy: 0.58500, task: multi, mean loss: 0.38396, multilabel_accuracy: 0.12600, avg. loss over tasks: 0.94821, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.13934, Variance: 0.15286
Semantic Loss - Mean: 1.01664, Variance: 0.00215

Test Epoch: 57 
task: majority, mean loss: 1.38854, accuracy: 0.61100, task: max, mean loss: 1.27117, accuracy: 0.57000, task: top, mean loss: 1.73077, accuracy: 0.52100, task: multi, mean loss: 0.43269, multilabel_accuracy: 0.11700, avg. loss over tasks: 1.20579
Diversity Loss - Mean: -0.14253, Variance: 0.16304
Semantic Loss - Mean: 1.18060, Variance: 0.00051

Train Epoch: 58 
task: majority, mean loss: 0.95895, accuracy: 0.69540, task: max, mean loss: 1.05627, accuracy: 0.61280, task: top, mean loss: 1.35164, accuracy: 0.59440, task: multi, mean loss: 0.38467, multilabel_accuracy: 0.12520, avg. loss over tasks: 0.93788, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.13936, Variance: 0.15437
Semantic Loss - Mean: 1.00403, Variance: 0.00216

Test Epoch: 58 
task: majority, mean loss: 1.21269, accuracy: 0.63300, task: max, mean loss: 1.21662, accuracy: 0.57900, task: top, mean loss: 1.59219, accuracy: 0.53500, task: multi, mean loss: 0.41755, multilabel_accuracy: 0.13200, avg. loss over tasks: 1.10976
Diversity Loss - Mean: -0.14260, Variance: 0.16420
Semantic Loss - Mean: 1.10055, Variance: 0.00051

Train Epoch: 59 
task: majority, mean loss: 0.99652, accuracy: 0.67840, task: max, mean loss: 1.06924, accuracy: 0.60080, task: top, mean loss: 1.35207, accuracy: 0.59260, task: multi, mean loss: 0.38696, multilabel_accuracy: 0.12200, avg. loss over tasks: 0.95120, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.13965, Variance: 0.15602
Semantic Loss - Mean: 1.01467, Variance: 0.00216

Test Epoch: 59 
task: majority, mean loss: 1.18843, accuracy: 0.62200, task: max, mean loss: 1.21324, accuracy: 0.55000, task: top, mean loss: 1.57005, accuracy: 0.51300, task: multi, mean loss: 0.40548, multilabel_accuracy: 0.11800, avg. loss over tasks: 1.09430
Diversity Loss - Mean: -0.14271, Variance: 0.16596
Semantic Loss - Mean: 1.10268, Variance: 0.00050

Train Epoch: 60 
task: majority, mean loss: 0.98714, accuracy: 0.68140, task: max, mean loss: 1.02483, accuracy: 0.62820, task: top, mean loss: 1.34433, accuracy: 0.59080, task: multi, mean loss: 0.38132, multilabel_accuracy: 0.12740, avg. loss over tasks: 0.93441, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.13948, Variance: 0.15759
Semantic Loss - Mean: 1.00328, Variance: 0.00217

Test Epoch: 60 
task: majority, mean loss: 1.15246, accuracy: 0.62000, task: max, mean loss: 1.15785, accuracy: 0.58100, task: top, mean loss: 1.50434, accuracy: 0.53700, task: multi, mean loss: 0.38703, multilabel_accuracy: 0.12700, avg. loss over tasks: 1.05042
Diversity Loss - Mean: -0.14270, Variance: 0.16788
Semantic Loss - Mean: 1.06146, Variance: 0.00050

Train Epoch: 61 
task: majority, mean loss: 0.96084, accuracy: 0.68980, task: max, mean loss: 1.04929, accuracy: 0.61140, task: top, mean loss: 1.35329, accuracy: 0.59080, task: multi, mean loss: 0.38133, multilabel_accuracy: 0.12980, avg. loss over tasks: 0.93619, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.13953, Variance: 0.15913
Semantic Loss - Mean: 1.00264, Variance: 0.00217

Test Epoch: 61 
task: majority, mean loss: 1.08270, accuracy: 0.64100, task: max, mean loss: 1.21474, accuracy: 0.55700, task: top, mean loss: 1.48291, accuracy: 0.55200, task: multi, mean loss: 0.38400, multilabel_accuracy: 0.13000, avg. loss over tasks: 1.04109
Diversity Loss - Mean: -0.14271, Variance: 0.16966
Semantic Loss - Mean: 1.06214, Variance: 0.00049

Train Epoch: 62 
task: majority, mean loss: 0.95513, accuracy: 0.68820, task: max, mean loss: 1.01922, accuracy: 0.62420, task: top, mean loss: 1.32424, accuracy: 0.60220, task: multi, mean loss: 0.38006, multilabel_accuracy: 0.13180, avg. loss over tasks: 0.91966, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.13944, Variance: 0.16064
Semantic Loss - Mean: 0.98383, Variance: 0.00217

Test Epoch: 62 
task: majority, mean loss: 1.15597, accuracy: 0.62700, task: max, mean loss: 1.16855, accuracy: 0.55900, task: top, mean loss: 1.51445, accuracy: 0.54400, task: multi, mean loss: 0.39639, multilabel_accuracy: 0.12300, avg. loss over tasks: 1.05884
Diversity Loss - Mean: -0.14273, Variance: 0.17132
Semantic Loss - Mean: 1.06230, Variance: 0.00049

Train Epoch: 63 
task: majority, mean loss: 0.97242, accuracy: 0.68340, task: max, mean loss: 1.02286, accuracy: 0.62300, task: top, mean loss: 1.30992, accuracy: 0.60060, task: multi, mean loss: 0.37733, multilabel_accuracy: 0.13760, avg. loss over tasks: 0.92063, lr: 0.00036281914076940894
Diversity Loss - Mean: -0.13970, Variance: 0.16228
Semantic Loss - Mean: 0.98675, Variance: 0.00218

Test Epoch: 63 
task: majority, mean loss: 1.17336, accuracy: 0.63200, task: max, mean loss: 1.19390, accuracy: 0.56500, task: top, mean loss: 1.59125, accuracy: 0.52500, task: multi, mean loss: 0.41165, multilabel_accuracy: 0.11700, avg. loss over tasks: 1.09254
Diversity Loss - Mean: -0.14271, Variance: 0.17291
Semantic Loss - Mean: 1.10158, Variance: 0.00048

Train Epoch: 64 
task: majority, mean loss: 0.94486, accuracy: 0.69340, task: max, mean loss: 1.02124, accuracy: 0.62260, task: top, mean loss: 1.33332, accuracy: 0.60280, task: multi, mean loss: 0.38113, multilabel_accuracy: 0.12460, avg. loss over tasks: 0.92013, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.13949, Variance: 0.16379
Semantic Loss - Mean: 0.98547, Variance: 0.00218

Test Epoch: 64 
task: majority, mean loss: 1.16169, accuracy: 0.62100, task: max, mean loss: 1.25291, accuracy: 0.55900, task: top, mean loss: 1.52100, accuracy: 0.53700, task: multi, mean loss: 0.39756, multilabel_accuracy: 0.11600, avg. loss over tasks: 1.08329
Diversity Loss - Mean: -0.14274, Variance: 0.17475
Semantic Loss - Mean: 1.09113, Variance: 0.00048

Train Epoch: 65 
task: majority, mean loss: 0.98003, accuracy: 0.68280, task: max, mean loss: 1.02642, accuracy: 0.62000, task: top, mean loss: 1.31880, accuracy: 0.60320, task: multi, mean loss: 0.37656, multilabel_accuracy: 0.13660, avg. loss over tasks: 0.92545, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.13975, Variance: 0.16544
Semantic Loss - Mean: 0.98913, Variance: 0.00219

Test Epoch: 65 
task: majority, mean loss: 1.13040, accuracy: 0.65100, task: max, mean loss: 1.21532, accuracy: 0.56200, task: top, mean loss: 1.55053, accuracy: 0.56500, task: multi, mean loss: 0.39778, multilabel_accuracy: 0.12200, avg. loss over tasks: 1.07351
Diversity Loss - Mean: -0.14266, Variance: 0.17591
Semantic Loss - Mean: 1.06513, Variance: 0.00047

Train Epoch: 66 
task: majority, mean loss: 0.93293, accuracy: 0.70220, task: max, mean loss: 0.98980, accuracy: 0.63680, task: top, mean loss: 1.33453, accuracy: 0.59780, task: multi, mean loss: 0.37405, multilabel_accuracy: 0.12820, avg. loss over tasks: 0.90783, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.13980, Variance: 0.16703
Semantic Loss - Mean: 0.97533, Variance: 0.00219

Test Epoch: 66 
task: majority, mean loss: 1.04921, accuracy: 0.65600, task: max, mean loss: 1.28620, accuracy: 0.53400, task: top, mean loss: 1.53336, accuracy: 0.52900, task: multi, mean loss: 0.39274, multilabel_accuracy: 0.14200, avg. loss over tasks: 1.06538
Diversity Loss - Mean: -0.14276, Variance: 0.17804
Semantic Loss - Mean: 1.08176, Variance: 0.00047

Train Epoch: 67 
task: majority, mean loss: 0.94792, accuracy: 0.69680, task: max, mean loss: 1.00071, accuracy: 0.62840, task: top, mean loss: 1.27589, accuracy: 0.62140, task: multi, mean loss: 0.37178, multilabel_accuracy: 0.13720, avg. loss over tasks: 0.89908, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.13973, Variance: 0.16860
Semantic Loss - Mean: 0.96493, Variance: 0.00219

Test Epoch: 67 
task: majority, mean loss: 1.20269, accuracy: 0.62300, task: max, mean loss: 1.22128, accuracy: 0.55700, task: top, mean loss: 1.56567, accuracy: 0.52200, task: multi, mean loss: 0.39602, multilabel_accuracy: 0.13400, avg. loss over tasks: 1.09641
Diversity Loss - Mean: -0.14272, Variance: 0.17967
Semantic Loss - Mean: 1.09412, Variance: 0.00046

Train Epoch: 68 
task: majority, mean loss: 0.90879, accuracy: 0.71040, task: max, mean loss: 1.00025, accuracy: 0.63140, task: top, mean loss: 1.28701, accuracy: 0.61740, task: multi, mean loss: 0.37517, multilabel_accuracy: 0.13600, avg. loss over tasks: 0.89281, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.13968, Variance: 0.17015
Semantic Loss - Mean: 0.95902, Variance: 0.00220

Test Epoch: 68 
task: majority, mean loss: 1.13085, accuracy: 0.64600, task: max, mean loss: 1.26655, accuracy: 0.56900, task: top, mean loss: 1.61355, accuracy: 0.54000, task: multi, mean loss: 0.39934, multilabel_accuracy: 0.13700, avg. loss over tasks: 1.10257
Diversity Loss - Mean: -0.14268, Variance: 0.18078
Semantic Loss - Mean: 1.09337, Variance: 0.00046

Train Epoch: 69 
task: majority, mean loss: 0.92880, accuracy: 0.70440, task: max, mean loss: 1.00174, accuracy: 0.62000, task: top, mean loss: 1.28386, accuracy: 0.61380, task: multi, mean loss: 0.37711, multilabel_accuracy: 0.12840, avg. loss over tasks: 0.89788, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.13975, Variance: 0.17168
Semantic Loss - Mean: 0.96370, Variance: 0.00220

Test Epoch: 69 
task: majority, mean loss: 1.19610, accuracy: 0.60600, task: max, mean loss: 1.26630, accuracy: 0.56000, task: top, mean loss: 1.56647, accuracy: 0.51800, task: multi, mean loss: 0.39976, multilabel_accuracy: 0.12100, avg. loss over tasks: 1.10716
Diversity Loss - Mean: -0.14276, Variance: 0.18255
Semantic Loss - Mean: 1.10476, Variance: 0.00046

Train Epoch: 70 
task: majority, mean loss: 0.86244, accuracy: 0.72320, task: max, mean loss: 0.98663, accuracy: 0.64180, task: top, mean loss: 1.26202, accuracy: 0.62260, task: multi, mean loss: 0.37138, multilabel_accuracy: 0.14160, avg. loss over tasks: 0.87062, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.13996, Variance: 0.17328
Semantic Loss - Mean: 0.93518, Variance: 0.00220

Test Epoch: 70 
task: majority, mean loss: 1.19056, accuracy: 0.61900, task: max, mean loss: 1.23370, accuracy: 0.57500, task: top, mean loss: 1.46808, accuracy: 0.54700, task: multi, mean loss: 0.38477, multilabel_accuracy: 0.14200, avg. loss over tasks: 1.06928
Diversity Loss - Mean: -0.14274, Variance: 0.18407
Semantic Loss - Mean: 1.06361, Variance: 0.00045

Train Epoch: 71 
task: majority, mean loss: 0.88735, accuracy: 0.71700, task: max, mean loss: 0.95015, accuracy: 0.65400, task: top, mean loss: 1.25404, accuracy: 0.62560, task: multi, mean loss: 0.37126, multilabel_accuracy: 0.14460, avg. loss over tasks: 0.86570, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.13999, Variance: 0.17488
Semantic Loss - Mean: 0.93101, Variance: 0.00221

Test Epoch: 71 
task: majority, mean loss: 1.18196, accuracy: 0.62300, task: max, mean loss: 1.26108, accuracy: 0.54100, task: top, mean loss: 1.51484, accuracy: 0.54200, task: multi, mean loss: 0.39141, multilabel_accuracy: 0.13500, avg. loss over tasks: 1.08732
Diversity Loss - Mean: -0.14276, Variance: 0.18580
Semantic Loss - Mean: 1.08513, Variance: 0.00045

Train Epoch: 72 
task: majority, mean loss: 0.89342, accuracy: 0.71200, task: max, mean loss: 0.96519, accuracy: 0.65540, task: top, mean loss: 1.26280, accuracy: 0.62380, task: multi, mean loss: 0.37054, multilabel_accuracy: 0.13960, avg. loss over tasks: 0.87299, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.14000, Variance: 0.17650
Semantic Loss - Mean: 0.93922, Variance: 0.00221

Test Epoch: 72 
task: majority, mean loss: 1.19666, accuracy: 0.60400, task: max, mean loss: 1.18850, accuracy: 0.57900, task: top, mean loss: 1.56738, accuracy: 0.51500, task: multi, mean loss: 0.40473, multilabel_accuracy: 0.12300, avg. loss over tasks: 1.08932
Diversity Loss - Mean: -0.14276, Variance: 0.18756
Semantic Loss - Mean: 1.08493, Variance: 0.00045

Train Epoch: 73 
task: majority, mean loss: 0.86424, accuracy: 0.72680, task: max, mean loss: 0.96000, accuracy: 0.64860, task: top, mean loss: 1.23183, accuracy: 0.63100, task: multi, mean loss: 0.37061, multilabel_accuracy: 0.13800, avg. loss over tasks: 0.85667, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.13993, Variance: 0.17803
Semantic Loss - Mean: 0.92286, Variance: 0.00222

Test Epoch: 73 
task: majority, mean loss: 1.12615, accuracy: 0.63700, task: max, mean loss: 1.25199, accuracy: 0.57600, task: top, mean loss: 1.47506, accuracy: 0.55300, task: multi, mean loss: 0.39165, multilabel_accuracy: 0.13600, avg. loss over tasks: 1.06121
Diversity Loss - Mean: -0.14277, Variance: 0.18922
Semantic Loss - Mean: 1.06147, Variance: 0.00044

Train Epoch: 74 
task: majority, mean loss: 0.85135, accuracy: 0.73080, task: max, mean loss: 0.95218, accuracy: 0.65460, task: top, mean loss: 1.19690, accuracy: 0.64100, task: multi, mean loss: 0.37144, multilabel_accuracy: 0.13100, avg. loss over tasks: 0.84297, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.13989, Variance: 0.17946
Semantic Loss - Mean: 0.90995, Variance: 0.00222

Test Epoch: 74 
task: majority, mean loss: 1.14946, accuracy: 0.63600, task: max, mean loss: 1.33975, accuracy: 0.55100, task: top, mean loss: 1.56857, accuracy: 0.54500, task: multi, mean loss: 0.39586, multilabel_accuracy: 0.13100, avg. loss over tasks: 1.11341
Diversity Loss - Mean: -0.14276, Variance: 0.19069
Semantic Loss - Mean: 1.10476, Variance: 0.00044

Train Epoch: 75 
task: majority, mean loss: 0.84048, accuracy: 0.73300, task: max, mean loss: 0.93277, accuracy: 0.65900, task: top, mean loss: 1.20568, accuracy: 0.63640, task: multi, mean loss: 0.36827, multilabel_accuracy: 0.14240, avg. loss over tasks: 0.83680, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.13984, Variance: 0.18091
Semantic Loss - Mean: 0.90479, Variance: 0.00222

Test Epoch: 75 
task: majority, mean loss: 1.16767, accuracy: 0.63300, task: max, mean loss: 1.22775, accuracy: 0.58100, task: top, mean loss: 1.51068, accuracy: 0.54400, task: multi, mean loss: 0.38974, multilabel_accuracy: 0.14900, avg. loss over tasks: 1.07396
Diversity Loss - Mean: -0.14275, Variance: 0.19209
Semantic Loss - Mean: 1.06312, Variance: 0.00043

Train Epoch: 76 
task: majority, mean loss: 0.81282, accuracy: 0.74000, task: max, mean loss: 0.92802, accuracy: 0.66200, task: top, mean loss: 1.20952, accuracy: 0.63820, task: multi, mean loss: 0.36751, multilabel_accuracy: 0.13540, avg. loss over tasks: 0.82947, lr: 0.00016626926212375047
Diversity Loss - Mean: -0.14005, Variance: 0.18236
Semantic Loss - Mean: 0.89448, Variance: 0.00223

Test Epoch: 76 
task: majority, mean loss: 1.22382, accuracy: 0.61000, task: max, mean loss: 1.26625, accuracy: 0.55800, task: top, mean loss: 1.54735, accuracy: 0.51400, task: multi, mean loss: 0.40267, multilabel_accuracy: 0.13900, avg. loss over tasks: 1.11002
Diversity Loss - Mean: -0.14277, Variance: 0.19372
Semantic Loss - Mean: 1.09877, Variance: 0.00043

Train Epoch: 77 
task: majority, mean loss: 0.85555, accuracy: 0.72340, task: max, mean loss: 0.94439, accuracy: 0.65500, task: top, mean loss: 1.18498, accuracy: 0.64600, task: multi, mean loss: 0.36923, multilabel_accuracy: 0.14080, avg. loss over tasks: 0.83854, lr: 0.00015351814395573083
Diversity Loss - Mean: -0.14012, Variance: 0.18388
Semantic Loss - Mean: 0.90355, Variance: 0.00223

Test Epoch: 77 
task: majority, mean loss: 1.13342, accuracy: 0.63200, task: max, mean loss: 1.19453, accuracy: 0.57300, task: top, mean loss: 1.48337, accuracy: 0.54200, task: multi, mean loss: 0.38848, multilabel_accuracy: 0.13800, avg. loss over tasks: 1.04995
Diversity Loss - Mean: -0.14278, Variance: 0.19533
Semantic Loss - Mean: 1.04644, Variance: 0.00043

Train Epoch: 78 
task: majority, mean loss: 0.82178, accuracy: 0.73280, task: max, mean loss: 0.91550, accuracy: 0.66700, task: top, mean loss: 1.14684, accuracy: 0.65920, task: multi, mean loss: 0.36552, multilabel_accuracy: 0.14360, avg. loss over tasks: 0.81241, lr: 0.00014118976973084385
Diversity Loss - Mean: -0.14005, Variance: 0.18532
Semantic Loss - Mean: 0.87813, Variance: 0.00223

Test Epoch: 78 
task: majority, mean loss: 1.21266, accuracy: 0.62600, task: max, mean loss: 1.37441, accuracy: 0.53800, task: top, mean loss: 1.58671, accuracy: 0.53100, task: multi, mean loss: 0.40715, multilabel_accuracy: 0.12900, avg. loss over tasks: 1.14523
Diversity Loss - Mean: -0.14276, Variance: 0.19671
Semantic Loss - Mean: 1.12717, Variance: 0.00042

Train Epoch: 79 
task: majority, mean loss: 0.79069, accuracy: 0.74980, task: max, mean loss: 0.91523, accuracy: 0.66180, task: top, mean loss: 1.13949, accuracy: 0.66400, task: multi, mean loss: 0.36514, multilabel_accuracy: 0.15020, avg. loss over tasks: 0.80264, lr: 0.00012929915967404152
Diversity Loss - Mean: -0.13997, Variance: 0.18672
Semantic Loss - Mean: 0.87233, Variance: 0.00224

Test Epoch: 79 
task: majority, mean loss: 1.18855, accuracy: 0.64800, task: max, mean loss: 1.32755, accuracy: 0.55500, task: top, mean loss: 1.56373, accuracy: 0.54800, task: multi, mean loss: 0.39976, multilabel_accuracy: 0.12500, avg. loss over tasks: 1.11990
Diversity Loss - Mean: -0.14278, Variance: 0.19819
Semantic Loss - Mean: 1.10587, Variance: 0.00042

Train Epoch: 80 
task: majority, mean loss: 0.82397, accuracy: 0.73800, task: max, mean loss: 0.88039, accuracy: 0.67160, task: top, mean loss: 1.15798, accuracy: 0.65520, task: multi, mean loss: 0.36359, multilabel_accuracy: 0.14500, avg. loss over tasks: 0.80648, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.14008, Variance: 0.18815
Semantic Loss - Mean: 0.87120, Variance: 0.00224

Test Epoch: 80 
task: majority, mean loss: 1.09157, accuracy: 0.67200, task: max, mean loss: 1.37632, accuracy: 0.53000, task: top, mean loss: 1.56250, accuracy: 0.54000, task: multi, mean loss: 0.39820, multilabel_accuracy: 0.11900, avg. loss over tasks: 1.10715
Diversity Loss - Mean: -0.14279, Variance: 0.19984
Semantic Loss - Mean: 1.10461, Variance: 0.00042

Train Epoch: 81 
task: majority, mean loss: 0.81101, accuracy: 0.73680, task: max, mean loss: 0.87026, accuracy: 0.68840, task: top, mean loss: 1.16097, accuracy: 0.65760, task: multi, mean loss: 0.36296, multilabel_accuracy: 0.15120, avg. loss over tasks: 0.80130, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.14001, Variance: 0.18953
Semantic Loss - Mean: 0.86677, Variance: 0.00224

Test Epoch: 81 
task: majority, mean loss: 1.18397, accuracy: 0.62000, task: max, mean loss: 1.29147, accuracy: 0.56200, task: top, mean loss: 1.56769, accuracy: 0.51300, task: multi, mean loss: 0.39084, multilabel_accuracy: 0.13900, avg. loss over tasks: 1.10849
Diversity Loss - Mean: -0.14279, Variance: 0.20136
Semantic Loss - Mean: 1.10016, Variance: 0.00041

Train Epoch: 82 
task: majority, mean loss: 0.80016, accuracy: 0.74420, task: max, mean loss: 0.88444, accuracy: 0.67800, task: top, mean loss: 1.12927, accuracy: 0.66700, task: multi, mean loss: 0.36474, multilabel_accuracy: 0.14020, avg. loss over tasks: 0.79465, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.13998, Variance: 0.19086
Semantic Loss - Mean: 0.86211, Variance: 0.00224

Test Epoch: 82 
task: majority, mean loss: 1.21508, accuracy: 0.62900, task: max, mean loss: 1.38352, accuracy: 0.55300, task: top, mean loss: 1.68569, accuracy: 0.51300, task: multi, mean loss: 0.40474, multilabel_accuracy: 0.13200, avg. loss over tasks: 1.17226
Diversity Loss - Mean: -0.14278, Variance: 0.20269
Semantic Loss - Mean: 1.15556, Variance: 0.00041

Train Epoch: 83 
task: majority, mean loss: 0.76430, accuracy: 0.75980, task: max, mean loss: 0.87593, accuracy: 0.68120, task: top, mean loss: 1.12561, accuracy: 0.66240, task: multi, mean loss: 0.36337, multilabel_accuracy: 0.14240, avg. loss over tasks: 0.78230, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.14015, Variance: 0.19222
Semantic Loss - Mean: 0.84817, Variance: 0.00225

Test Epoch: 83 
task: majority, mean loss: 1.21601, accuracy: 0.62300, task: max, mean loss: 1.33278, accuracy: 0.57600, task: top, mean loss: 1.58444, accuracy: 0.53300, task: multi, mean loss: 0.39606, multilabel_accuracy: 0.13700, avg. loss over tasks: 1.13232
Diversity Loss - Mean: -0.14277, Variance: 0.20405
Semantic Loss - Mean: 1.11580, Variance: 0.00041

Train Epoch: 84 
task: majority, mean loss: 0.78247, accuracy: 0.74600, task: max, mean loss: 0.87037, accuracy: 0.68940, task: top, mean loss: 1.10035, accuracy: 0.66700, task: multi, mean loss: 0.35969, multilabel_accuracy: 0.15300, avg. loss over tasks: 0.77822, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.14012, Variance: 0.19357
Semantic Loss - Mean: 0.84514, Variance: 0.00225

Test Epoch: 84 
task: majority, mean loss: 1.30185, accuracy: 0.61000, task: max, mean loss: 1.38919, accuracy: 0.54700, task: top, mean loss: 1.72860, accuracy: 0.50700, task: multi, mean loss: 0.39887, multilabel_accuracy: 0.13800, avg. loss over tasks: 1.20463
Diversity Loss - Mean: -0.14278, Variance: 0.20543
Semantic Loss - Mean: 1.18439, Variance: 0.00041

Train Epoch: 85 
task: majority, mean loss: 0.78117, accuracy: 0.75320, task: max, mean loss: 0.86141, accuracy: 0.68400, task: top, mean loss: 1.10398, accuracy: 0.67140, task: multi, mean loss: 0.36228, multilabel_accuracy: 0.14320, avg. loss over tasks: 0.77721, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.14006, Variance: 0.19490
Semantic Loss - Mean: 0.84410, Variance: 0.00225

Test Epoch: 85 
task: majority, mean loss: 1.28426, accuracy: 0.59500, task: max, mean loss: 1.46092, accuracy: 0.50900, task: top, mean loss: 1.74313, accuracy: 0.49700, task: multi, mean loss: 0.41221, multilabel_accuracy: 0.12400, avg. loss over tasks: 1.22513
Diversity Loss - Mean: -0.14278, Variance: 0.20685
Semantic Loss - Mean: 1.20561, Variance: 0.00040

Train Epoch: 86 
task: majority, mean loss: 0.75374, accuracy: 0.75800, task: max, mean loss: 0.85249, accuracy: 0.68680, task: top, mean loss: 1.08000, accuracy: 0.67840, task: multi, mean loss: 0.36041, multilabel_accuracy: 0.15240, avg. loss over tasks: 0.76166, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.13999, Variance: 0.19616
Semantic Loss - Mean: 0.82684, Variance: 0.00225

Test Epoch: 86 
task: majority, mean loss: 1.21987, accuracy: 0.63100, task: max, mean loss: 1.40175, accuracy: 0.54700, task: top, mean loss: 1.61998, accuracy: 0.52500, task: multi, mean loss: 0.40275, multilabel_accuracy: 0.12800, avg. loss over tasks: 1.16109
Diversity Loss - Mean: -0.14279, Variance: 0.20821
Semantic Loss - Mean: 1.13880, Variance: 0.00040

Train Epoch: 87 
task: majority, mean loss: 0.77714, accuracy: 0.74860, task: max, mean loss: 0.84556, accuracy: 0.69700, task: top, mean loss: 1.07730, accuracy: 0.68380, task: multi, mean loss: 0.36047, multilabel_accuracy: 0.14640, avg. loss over tasks: 0.76512, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.14006, Variance: 0.19745
Semantic Loss - Mean: 0.83138, Variance: 0.00226

Test Epoch: 87 
task: majority, mean loss: 1.28506, accuracy: 0.60800, task: max, mean loss: 1.46670, accuracy: 0.55400, task: top, mean loss: 1.70069, accuracy: 0.49600, task: multi, mean loss: 0.40935, multilabel_accuracy: 0.11900, avg. loss over tasks: 1.21545
Diversity Loss - Mean: -0.14278, Variance: 0.20946
Semantic Loss - Mean: 1.18644, Variance: 0.00040

Train Epoch: 88 
task: majority, mean loss: 0.79484, accuracy: 0.74560, task: max, mean loss: 0.83930, accuracy: 0.69100, task: top, mean loss: 1.10230, accuracy: 0.67120, task: multi, mean loss: 0.36124, multilabel_accuracy: 0.14200, avg. loss over tasks: 0.77442, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.14012, Variance: 0.19872
Semantic Loss - Mean: 0.84248, Variance: 0.00226

Test Epoch: 88 
task: majority, mean loss: 1.25953, accuracy: 0.62100, task: max, mean loss: 1.47930, accuracy: 0.54700, task: top, mean loss: 1.67455, accuracy: 0.49600, task: multi, mean loss: 0.40628, multilabel_accuracy: 0.13000, avg. loss over tasks: 1.20492
Diversity Loss - Mean: -0.14279, Variance: 0.21079
Semantic Loss - Mean: 1.18166, Variance: 0.00040

Train Epoch: 89 
task: majority, mean loss: 0.75348, accuracy: 0.75900, task: max, mean loss: 0.84429, accuracy: 0.69420, task: top, mean loss: 1.07331, accuracy: 0.68120, task: multi, mean loss: 0.36024, multilabel_accuracy: 0.14700, avg. loss over tasks: 0.75783, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.14021, Variance: 0.19999
Semantic Loss - Mean: 0.82478, Variance: 0.00226

Test Epoch: 89 
task: majority, mean loss: 1.29802, accuracy: 0.58200, task: max, mean loss: 1.46953, accuracy: 0.53600, task: top, mean loss: 1.72921, accuracy: 0.47800, task: multi, mean loss: 0.40433, multilabel_accuracy: 0.14400, avg. loss over tasks: 1.22527
Diversity Loss - Mean: -0.14279, Variance: 0.21215
Semantic Loss - Mean: 1.20172, Variance: 0.00040

Train Epoch: 90 
task: majority, mean loss: 0.76598, accuracy: 0.75160, task: max, mean loss: 0.83885, accuracy: 0.69580, task: top, mean loss: 1.07165, accuracy: 0.68180, task: multi, mean loss: 0.35952, multilabel_accuracy: 0.14420, avg. loss over tasks: 0.75900, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.14022, Variance: 0.20125
Semantic Loss - Mean: 0.82600, Variance: 0.00226

Test Epoch: 90 
task: majority, mean loss: 1.18854, accuracy: 0.63600, task: max, mean loss: 1.52000, accuracy: 0.52200, task: top, mean loss: 1.73422, accuracy: 0.48700, task: multi, mean loss: 0.41392, multilabel_accuracy: 0.12200, avg. loss over tasks: 1.21417
Diversity Loss - Mean: -0.14279, Variance: 0.21341
Semantic Loss - Mean: 1.18892, Variance: 0.00039

Train Epoch: 91 
task: majority, mean loss: 0.74435, accuracy: 0.75720, task: max, mean loss: 0.83003, accuracy: 0.70540, task: top, mean loss: 1.08737, accuracy: 0.67740, task: multi, mean loss: 0.35862, multilabel_accuracy: 0.14780, avg. loss over tasks: 0.75509, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.14015, Variance: 0.20246
Semantic Loss - Mean: 0.81983, Variance: 0.00226

Test Epoch: 91 
task: majority, mean loss: 1.32444, accuracy: 0.60300, task: max, mean loss: 1.47547, accuracy: 0.53800, task: top, mean loss: 1.75545, accuracy: 0.49100, task: multi, mean loss: 0.41201, multilabel_accuracy: 0.11400, avg. loss over tasks: 1.24184
Diversity Loss - Mean: -0.14279, Variance: 0.21465
Semantic Loss - Mean: 1.21691, Variance: 0.00039

Train Epoch: 92 
task: majority, mean loss: 0.74227, accuracy: 0.75780, task: max, mean loss: 0.82397, accuracy: 0.70060, task: top, mean loss: 1.05632, accuracy: 0.68440, task: multi, mean loss: 0.35896, multilabel_accuracy: 0.14700, avg. loss over tasks: 0.74538, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.14007, Variance: 0.20364
Semantic Loss - Mean: 0.80981, Variance: 0.00226

Test Epoch: 92 
task: majority, mean loss: 1.30085, accuracy: 0.61200, task: max, mean loss: 1.43926, accuracy: 0.53800, task: top, mean loss: 1.84289, accuracy: 0.45900, task: multi, mean loss: 0.41176, multilabel_accuracy: 0.13500, avg. loss over tasks: 1.24869
Diversity Loss - Mean: -0.14279, Variance: 0.21586
Semantic Loss - Mean: 1.21973, Variance: 0.00039

Train Epoch: 93 
task: majority, mean loss: 0.74211, accuracy: 0.76720, task: max, mean loss: 0.81699, accuracy: 0.70740, task: top, mean loss: 1.07866, accuracy: 0.68080, task: multi, mean loss: 0.35847, multilabel_accuracy: 0.14940, avg. loss over tasks: 0.74906, lr: 1.583728472513982e-05
Diversity Loss - Mean: -0.14012, Variance: 0.20480
Semantic Loss - Mean: 0.81562, Variance: 0.00226

Test Epoch: 93 
task: majority, mean loss: 1.19282, accuracy: 0.63500, task: max, mean loss: 1.48035, accuracy: 0.53200, task: top, mean loss: 1.65762, accuracy: 0.51600, task: multi, mean loss: 0.40447, multilabel_accuracy: 0.13100, avg. loss over tasks: 1.18382
Diversity Loss - Mean: -0.14279, Variance: 0.21705
Semantic Loss - Mean: 1.15949, Variance: 0.00039

Train Epoch: 94 
task: majority, mean loss: 0.71166, accuracy: 0.77020, task: max, mean loss: 0.78742, accuracy: 0.71960, task: top, mean loss: 1.04213, accuracy: 0.69160, task: multi, mean loss: 0.35367, multilabel_accuracy: 0.15440, avg. loss over tasks: 0.72372, lr: 1.191527343346406e-05
Diversity Loss - Mean: -0.14008, Variance: 0.20590
Semantic Loss - Mean: 0.79269, Variance: 0.00226

Test Epoch: 94 
task: majority, mean loss: 1.24306, accuracy: 0.62100, task: max, mean loss: 1.52779, accuracy: 0.53000, task: top, mean loss: 1.70798, accuracy: 0.50800, task: multi, mean loss: 0.40177, multilabel_accuracy: 0.14000, avg. loss over tasks: 1.22015
Diversity Loss - Mean: -0.14279, Variance: 0.21820
Semantic Loss - Mean: 1.18748, Variance: 0.00038

Train Epoch: 95 
task: majority, mean loss: 0.74133, accuracy: 0.76100, task: max, mean loss: 0.82261, accuracy: 0.70780, task: top, mean loss: 1.06815, accuracy: 0.68280, task: multi, mean loss: 0.35930, multilabel_accuracy: 0.14920, avg. loss over tasks: 0.74785, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.14026, Variance: 0.20702
Semantic Loss - Mean: 0.81221, Variance: 0.00226

Test Epoch: 95 
task: majority, mean loss: 1.31500, accuracy: 0.58800, task: max, mean loss: 1.51280, accuracy: 0.53200, task: top, mean loss: 1.75579, accuracy: 0.49000, task: multi, mean loss: 0.41260, multilabel_accuracy: 0.13000, avg. loss over tasks: 1.24905
Diversity Loss - Mean: -0.14279, Variance: 0.21938
Semantic Loss - Mean: 1.21762, Variance: 0.00038

Train Epoch: 96 
task: majority, mean loss: 0.73422, accuracy: 0.76820, task: max, mean loss: 0.82247, accuracy: 0.70040, task: top, mean loss: 1.03001, accuracy: 0.70040, task: multi, mean loss: 0.35815, multilabel_accuracy: 0.15020, avg. loss over tasks: 0.73621, lr: 5.86109966358566e-06
Diversity Loss - Mean: -0.14011, Variance: 0.20811
Semantic Loss - Mean: 0.80435, Variance: 0.00226

Test Epoch: 96 
task: majority, mean loss: 1.26425, accuracy: 0.60100, task: max, mean loss: 1.49754, accuracy: 0.54500, task: top, mean loss: 1.75542, accuracy: 0.49800, task: multi, mean loss: 0.40728, multilabel_accuracy: 0.12900, avg. loss over tasks: 1.23112
Diversity Loss - Mean: -0.14279, Variance: 0.22051
Semantic Loss - Mean: 1.20222, Variance: 0.00038

Train Epoch: 97 
task: majority, mean loss: 0.69872, accuracy: 0.77160, task: max, mean loss: 0.78308, accuracy: 0.72280, task: top, mean loss: 1.03715, accuracy: 0.69500, task: multi, mean loss: 0.35357, multilabel_accuracy: 0.15200, avg. loss over tasks: 0.71813, lr: 3.7363132635474912e-06
Diversity Loss - Mean: -0.14009, Variance: 0.20917
Semantic Loss - Mean: 0.78767, Variance: 0.00227

Test Epoch: 97 
task: majority, mean loss: 1.31900, accuracy: 0.61100, task: max, mean loss: 1.54052, accuracy: 0.54000, task: top, mean loss: 1.74362, accuracy: 0.49400, task: multi, mean loss: 0.41381, multilabel_accuracy: 0.12400, avg. loss over tasks: 1.25424
Diversity Loss - Mean: -0.14279, Variance: 0.22160
Semantic Loss - Mean: 1.21779, Variance: 0.00038

Train Epoch: 98 
task: majority, mean loss: 0.72103, accuracy: 0.76940, task: max, mean loss: 0.80775, accuracy: 0.70900, task: top, mean loss: 1.06275, accuracy: 0.68500, task: multi, mean loss: 0.35573, multilabel_accuracy: 0.14940, avg. loss over tasks: 0.73681, lr: 2.216756895217758e-06
Diversity Loss - Mean: -0.14017, Variance: 0.21021
Semantic Loss - Mean: 0.80261, Variance: 0.00227

Test Epoch: 98 
task: majority, mean loss: 1.30851, accuracy: 0.60500, task: max, mean loss: 1.48447, accuracy: 0.54100, task: top, mean loss: 1.71128, accuracy: 0.49900, task: multi, mean loss: 0.40498, multilabel_accuracy: 0.14300, avg. loss over tasks: 1.22731
Diversity Loss - Mean: -0.14279, Variance: 0.22267
Semantic Loss - Mean: 1.19737, Variance: 0.00038

Train Epoch: 99 
task: majority, mean loss: 0.74109, accuracy: 0.76300, task: max, mean loss: 0.79283, accuracy: 0.71600, task: top, mean loss: 1.05288, accuracy: 0.68680, task: multi, mean loss: 0.35493, multilabel_accuracy: 0.15100, avg. loss over tasks: 0.73543, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.14014, Variance: 0.21122
Semantic Loss - Mean: 0.80177, Variance: 0.00227

Test Epoch: 99 
task: majority, mean loss: 1.29989, accuracy: 0.58700, task: max, mean loss: 1.44654, accuracy: 0.54800, task: top, mean loss: 1.65527, accuracy: 0.51600, task: multi, mean loss: 0.40102, multilabel_accuracy: 0.12600, avg. loss over tasks: 1.20068
Diversity Loss - Mean: -0.14279, Variance: 0.22373
Semantic Loss - Mean: 1.17063, Variance: 0.00037

Train Epoch: 100 
task: majority, mean loss: 0.71703, accuracy: 0.77140, task: max, mean loss: 0.80086, accuracy: 0.71380, task: top, mean loss: 1.03751, accuracy: 0.69480, task: multi, mean loss: 0.35464, multilabel_accuracy: 0.15280, avg. loss over tasks: 0.72751, lr: 1e-06
Diversity Loss - Mean: -0.14015, Variance: 0.21222
Semantic Loss - Mean: 0.79427, Variance: 0.00227

Test Epoch: 100 
task: majority, mean loss: 1.25161, accuracy: 0.61000, task: max, mean loss: 1.40944, accuracy: 0.55700, task: top, mean loss: 1.60411, accuracy: 0.52100, task: multi, mean loss: 0.40583, multilabel_accuracy: 0.15500, avg. loss over tasks: 1.16775
Diversity Loss - Mean: -0.14279, Variance: 0.22476
Semantic Loss - Mean: 1.13913, Variance: 0.00037

