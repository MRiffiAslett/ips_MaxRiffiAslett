Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.35326, accuracy: 0.12300, task: max, mean loss: 2.20824, accuracy: 0.24100, task: top, mean loss: 2.35197, accuracy: 0.09600, task: multi, mean loss: 0.69817, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.90291, lr: 0.0001
Diversity Loss - Mean: -0.11142, Variance: 0.07657
Semantic Loss - Mean: 1.99409, Variance: 0.00821

Test Epoch: 1 
task: majority, mean loss: 2.30884, accuracy: 0.10000, task: max, mean loss: 1.91727, accuracy: 0.26900, task: top, mean loss: 2.31212, accuracy: 0.09800, task: multi, mean loss: 0.63073, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79224
Diversity Loss - Mean: -0.14134, Variance: 0.09535
Semantic Loss - Mean: 1.91027, Variance: 0.00452

Train Epoch: 2 
task: majority, mean loss: 2.32366, accuracy: 0.10900, task: max, mean loss: 1.86559, accuracy: 0.26700, task: top, mean loss: 2.33162, accuracy: 0.08400, task: multi, mean loss: 0.61481, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78392, lr: 0.0002
Diversity Loss - Mean: -0.14193, Variance: 0.09446
Semantic Loss - Mean: 1.83839, Variance: 0.00487

Test Epoch: 2 
task: majority, mean loss: 2.32025, accuracy: 0.10000, task: max, mean loss: 1.89877, accuracy: 0.21300, task: top, mean loss: 2.32073, accuracy: 0.10100, task: multi, mean loss: 0.60248, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78556
Diversity Loss - Mean: -0.14117, Variance: 0.11702
Semantic Loss - Mean: 1.79727, Variance: 0.00241

Train Epoch: 3 
task: majority, mean loss: 2.33356, accuracy: 0.09200, task: max, mean loss: 1.85505, accuracy: 0.24700, task: top, mean loss: 2.32372, accuracy: 0.09500, task: multi, mean loss: 0.60716, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77987, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14178, Variance: 0.11203
Semantic Loss - Mean: 1.77721, Variance: 0.00332

Test Epoch: 3 
task: majority, mean loss: 2.33199, accuracy: 0.08900, task: max, mean loss: 1.86912, accuracy: 0.27600, task: top, mean loss: 2.32810, accuracy: 0.10300, task: multi, mean loss: 0.60248, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78292
Diversity Loss - Mean: -0.14184, Variance: 0.12947
Semantic Loss - Mean: 1.77693, Variance: 0.00162

Train Epoch: 4 
task: majority, mean loss: 2.33715, accuracy: 0.09700, task: max, mean loss: 1.84615, accuracy: 0.24800, task: top, mean loss: 2.34129, accuracy: 0.09400, task: multi, mean loss: 0.60670, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78282, lr: 0.0004
Diversity Loss - Mean: -0.14188, Variance: 0.12296
Semantic Loss - Mean: 1.77129, Variance: 0.00253

Test Epoch: 4 
task: majority, mean loss: 2.32133, accuracy: 0.10000, task: max, mean loss: 1.86310, accuracy: 0.22200, task: top, mean loss: 2.34465, accuracy: 0.10200, task: multi, mean loss: 0.60329, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78309
Diversity Loss - Mean: -0.14115, Variance: 0.13421
Semantic Loss - Mean: 1.77626, Variance: 0.00122

Train Epoch: 5 
task: majority, mean loss: 2.33026, accuracy: 0.09700, task: max, mean loss: 1.83499, accuracy: 0.24900, task: top, mean loss: 2.32237, accuracy: 0.10700, task: multi, mean loss: 0.60518, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77320, lr: 0.0005
Diversity Loss - Mean: -0.14183, Variance: 0.12932
Semantic Loss - Mean: 1.76822, Variance: 0.00206

Test Epoch: 5 
task: majority, mean loss: 2.31816, accuracy: 0.10200, task: max, mean loss: 1.86583, accuracy: 0.27400, task: top, mean loss: 2.30787, accuracy: 0.10100, task: multi, mean loss: 0.60237, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77356
Diversity Loss - Mean: -0.14175, Variance: 0.13775
Semantic Loss - Mean: 1.77076, Variance: 0.00098

Train Epoch: 6 
task: majority, mean loss: 2.32851, accuracy: 0.11000, task: max, mean loss: 1.84591, accuracy: 0.24800, task: top, mean loss: 2.32995, accuracy: 0.10900, task: multi, mean loss: 0.60705, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77786, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.14196, Variance: 0.13275
Semantic Loss - Mean: 1.76979, Variance: 0.00174

Test Epoch: 6 
task: majority, mean loss: 2.33636, accuracy: 0.09000, task: max, mean loss: 1.86182, accuracy: 0.24300, task: top, mean loss: 2.31796, accuracy: 0.10400, task: multi, mean loss: 0.60162, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77944
Diversity Loss - Mean: -0.14185, Variance: 0.13687
Semantic Loss - Mean: 1.77047, Variance: 0.00083

Train Epoch: 7 
task: majority, mean loss: 2.31308, accuracy: 0.10700, task: max, mean loss: 1.85281, accuracy: 0.25800, task: top, mean loss: 2.31837, accuracy: 0.10300, task: multi, mean loss: 0.60750, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77294, lr: 0.0007
Diversity Loss - Mean: -0.14136, Variance: 0.13327
Semantic Loss - Mean: 1.76770, Variance: 0.00151

Test Epoch: 7 
task: majority, mean loss: 2.31413, accuracy: 0.09700, task: max, mean loss: 1.94107, accuracy: 0.16400, task: top, mean loss: 2.31883, accuracy: 0.10100, task: multi, mean loss: 0.60448, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79463
Diversity Loss - Mean: -0.13948, Variance: 0.13687
Semantic Loss - Mean: 1.77931, Variance: 0.00072

Train Epoch: 8 
task: majority, mean loss: 2.32000, accuracy: 0.11300, task: max, mean loss: 1.83665, accuracy: 0.25000, task: top, mean loss: 2.32896, accuracy: 0.10300, task: multi, mean loss: 0.60618, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77295, lr: 0.0008
Diversity Loss - Mean: -0.14068, Variance: 0.13422
Semantic Loss - Mean: 1.76975, Variance: 0.00134

Test Epoch: 8 
task: majority, mean loss: 2.33197, accuracy: 0.11100, task: max, mean loss: 1.87162, accuracy: 0.27400, task: top, mean loss: 2.31459, accuracy: 0.09300, task: multi, mean loss: 0.60246, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78016
Diversity Loss - Mean: -0.13569, Variance: 0.13761
Semantic Loss - Mean: 1.77724, Variance: 0.00064

Train Epoch: 9 
task: majority, mean loss: 2.33568, accuracy: 0.10700, task: max, mean loss: 1.84983, accuracy: 0.24400, task: top, mean loss: 2.33036, accuracy: 0.10000, task: multi, mean loss: 0.60748, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78084, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.14160, Variance: 0.13596
Semantic Loss - Mean: 1.77251, Variance: 0.00120

Test Epoch: 9 
task: majority, mean loss: 2.39378, accuracy: 0.08900, task: max, mean loss: 1.87567, accuracy: 0.21300, task: top, mean loss: 2.34849, accuracy: 0.10300, task: multi, mean loss: 0.60317, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.80528
Diversity Loss - Mean: -0.12274, Variance: 0.13972
Semantic Loss - Mean: 1.78552, Variance: 0.00061

Train Epoch: 10 
task: majority, mean loss: 2.33854, accuracy: 0.08400, task: max, mean loss: 1.84726, accuracy: 0.22900, task: top, mean loss: 2.33096, accuracy: 0.11200, task: multi, mean loss: 0.60563, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78060, lr: 0.001
Diversity Loss - Mean: -0.14233, Variance: 0.13789
Semantic Loss - Mean: 1.76907, Variance: 0.00109

Test Epoch: 10 
task: majority, mean loss: 2.35986, accuracy: 0.09400, task: max, mean loss: 1.85789, accuracy: 0.27400, task: top, mean loss: 2.34067, accuracy: 0.09800, task: multi, mean loss: 0.60305, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79037
Diversity Loss - Mean: -0.13125, Variance: 0.14268
Semantic Loss - Mean: 1.78086, Variance: 0.00058

Train Epoch: 11 
task: majority, mean loss: 2.33164, accuracy: 0.10700, task: max, mean loss: 1.84259, accuracy: 0.25500, task: top, mean loss: 2.33517, accuracy: 0.08600, task: multi, mean loss: 0.60581, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77880, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.14240, Variance: 0.14019
Semantic Loss - Mean: 1.76720, Variance: 0.00100

Test Epoch: 11 
task: majority, mean loss: 2.30954, accuracy: 0.10900, task: max, mean loss: 1.87488, accuracy: 0.21300, task: top, mean loss: 2.32337, accuracy: 0.10100, task: multi, mean loss: 0.60165, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77736
Diversity Loss - Mean: -0.14256, Variance: 0.14499
Semantic Loss - Mean: 1.77163, Variance: 0.00053

Train Epoch: 12 
task: majority, mean loss: 2.32785, accuracy: 0.08100, task: max, mean loss: 1.83062, accuracy: 0.25600, task: top, mean loss: 2.31530, accuracy: 0.10400, task: multi, mean loss: 0.60544, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76980, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.14245, Variance: 0.14219
Semantic Loss - Mean: 1.76211, Variance: 0.00092

Test Epoch: 12 
task: majority, mean loss: 2.33917, accuracy: 0.10000, task: max, mean loss: 1.89543, accuracy: 0.21300, task: top, mean loss: 2.30176, accuracy: 0.13000, task: multi, mean loss: 0.60270, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78477
Diversity Loss - Mean: -0.14270, Variance: 0.14675
Semantic Loss - Mean: 1.77609, Variance: 0.00048

Train Epoch: 13 
task: majority, mean loss: 2.32009, accuracy: 0.09800, task: max, mean loss: 1.82824, accuracy: 0.24800, task: top, mean loss: 2.31367, accuracy: 0.11900, task: multi, mean loss: 0.60546, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76686, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.14256, Variance: 0.14396
Semantic Loss - Mean: 1.76223, Variance: 0.00085

Test Epoch: 13 
task: majority, mean loss: 2.33233, accuracy: 0.08900, task: max, mean loss: 1.88610, accuracy: 0.21300, task: top, mean loss: 2.32364, accuracy: 0.10300, task: multi, mean loss: 0.60143, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78588
Diversity Loss - Mean: -0.14274, Variance: 0.14784
Semantic Loss - Mean: 1.77604, Variance: 0.00045

Train Epoch: 14 
task: majority, mean loss: 2.31922, accuracy: 0.10300, task: max, mean loss: 1.83251, accuracy: 0.23600, task: top, mean loss: 2.32288, accuracy: 0.10600, task: multi, mean loss: 0.60492, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76988, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.14254, Variance: 0.14531
Semantic Loss - Mean: 1.76321, Variance: 0.00080

Test Epoch: 14 
task: majority, mean loss: 2.31675, accuracy: 0.10900, task: max, mean loss: 1.86572, accuracy: 0.21300, task: top, mean loss: 2.31392, accuracy: 0.09600, task: multi, mean loss: 0.60144, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77446
Diversity Loss - Mean: -0.14238, Variance: 0.14897
Semantic Loss - Mean: 1.76921, Variance: 0.00042

Train Epoch: 15 
task: majority, mean loss: 2.31780, accuracy: 0.10500, task: max, mean loss: 1.83308, accuracy: 0.25800, task: top, mean loss: 2.32398, accuracy: 0.08900, task: multi, mean loss: 0.60448, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76984, lr: 0.000992411472629598
Diversity Loss - Mean: -0.14253, Variance: 0.14661
Semantic Loss - Mean: 1.76189, Variance: 0.00075

Test Epoch: 15 
task: majority, mean loss: 2.31433, accuracy: 0.09400, task: max, mean loss: 1.86419, accuracy: 0.27400, task: top, mean loss: 2.31132, accuracy: 0.09600, task: multi, mean loss: 0.60265, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77313
Diversity Loss - Mean: -0.14276, Variance: 0.15015
Semantic Loss - Mean: 1.77003, Variance: 0.00039

Train Epoch: 16 
task: majority, mean loss: 2.31895, accuracy: 0.11000, task: max, mean loss: 1.82864, accuracy: 0.24200, task: top, mean loss: 2.31944, accuracy: 0.09100, task: multi, mean loss: 0.60409, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76778, lr: 0.000989084726566536
Diversity Loss - Mean: -0.14256, Variance: 0.14775
Semantic Loss - Mean: 1.76133, Variance: 0.00070

Test Epoch: 16 
task: majority, mean loss: 2.32311, accuracy: 0.09400, task: max, mean loss: 1.86156, accuracy: 0.27400, task: top, mean loss: 2.31895, accuracy: 0.10100, task: multi, mean loss: 0.60108, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77618
Diversity Loss - Mean: -0.14265, Variance: 0.15155
Semantic Loss - Mean: 1.76915, Variance: 0.00036

Train Epoch: 17 
task: majority, mean loss: 2.31544, accuracy: 0.08800, task: max, mean loss: 1.82217, accuracy: 0.26200, task: top, mean loss: 2.31614, accuracy: 0.10500, task: multi, mean loss: 0.60392, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76442, lr: 0.00098516271527486
Diversity Loss - Mean: -0.14258, Variance: 0.14905
Semantic Loss - Mean: 1.76004, Variance: 0.00066

Test Epoch: 17 
task: majority, mean loss: 2.33745, accuracy: 0.08900, task: max, mean loss: 1.86248, accuracy: 0.27400, task: top, mean loss: 2.31190, accuracy: 0.10100, task: multi, mean loss: 0.60290, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77868
Diversity Loss - Mean: -0.14278, Variance: 0.15230
Semantic Loss - Mean: 1.77119, Variance: 0.00034

Train Epoch: 18 
task: majority, mean loss: 2.31386, accuracy: 0.12900, task: max, mean loss: 1.82430, accuracy: 0.26000, task: top, mean loss: 2.30913, accuracy: 0.11400, task: multi, mean loss: 0.60345, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76269, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.14258, Variance: 0.14977
Semantic Loss - Mean: 1.75944, Variance: 0.00063

Test Epoch: 18 
task: majority, mean loss: 2.31601, accuracy: 0.11100, task: max, mean loss: 1.86798, accuracy: 0.27400, task: top, mean loss: 2.31331, accuracy: 0.10400, task: multi, mean loss: 0.60142, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77468
Diversity Loss - Mean: -0.14277, Variance: 0.15277
Semantic Loss - Mean: 1.76842, Variance: 0.00032

Train Epoch: 19 
task: majority, mean loss: 2.31760, accuracy: 0.10900, task: max, mean loss: 1.82920, accuracy: 0.25800, task: top, mean loss: 2.31580, accuracy: 0.10700, task: multi, mean loss: 0.60459, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76680, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.14258, Variance: 0.15039
Semantic Loss - Mean: 1.76031, Variance: 0.00060

Test Epoch: 19 
task: majority, mean loss: 2.31336, accuracy: 0.08900, task: max, mean loss: 1.87836, accuracy: 0.21300, task: top, mean loss: 2.29897, accuracy: 0.12600, task: multi, mean loss: 0.60275, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77336
Diversity Loss - Mean: -0.14274, Variance: 0.15335
Semantic Loss - Mean: 1.76944, Variance: 0.00031

Train Epoch: 20 
task: majority, mean loss: 2.31585, accuracy: 0.11000, task: max, mean loss: 1.83273, accuracy: 0.23500, task: top, mean loss: 2.31198, accuracy: 0.10400, task: multi, mean loss: 0.60318, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76593, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.14261, Variance: 0.15100
Semantic Loss - Mean: 1.76059, Variance: 0.00057

Test Epoch: 20 
task: majority, mean loss: 2.31531, accuracy: 0.09400, task: max, mean loss: 1.86325, accuracy: 0.27400, task: top, mean loss: 2.30260, accuracy: 0.10100, task: multi, mean loss: 0.60077, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77048
Diversity Loss - Mean: -0.14275, Variance: 0.15385
Semantic Loss - Mean: 1.76866, Variance: 0.00029

Train Epoch: 21 
task: majority, mean loss: 2.31559, accuracy: 0.11100, task: max, mean loss: 1.83239, accuracy: 0.26700, task: top, mean loss: 2.31312, accuracy: 0.10800, task: multi, mean loss: 0.60326, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76609, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.14258, Variance: 0.15150
Semantic Loss - Mean: 1.76058, Variance: 0.00054

Test Epoch: 21 
task: majority, mean loss: 2.30909, accuracy: 0.10000, task: max, mean loss: 1.86047, accuracy: 0.27400, task: top, mean loss: 2.30062, accuracy: 0.10100, task: multi, mean loss: 0.60153, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76793
Diversity Loss - Mean: -0.14271, Variance: 0.15425
Semantic Loss - Mean: 1.76654, Variance: 0.00028

Train Epoch: 22 
task: majority, mean loss: 2.31786, accuracy: 0.08900, task: max, mean loss: 1.82341, accuracy: 0.26700, task: top, mean loss: 2.30300, accuracy: 0.13400, task: multi, mean loss: 0.60297, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76181, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.14259, Variance: 0.15197
Semantic Loss - Mean: 1.75918, Variance: 0.00052

Test Epoch: 22 
task: majority, mean loss: 2.31722, accuracy: 0.08900, task: max, mean loss: 1.85945, accuracy: 0.27400, task: top, mean loss: 2.30745, accuracy: 0.10100, task: multi, mean loss: 0.60144, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77139
Diversity Loss - Mean: -0.14255, Variance: 0.15438
Semantic Loss - Mean: 1.77112, Variance: 0.00027

Train Epoch: 23 
task: majority, mean loss: 2.31046, accuracy: 0.10500, task: max, mean loss: 1.82266, accuracy: 0.24900, task: top, mean loss: 2.30875, accuracy: 0.11000, task: multi, mean loss: 0.60368, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76139, lr: 0.000949447626126434
Diversity Loss - Mean: -0.14259, Variance: 0.15227
Semantic Loss - Mean: 1.75873, Variance: 0.00050

Test Epoch: 23 
task: majority, mean loss: 2.31577, accuracy: 0.08900, task: max, mean loss: 1.85963, accuracy: 0.27400, task: top, mean loss: 2.29555, accuracy: 0.13000, task: multi, mean loss: 0.60146, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76810
Diversity Loss - Mean: -0.14272, Variance: 0.15452
Semantic Loss - Mean: 1.76813, Variance: 0.00026

Train Epoch: 24 
task: majority, mean loss: 2.31388, accuracy: 0.09500, task: max, mean loss: 1.82085, accuracy: 0.27000, task: top, mean loss: 2.31370, accuracy: 0.11400, task: multi, mean loss: 0.60365, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76302, lr: 0.000941532322633034
Diversity Loss - Mean: -0.14259, Variance: 0.15249
Semantic Loss - Mean: 1.75893, Variance: 0.00048

Test Epoch: 24 
task: majority, mean loss: 2.30761, accuracy: 0.08900, task: max, mean loss: 1.86291, accuracy: 0.27400, task: top, mean loss: 2.30713, accuracy: 0.10100, task: multi, mean loss: 0.60181, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76986
Diversity Loss - Mean: -0.14278, Variance: 0.15462
Semantic Loss - Mean: 1.76828, Variance: 0.00024

Train Epoch: 25 
task: majority, mean loss: 2.31396, accuracy: 0.10100, task: max, mean loss: 1.82115, accuracy: 0.24800, task: top, mean loss: 2.30354, accuracy: 0.11900, task: multi, mean loss: 0.60391, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76064, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.14265, Variance: 0.15271
Semantic Loss - Mean: 1.75789, Variance: 0.00046

Test Epoch: 25 
task: majority, mean loss: 2.30927, accuracy: 0.08900, task: max, mean loss: 1.85479, accuracy: 0.27400, task: top, mean loss: 2.30696, accuracy: 0.10100, task: multi, mean loss: 0.60133, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76809
Diversity Loss - Mean: -0.14277, Variance: 0.15498
Semantic Loss - Mean: 1.76715, Variance: 0.00023

Train Epoch: 26 
task: majority, mean loss: 2.31001, accuracy: 0.09500, task: max, mean loss: 1.82006, accuracy: 0.24900, task: top, mean loss: 2.30882, accuracy: 0.10300, task: multi, mean loss: 0.60366, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76064, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.14261, Variance: 0.15302
Semantic Loss - Mean: 1.75803, Variance: 0.00044

Test Epoch: 26 
task: majority, mean loss: 2.30820, accuracy: 0.08900, task: max, mean loss: 1.85629, accuracy: 0.27400, task: top, mean loss: 2.31787, accuracy: 0.10100, task: multi, mean loss: 0.60133, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77092
Diversity Loss - Mean: -0.14279, Variance: 0.15520
Semantic Loss - Mean: 1.76856, Variance: 0.00023

Train Epoch: 27 
task: majority, mean loss: 2.30639, accuracy: 0.11200, task: max, mean loss: 1.82335, accuracy: 0.25300, task: top, mean loss: 2.31092, accuracy: 0.12500, task: multi, mean loss: 0.60385, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76113, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.14260, Variance: 0.15328
Semantic Loss - Mean: 1.75843, Variance: 0.00043

Test Epoch: 27 
task: majority, mean loss: 2.30415, accuracy: 0.10600, task: max, mean loss: 1.86013, accuracy: 0.27400, task: top, mean loss: 2.30407, accuracy: 0.10100, task: multi, mean loss: 0.60089, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76731
Diversity Loss - Mean: -0.14268, Variance: 0.15533
Semantic Loss - Mean: 1.76788, Variance: 0.00022

Train Epoch: 28 
task: majority, mean loss: 2.31241, accuracy: 0.08900, task: max, mean loss: 1.82491, accuracy: 0.25800, task: top, mean loss: 2.30582, accuracy: 0.11700, task: multi, mean loss: 0.60321, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76159, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.14261, Variance: 0.15344
Semantic Loss - Mean: 1.75834, Variance: 0.00041

Test Epoch: 28 
task: majority, mean loss: 2.30693, accuracy: 0.10000, task: max, mean loss: 1.86175, accuracy: 0.27400, task: top, mean loss: 2.30754, accuracy: 0.10100, task: multi, mean loss: 0.60103, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76931
Diversity Loss - Mean: -0.14273, Variance: 0.15553
Semantic Loss - Mean: 1.76798, Variance: 0.00021

Train Epoch: 29 
task: majority, mean loss: 2.31025, accuracy: 0.11600, task: max, mean loss: 1.81995, accuracy: 0.26200, task: top, mean loss: 2.30769, accuracy: 0.12100, task: multi, mean loss: 0.60423, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76053, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.14260, Variance: 0.15359
Semantic Loss - Mean: 1.75825, Variance: 0.00040

Test Epoch: 29 
task: majority, mean loss: 2.31199, accuracy: 0.08900, task: max, mean loss: 1.86003, accuracy: 0.27400, task: top, mean loss: 2.29804, accuracy: 0.10100, task: multi, mean loss: 0.60076, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76770
Diversity Loss - Mean: -0.14269, Variance: 0.15556
Semantic Loss - Mean: 1.76950, Variance: 0.00020

Train Epoch: 30 
task: majority, mean loss: 2.31010, accuracy: 0.10400, task: max, mean loss: 1.82072, accuracy: 0.26600, task: top, mean loss: 2.30814, accuracy: 0.12400, task: multi, mean loss: 0.60355, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76063, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.14263, Variance: 0.15363
Semantic Loss - Mean: 1.75857, Variance: 0.00039

Test Epoch: 30 
task: majority, mean loss: 2.30593, accuracy: 0.10900, task: max, mean loss: 1.86336, accuracy: 0.21300, task: top, mean loss: 2.30290, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76821
Diversity Loss - Mean: -0.14277, Variance: 0.15556
Semantic Loss - Mean: 1.76766, Variance: 0.00020

Train Epoch: 31 
task: majority, mean loss: 2.30770, accuracy: 0.10600, task: max, mean loss: 1.81985, accuracy: 0.24500, task: top, mean loss: 2.30585, accuracy: 0.11300, task: multi, mean loss: 0.60285, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75906, lr: 0.0008717008403259585
Diversity Loss - Mean: -0.14264, Variance: 0.15364
Semantic Loss - Mean: 1.75743, Variance: 0.00038

Test Epoch: 31 
task: majority, mean loss: 2.31141, accuracy: 0.08900, task: max, mean loss: 1.85990, accuracy: 0.27400, task: top, mean loss: 2.30534, accuracy: 0.10100, task: multi, mean loss: 0.60056, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76930
Diversity Loss - Mean: -0.14279, Variance: 0.15550
Semantic Loss - Mean: 1.76804, Variance: 0.00019

Train Epoch: 32 
task: majority, mean loss: 2.30783, accuracy: 0.10200, task: max, mean loss: 1.81696, accuracy: 0.27200, task: top, mean loss: 2.30734, accuracy: 0.11500, task: multi, mean loss: 0.60337, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75888, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.14266, Variance: 0.15361
Semantic Loss - Mean: 1.75819, Variance: 0.00036

Test Epoch: 32 
task: majority, mean loss: 2.30898, accuracy: 0.08900, task: max, mean loss: 1.85922, accuracy: 0.27400, task: top, mean loss: 2.30261, accuracy: 0.10100, task: multi, mean loss: 0.60136, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76804
Diversity Loss - Mean: -0.14281, Variance: 0.15551
Semantic Loss - Mean: 1.76789, Variance: 0.00018

Train Epoch: 33 
task: majority, mean loss: 2.30448, accuracy: 0.09700, task: max, mean loss: 1.82208, accuracy: 0.25600, task: top, mean loss: 2.30416, accuracy: 0.12500, task: multi, mean loss: 0.60347, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75855, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.14265, Variance: 0.15362
Semantic Loss - Mean: 1.75679, Variance: 0.00035

Test Epoch: 33 
task: majority, mean loss: 2.31041, accuracy: 0.08900, task: max, mean loss: 1.85742, accuracy: 0.27400, task: top, mean loss: 2.30003, accuracy: 0.10100, task: multi, mean loss: 0.60115, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76725
Diversity Loss - Mean: -0.14272, Variance: 0.15549
Semantic Loss - Mean: 1.76696, Variance: 0.00018

Train Epoch: 34 
task: majority, mean loss: 2.30579, accuracy: 0.09400, task: max, mean loss: 1.82369, accuracy: 0.25200, task: top, mean loss: 2.30586, accuracy: 0.12000, task: multi, mean loss: 0.60290, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75956, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.14263, Variance: 0.15359
Semantic Loss - Mean: 1.75803, Variance: 0.00034

Test Epoch: 34 
task: majority, mean loss: 2.31245, accuracy: 0.08900, task: max, mean loss: 1.86172, accuracy: 0.27400, task: top, mean loss: 2.30307, accuracy: 0.10100, task: multi, mean loss: 0.60076, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76950
Diversity Loss - Mean: -0.14280, Variance: 0.15536
Semantic Loss - Mean: 1.76880, Variance: 0.00017

Train Epoch: 35 
task: majority, mean loss: 2.30506, accuracy: 0.08600, task: max, mean loss: 1.82143, accuracy: 0.26300, task: top, mean loss: 2.30474, accuracy: 0.11900, task: multi, mean loss: 0.60278, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75850, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.14265, Variance: 0.15352
Semantic Loss - Mean: 1.75774, Variance: 0.00034

Test Epoch: 35 
task: majority, mean loss: 2.31023, accuracy: 0.08900, task: max, mean loss: 1.86124, accuracy: 0.27400, task: top, mean loss: 2.30356, accuracy: 0.10100, task: multi, mean loss: 0.60070, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76893
Diversity Loss - Mean: -0.14281, Variance: 0.15520
Semantic Loss - Mean: 1.76855, Variance: 0.00017

Train Epoch: 36 
task: majority, mean loss: 2.30653, accuracy: 0.10500, task: max, mean loss: 1.82096, accuracy: 0.26400, task: top, mean loss: 2.30604, accuracy: 0.12500, task: multi, mean loss: 0.60288, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75910, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.14266, Variance: 0.15345
Semantic Loss - Mean: 1.75742, Variance: 0.00033

Test Epoch: 36 
task: majority, mean loss: 2.30843, accuracy: 0.08900, task: max, mean loss: 1.86084, accuracy: 0.27400, task: top, mean loss: 2.29855, accuracy: 0.10100, task: multi, mean loss: 0.60093, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76719
Diversity Loss - Mean: -0.14278, Variance: 0.15506
Semantic Loss - Mean: 1.76703, Variance: 0.00016

Train Epoch: 37 
task: majority, mean loss: 2.30612, accuracy: 0.09500, task: max, mean loss: 1.82243, accuracy: 0.25200, task: top, mean loss: 2.30702, accuracy: 0.12500, task: multi, mean loss: 0.60299, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75964, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.14266, Variance: 0.15339
Semantic Loss - Mean: 1.75779, Variance: 0.00032

Test Epoch: 37 
task: majority, mean loss: 2.30774, accuracy: 0.08900, task: max, mean loss: 1.86393, accuracy: 0.21300, task: top, mean loss: 2.30114, accuracy: 0.10100, task: multi, mean loss: 0.60112, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76848
Diversity Loss - Mean: -0.14273, Variance: 0.15496
Semantic Loss - Mean: 1.76761, Variance: 0.00016

Train Epoch: 38 
task: majority, mean loss: 2.30464, accuracy: 0.10800, task: max, mean loss: 1.82040, accuracy: 0.24100, task: top, mean loss: 2.30566, accuracy: 0.11600, task: multi, mean loss: 0.60359, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75857, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.14266, Variance: 0.15331
Semantic Loss - Mean: 1.75764, Variance: 0.00031

Test Epoch: 38 
task: majority, mean loss: 2.31317, accuracy: 0.08900, task: max, mean loss: 1.85894, accuracy: 0.27400, task: top, mean loss: 2.30497, accuracy: 0.10100, task: multi, mean loss: 0.60096, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76951
Diversity Loss - Mean: -0.14279, Variance: 0.15482
Semantic Loss - Mean: 1.76866, Variance: 0.00016

Train Epoch: 39 
task: majority, mean loss: 2.30420, accuracy: 0.09400, task: max, mean loss: 1.82028, accuracy: 0.25200, task: top, mean loss: 2.30257, accuracy: 0.12500, task: multi, mean loss: 0.60321, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75757, lr: 0.000765194672484486
Diversity Loss - Mean: -0.14267, Variance: 0.15322
Semantic Loss - Mean: 1.75694, Variance: 0.00030

Test Epoch: 39 
task: majority, mean loss: 2.30877, accuracy: 0.08900, task: max, mean loss: 1.86142, accuracy: 0.21300, task: top, mean loss: 2.30165, accuracy: 0.10100, task: multi, mean loss: 0.60093, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76819
Diversity Loss - Mean: -0.14280, Variance: 0.15471
Semantic Loss - Mean: 1.76813, Variance: 0.00015

Train Epoch: 40 
task: majority, mean loss: 2.30526, accuracy: 0.10200, task: max, mean loss: 1.81677, accuracy: 0.24100, task: top, mean loss: 2.30374, accuracy: 0.13000, task: multi, mean loss: 0.60293, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75717, lr: 0.00075025
Diversity Loss - Mean: -0.14258, Variance: 0.15312
Semantic Loss - Mean: 1.75659, Variance: 0.00030

Test Epoch: 40 
task: majority, mean loss: 2.31048, accuracy: 0.08900, task: max, mean loss: 1.85991, accuracy: 0.27400, task: top, mean loss: 2.29967, accuracy: 0.10100, task: multi, mean loss: 0.60053, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76765
Diversity Loss - Mean: -0.13669, Variance: 0.15507
Semantic Loss - Mean: 1.76819, Variance: 0.00015

Train Epoch: 41 
task: majority, mean loss: 2.30352, accuracy: 0.11800, task: max, mean loss: 1.81731, accuracy: 0.25600, task: top, mean loss: 2.30244, accuracy: 0.12200, task: multi, mean loss: 0.60262, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75647, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.14182, Variance: 0.15311
Semantic Loss - Mean: 1.75654, Variance: 0.00029

Test Epoch: 41 
task: majority, mean loss: 2.30963, accuracy: 0.08900, task: max, mean loss: 1.85786, accuracy: 0.27400, task: top, mean loss: 2.30243, accuracy: 0.10100, task: multi, mean loss: 0.60087, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76770
Diversity Loss - Mean: -0.13864, Variance: 0.15560
Semantic Loss - Mean: 1.76847, Variance: 0.00014

Train Epoch: 42 
task: majority, mean loss: 2.30436, accuracy: 0.10700, task: max, mean loss: 1.81595, accuracy: 0.24900, task: top, mean loss: 2.30281, accuracy: 0.12300, task: multi, mean loss: 0.60284, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75649, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.14218, Variance: 0.15315
Semantic Loss - Mean: 1.75656, Variance: 0.00028

Test Epoch: 42 
task: majority, mean loss: 2.31029, accuracy: 0.08900, task: max, mean loss: 1.85510, accuracy: 0.27400, task: top, mean loss: 2.30011, accuracy: 0.10100, task: multi, mean loss: 0.60099, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76662
Diversity Loss - Mean: -0.13745, Variance: 0.15611
Semantic Loss - Mean: 1.76794, Variance: 0.00014

Train Epoch: 43 
task: majority, mean loss: 2.30269, accuracy: 0.12400, task: max, mean loss: 1.82035, accuracy: 0.26900, task: top, mean loss: 2.30387, accuracy: 0.12600, task: multi, mean loss: 0.60278, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75742, lr: 0.0007036649532163622
Diversity Loss - Mean: -0.14267, Variance: 0.15315
Semantic Loss - Mean: 1.75845, Variance: 0.00028

Test Epoch: 43 
task: majority, mean loss: 2.30921, accuracy: 0.08900, task: max, mean loss: 1.86341, accuracy: 0.27400, task: top, mean loss: 2.30297, accuracy: 0.10100, task: multi, mean loss: 0.60107, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76916
Diversity Loss - Mean: -0.14249, Variance: 0.15610
Semantic Loss - Mean: 1.76898, Variance: 0.00014

Train Epoch: 44 
task: majority, mean loss: 2.30315, accuracy: 0.11000, task: max, mean loss: 1.82372, accuracy: 0.26500, task: top, mean loss: 2.30355, accuracy: 0.12100, task: multi, mean loss: 0.60286, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75832, lr: 0.000687615993411248
Diversity Loss - Mean: -0.14268, Variance: 0.15308
Semantic Loss - Mean: 1.75738, Variance: 0.00027

Test Epoch: 44 
task: majority, mean loss: 2.31215, accuracy: 0.08900, task: max, mean loss: 1.85964, accuracy: 0.27400, task: top, mean loss: 2.30199, accuracy: 0.10100, task: multi, mean loss: 0.60081, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76865
Diversity Loss - Mean: -0.14281, Variance: 0.15597
Semantic Loss - Mean: 1.76725, Variance: 0.00014

Train Epoch: 45 
task: majority, mean loss: 2.30419, accuracy: 0.10200, task: max, mean loss: 1.82020, accuracy: 0.25500, task: top, mean loss: 2.30412, accuracy: 0.12700, task: multi, mean loss: 0.60289, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75785, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.14268, Variance: 0.15304
Semantic Loss - Mean: 1.75710, Variance: 0.00026

Test Epoch: 45 
task: majority, mean loss: 2.30676, accuracy: 0.08900, task: max, mean loss: 1.85566, accuracy: 0.27400, task: top, mean loss: 2.30049, accuracy: 0.10100, task: multi, mean loss: 0.60058, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76587
Diversity Loss - Mean: -0.14279, Variance: 0.15588
Semantic Loss - Mean: 1.76616, Variance: 0.00013

Train Epoch: 46 
task: majority, mean loss: 2.30330, accuracy: 0.10000, task: max, mean loss: 1.81895, accuracy: 0.25200, task: top, mean loss: 2.30298, accuracy: 0.12600, task: multi, mean loss: 0.60245, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75692, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.14269, Variance: 0.15296
Semantic Loss - Mean: 1.75693, Variance: 0.00026

Test Epoch: 46 
task: majority, mean loss: 2.30825, accuracy: 0.08900, task: max, mean loss: 1.85911, accuracy: 0.27400, task: top, mean loss: 2.30329, accuracy: 0.10100, task: multi, mean loss: 0.60082, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76787
Diversity Loss - Mean: -0.14281, Variance: 0.15578
Semantic Loss - Mean: 1.76739, Variance: 0.00013

Train Epoch: 47 
task: majority, mean loss: 2.30330, accuracy: 0.11400, task: max, mean loss: 1.81733, accuracy: 0.25700, task: top, mean loss: 2.30288, accuracy: 0.11600, task: multi, mean loss: 0.60231, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75646, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.14269, Variance: 0.15291
Semantic Loss - Mean: 1.75557, Variance: 0.00025

Test Epoch: 47 
task: majority, mean loss: 2.30759, accuracy: 0.08900, task: max, mean loss: 1.85529, accuracy: 0.27400, task: top, mean loss: 2.30282, accuracy: 0.10100, task: multi, mean loss: 0.60082, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76663
Diversity Loss - Mean: -0.14277, Variance: 0.15572
Semantic Loss - Mean: 1.76687, Variance: 0.00013

Train Epoch: 48 
task: majority, mean loss: 2.30383, accuracy: 0.11900, task: max, mean loss: 1.81555, accuracy: 0.25700, task: top, mean loss: 2.30443, accuracy: 0.12600, task: multi, mean loss: 0.60283, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75666, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.14268, Variance: 0.15288
Semantic Loss - Mean: 1.75613, Variance: 0.00025

Test Epoch: 48 
task: majority, mean loss: 2.30929, accuracy: 0.08900, task: max, mean loss: 1.85869, accuracy: 0.27400, task: top, mean loss: 2.30157, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76756
Diversity Loss - Mean: -0.14281, Variance: 0.15567
Semantic Loss - Mean: 1.76714, Variance: 0.00012

Train Epoch: 49 
task: majority, mean loss: 2.30454, accuracy: 0.11500, task: max, mean loss: 1.81467, accuracy: 0.26100, task: top, mean loss: 2.30303, accuracy: 0.12800, task: multi, mean loss: 0.60255, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75620, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.14268, Variance: 0.15283
Semantic Loss - Mean: 1.75634, Variance: 0.00024

Test Epoch: 49 
task: majority, mean loss: 2.30834, accuracy: 0.08900, task: max, mean loss: 1.85633, accuracy: 0.27400, task: top, mean loss: 2.29971, accuracy: 0.10100, task: multi, mean loss: 0.60066, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76626
Diversity Loss - Mean: -0.14279, Variance: 0.15561
Semantic Loss - Mean: 1.76576, Variance: 0.00012

Train Epoch: 50 
task: majority, mean loss: 2.30383, accuracy: 0.11600, task: max, mean loss: 1.82070, accuracy: 0.27200, task: top, mean loss: 2.29994, accuracy: 0.12600, task: multi, mean loss: 0.60255, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75675, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.14269, Variance: 0.15277
Semantic Loss - Mean: 1.75688, Variance: 0.00024

Test Epoch: 50 
task: majority, mean loss: 2.30731, accuracy: 0.08900, task: max, mean loss: 1.85494, accuracy: 0.27400, task: top, mean loss: 2.30140, accuracy: 0.10100, task: multi, mean loss: 0.60107, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76618
Diversity Loss - Mean: -0.14281, Variance: 0.15553
Semantic Loss - Mean: 1.76627, Variance: 0.00012

Train Epoch: 51 
task: majority, mean loss: 2.30236, accuracy: 0.10600, task: max, mean loss: 1.81654, accuracy: 0.24500, task: top, mean loss: 2.30195, accuracy: 0.12200, task: multi, mean loss: 0.60268, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75588, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.14268, Variance: 0.15271
Semantic Loss - Mean: 1.75653, Variance: 0.00023

Test Epoch: 51 
task: majority, mean loss: 2.30904, accuracy: 0.08900, task: max, mean loss: 1.85619, accuracy: 0.27400, task: top, mean loss: 2.30002, accuracy: 0.10100, task: multi, mean loss: 0.60051, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76644
Diversity Loss - Mean: -0.14282, Variance: 0.15542
Semantic Loss - Mean: 1.76783, Variance: 0.00012

Train Epoch: 52 
task: majority, mean loss: 2.30255, accuracy: 0.10700, task: max, mean loss: 1.81495, accuracy: 0.26500, task: top, mean loss: 2.30121, accuracy: 0.12600, task: multi, mean loss: 0.60263, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75534, lr: 0.0005527119674021931
Diversity Loss - Mean: -0.14269, Variance: 0.15264
Semantic Loss - Mean: 1.75558, Variance: 0.00023

Test Epoch: 52 
task: majority, mean loss: 2.30821, accuracy: 0.08900, task: max, mean loss: 1.85785, accuracy: 0.27400, task: top, mean loss: 2.30138, accuracy: 0.10100, task: multi, mean loss: 0.60075, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76705
Diversity Loss - Mean: -0.14280, Variance: 0.15531
Semantic Loss - Mean: 1.76707, Variance: 0.00011

Train Epoch: 53 
task: majority, mean loss: 2.30288, accuracy: 0.10900, task: max, mean loss: 1.81413, accuracy: 0.26800, task: top, mean loss: 2.30404, accuracy: 0.12300, task: multi, mean loss: 0.60259, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75591, lr: 0.0005353433586351905
Diversity Loss - Mean: -0.14270, Variance: 0.15256
Semantic Loss - Mean: 1.75545, Variance: 0.00023

Test Epoch: 53 
task: majority, mean loss: 2.30935, accuracy: 0.08900, task: max, mean loss: 1.85715, accuracy: 0.27400, task: top, mean loss: 2.30332, accuracy: 0.10100, task: multi, mean loss: 0.60074, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76764
Diversity Loss - Mean: -0.14283, Variance: 0.15518
Semantic Loss - Mean: 1.76805, Variance: 0.00011

Train Epoch: 54 
task: majority, mean loss: 2.30273, accuracy: 0.10600, task: max, mean loss: 1.81930, accuracy: 0.25500, task: top, mean loss: 2.30089, accuracy: 0.12600, task: multi, mean loss: 0.60274, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75642, lr: 0.0005179322986028993
Diversity Loss - Mean: -0.14270, Variance: 0.15247
Semantic Loss - Mean: 1.75597, Variance: 0.00022

Test Epoch: 54 
task: majority, mean loss: 2.30844, accuracy: 0.08900, task: max, mean loss: 1.85898, accuracy: 0.27400, task: top, mean loss: 2.30209, accuracy: 0.10100, task: multi, mean loss: 0.60090, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76760
Diversity Loss - Mean: -0.14283, Variance: 0.15500
Semantic Loss - Mean: 1.76831, Variance: 0.00011

Train Epoch: 55 
task: majority, mean loss: 2.30236, accuracy: 0.11700, task: max, mean loss: 1.81790, accuracy: 0.26800, task: top, mean loss: 2.29937, accuracy: 0.12700, task: multi, mean loss: 0.60252, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75554, lr: 0.0005005
Diversity Loss - Mean: -0.14269, Variance: 0.15236
Semantic Loss - Mean: 1.75579, Variance: 0.00022

Test Epoch: 55 
task: majority, mean loss: 2.30939, accuracy: 0.08900, task: max, mean loss: 1.85763, accuracy: 0.27400, task: top, mean loss: 2.30129, accuracy: 0.10100, task: multi, mean loss: 0.60083, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14283, Variance: 0.15491
Semantic Loss - Mean: 1.76667, Variance: 0.00011

Train Epoch: 56 
task: majority, mean loss: 2.30101, accuracy: 0.11800, task: max, mean loss: 1.81353, accuracy: 0.26800, task: top, mean loss: 2.30033, accuracy: 0.12600, task: multi, mean loss: 0.60286, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75443, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.14267, Variance: 0.15226
Semantic Loss - Mean: 1.75498, Variance: 0.00021

Test Epoch: 56 
task: majority, mean loss: 2.30924, accuracy: 0.08900, task: max, mean loss: 1.86044, accuracy: 0.27400, task: top, mean loss: 2.30164, accuracy: 0.10100, task: multi, mean loss: 0.60083, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76804
Diversity Loss - Mean: -0.14282, Variance: 0.15473
Semantic Loss - Mean: 1.76835, Variance: 0.00011

Train Epoch: 57 
task: majority, mean loss: 2.30032, accuracy: 0.11200, task: max, mean loss: 1.81991, accuracy: 0.26300, task: top, mean loss: 2.30293, accuracy: 0.12600, task: multi, mean loss: 0.60254, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75642, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.14270, Variance: 0.15216
Semantic Loss - Mean: 1.75704, Variance: 0.00021

Test Epoch: 57 
task: majority, mean loss: 2.30958, accuracy: 0.08900, task: max, mean loss: 1.86476, accuracy: 0.27400, task: top, mean loss: 2.30161, accuracy: 0.10100, task: multi, mean loss: 0.60094, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76922
Diversity Loss - Mean: -0.14284, Variance: 0.15456
Semantic Loss - Mean: 1.76914, Variance: 0.00010

Train Epoch: 58 
task: majority, mean loss: 2.30212, accuracy: 0.11700, task: max, mean loss: 1.81708, accuracy: 0.26300, task: top, mean loss: 2.30185, accuracy: 0.12500, task: multi, mean loss: 0.60250, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75589, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.14270, Variance: 0.15206
Semantic Loss - Mean: 1.75628, Variance: 0.00021

Test Epoch: 58 
task: majority, mean loss: 2.30787, accuracy: 0.08900, task: max, mean loss: 1.85801, accuracy: 0.27400, task: top, mean loss: 2.30080, accuracy: 0.10100, task: multi, mean loss: 0.60084, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76688
Diversity Loss - Mean: -0.14283, Variance: 0.15450
Semantic Loss - Mean: 1.76675, Variance: 0.00010

Train Epoch: 59 
task: majority, mean loss: 2.30313, accuracy: 0.10800, task: max, mean loss: 1.81826, accuracy: 0.26200, task: top, mean loss: 2.30083, accuracy: 0.12500, task: multi, mean loss: 0.60232, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75613, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.14269, Variance: 0.15199
Semantic Loss - Mean: 1.75597, Variance: 0.00020

Test Epoch: 59 
task: majority, mean loss: 2.30824, accuracy: 0.08900, task: max, mean loss: 1.85853, accuracy: 0.27400, task: top, mean loss: 2.30022, accuracy: 0.10100, task: multi, mean loss: 0.60065, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76691
Diversity Loss - Mean: -0.14281, Variance: 0.15441
Semantic Loss - Mean: 1.76639, Variance: 0.00010

Train Epoch: 60 
task: majority, mean loss: 2.29943, accuracy: 0.11000, task: max, mean loss: 1.81812, accuracy: 0.26200, task: top, mean loss: 2.29840, accuracy: 0.12600, task: multi, mean loss: 0.60258, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75463, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.14268, Variance: 0.15193
Semantic Loss - Mean: 1.75550, Variance: 0.00020

Test Epoch: 60 
task: majority, mean loss: 2.30916, accuracy: 0.08900, task: max, mean loss: 1.85715, accuracy: 0.27400, task: top, mean loss: 2.30020, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76679
Diversity Loss - Mean: -0.14283, Variance: 0.15433
Semantic Loss - Mean: 1.76614, Variance: 0.00010

Train Epoch: 61 
task: majority, mean loss: 2.30029, accuracy: 0.11200, task: max, mean loss: 1.81438, accuracy: 0.26400, task: top, mean loss: 2.29999, accuracy: 0.12600, task: multi, mean loss: 0.60239, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75426, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.14270, Variance: 0.15188
Semantic Loss - Mean: 1.75473, Variance: 0.00020

Test Epoch: 61 
task: majority, mean loss: 2.30884, accuracy: 0.08900, task: max, mean loss: 1.85651, accuracy: 0.27400, task: top, mean loss: 2.30066, accuracy: 0.10100, task: multi, mean loss: 0.60072, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76668
Diversity Loss - Mean: -0.14282, Variance: 0.15430
Semantic Loss - Mean: 1.76671, Variance: 0.00010

Train Epoch: 62 
task: majority, mean loss: 2.30318, accuracy: 0.11100, task: max, mean loss: 1.81711, accuracy: 0.26500, task: top, mean loss: 2.30213, accuracy: 0.12500, task: multi, mean loss: 0.60230, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75618, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.14269, Variance: 0.15183
Semantic Loss - Mean: 1.75595, Variance: 0.00019

Test Epoch: 62 
task: majority, mean loss: 2.30904, accuracy: 0.08900, task: max, mean loss: 1.85784, accuracy: 0.27400, task: top, mean loss: 2.30097, accuracy: 0.10100, task: multi, mean loss: 0.60060, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76711
Diversity Loss - Mean: -0.14280, Variance: 0.15422
Semantic Loss - Mean: 1.76709, Variance: 0.00010

Train Epoch: 63 
task: majority, mean loss: 2.30127, accuracy: 0.11100, task: max, mean loss: 1.81616, accuracy: 0.27200, task: top, mean loss: 2.30023, accuracy: 0.12400, task: multi, mean loss: 0.60224, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75497, lr: 0.00036281914076940884
Diversity Loss - Mean: -0.14270, Variance: 0.15176
Semantic Loss - Mean: 1.75498, Variance: 0.00019

Test Epoch: 63 
task: majority, mean loss: 2.30884, accuracy: 0.08900, task: max, mean loss: 1.85841, accuracy: 0.27400, task: top, mean loss: 2.30223, accuracy: 0.10100, task: multi, mean loss: 0.60070, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76755
Diversity Loss - Mean: -0.14283, Variance: 0.15413
Semantic Loss - Mean: 1.76711, Variance: 0.00009

Train Epoch: 64 
task: majority, mean loss: 2.30134, accuracy: 0.11300, task: max, mean loss: 1.81342, accuracy: 0.26400, task: top, mean loss: 2.30080, accuracy: 0.12600, task: multi, mean loss: 0.60248, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75451, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.14270, Variance: 0.15171
Semantic Loss - Mean: 1.75426, Variance: 0.00019

Test Epoch: 64 
task: majority, mean loss: 2.30848, accuracy: 0.08900, task: max, mean loss: 1.85780, accuracy: 0.27400, task: top, mean loss: 2.30140, accuracy: 0.10100, task: multi, mean loss: 0.60077, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76711
Diversity Loss - Mean: -0.14284, Variance: 0.15406
Semantic Loss - Mean: 1.76696, Variance: 0.00009

Train Epoch: 65 
task: majority, mean loss: 2.30221, accuracy: 0.11200, task: max, mean loss: 1.81352, accuracy: 0.26200, task: top, mean loss: 2.30001, accuracy: 0.12300, task: multi, mean loss: 0.60225, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75450, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.14270, Variance: 0.15166
Semantic Loss - Mean: 1.75475, Variance: 0.00019

Test Epoch: 65 
task: majority, mean loss: 2.30959, accuracy: 0.08900, task: max, mean loss: 1.85844, accuracy: 0.27400, task: top, mean loss: 2.30165, accuracy: 0.10100, task: multi, mean loss: 0.60064, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76758
Diversity Loss - Mean: -0.14284, Variance: 0.15393
Semantic Loss - Mean: 1.76812, Variance: 0.00009

Train Epoch: 66 
task: majority, mean loss: 2.30115, accuracy: 0.12000, task: max, mean loss: 1.81192, accuracy: 0.26500, task: top, mean loss: 2.29896, accuracy: 0.12600, task: multi, mean loss: 0.60248, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75363, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.14269, Variance: 0.15156
Semantic Loss - Mean: 1.75488, Variance: 0.00018

Test Epoch: 66 
task: majority, mean loss: 2.30992, accuracy: 0.08900, task: max, mean loss: 1.85795, accuracy: 0.27400, task: top, mean loss: 2.30189, accuracy: 0.10100, task: multi, mean loss: 0.60072, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76762
Diversity Loss - Mean: -0.14282, Variance: 0.15384
Semantic Loss - Mean: 1.76730, Variance: 0.00009

Train Epoch: 67 
task: majority, mean loss: 2.30111, accuracy: 0.10500, task: max, mean loss: 1.81368, accuracy: 0.26500, task: top, mean loss: 2.30115, accuracy: 0.12600, task: multi, mean loss: 0.60236, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75458, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.14269, Variance: 0.15148
Semantic Loss - Mean: 1.75438, Variance: 0.00018

Test Epoch: 67 
task: majority, mean loss: 2.30835, accuracy: 0.08900, task: max, mean loss: 1.85716, accuracy: 0.27400, task: top, mean loss: 2.30064, accuracy: 0.10100, task: multi, mean loss: 0.60069, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76671
Diversity Loss - Mean: -0.14282, Variance: 0.15377
Semantic Loss - Mean: 1.76635, Variance: 0.00009

Train Epoch: 68 
task: majority, mean loss: 2.30015, accuracy: 0.11800, task: max, mean loss: 1.81669, accuracy: 0.27200, task: top, mean loss: 2.30088, accuracy: 0.12600, task: multi, mean loss: 0.60221, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75498, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.14270, Variance: 0.15142
Semantic Loss - Mean: 1.75483, Variance: 0.00018

Test Epoch: 68 
task: majority, mean loss: 2.30955, accuracy: 0.08900, task: max, mean loss: 1.85950, accuracy: 0.27400, task: top, mean loss: 2.30177, accuracy: 0.10100, task: multi, mean loss: 0.60076, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76789
Diversity Loss - Mean: -0.14281, Variance: 0.15367
Semantic Loss - Mean: 1.76778, Variance: 0.00009

Train Epoch: 69 
task: majority, mean loss: 2.30049, accuracy: 0.12400, task: max, mean loss: 1.81261, accuracy: 0.25700, task: top, mean loss: 2.30090, accuracy: 0.12500, task: multi, mean loss: 0.60252, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75413, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.14269, Variance: 0.15135
Semantic Loss - Mean: 1.75462, Variance: 0.00018

Test Epoch: 69 
task: majority, mean loss: 2.30804, accuracy: 0.08900, task: max, mean loss: 1.85826, accuracy: 0.27400, task: top, mean loss: 2.30085, accuracy: 0.10100, task: multi, mean loss: 0.60075, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76698
Diversity Loss - Mean: -0.14280, Variance: 0.15358
Semantic Loss - Mean: 1.76686, Variance: 0.00009

Train Epoch: 70 
task: majority, mean loss: 2.30018, accuracy: 0.11700, task: max, mean loss: 1.81599, accuracy: 0.26400, task: top, mean loss: 2.29870, accuracy: 0.12600, task: multi, mean loss: 0.60246, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75433, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.14271, Variance: 0.15129
Semantic Loss - Mean: 1.75448, Variance: 0.00017

Test Epoch: 70 
task: majority, mean loss: 2.30916, accuracy: 0.08900, task: max, mean loss: 1.85737, accuracy: 0.27400, task: top, mean loss: 2.30069, accuracy: 0.10100, task: multi, mean loss: 0.60064, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76697
Diversity Loss - Mean: -0.14283, Variance: 0.15349
Semantic Loss - Mean: 1.76696, Variance: 0.00009

Train Epoch: 71 
task: majority, mean loss: 2.30111, accuracy: 0.11500, task: max, mean loss: 1.81170, accuracy: 0.26500, task: top, mean loss: 2.29872, accuracy: 0.12500, task: multi, mean loss: 0.60222, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75344, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.14271, Variance: 0.15122
Semantic Loss - Mean: 1.75406, Variance: 0.00017

Test Epoch: 71 
task: majority, mean loss: 2.30860, accuracy: 0.08900, task: max, mean loss: 1.85882, accuracy: 0.27400, task: top, mean loss: 2.30035, accuracy: 0.10100, task: multi, mean loss: 0.60070, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76712
Diversity Loss - Mean: -0.14284, Variance: 0.15340
Semantic Loss - Mean: 1.76705, Variance: 0.00008

Train Epoch: 72 
task: majority, mean loss: 2.30202, accuracy: 0.11800, task: max, mean loss: 1.81372, accuracy: 0.27200, task: top, mean loss: 2.30002, accuracy: 0.12600, task: multi, mean loss: 0.60203, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75445, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.14271, Variance: 0.15114
Semantic Loss - Mean: 1.75433, Variance: 0.00017

Test Epoch: 72 
task: majority, mean loss: 2.30964, accuracy: 0.08900, task: max, mean loss: 1.85889, accuracy: 0.27400, task: top, mean loss: 2.30095, accuracy: 0.10100, task: multi, mean loss: 0.60076, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76756
Diversity Loss - Mean: -0.14284, Variance: 0.15330
Semantic Loss - Mean: 1.76738, Variance: 0.00008

Train Epoch: 73 
task: majority, mean loss: 2.29998, accuracy: 0.11700, task: max, mean loss: 1.81234, accuracy: 0.26500, task: top, mean loss: 2.29941, accuracy: 0.12600, task: multi, mean loss: 0.60229, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75350, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.14270, Variance: 0.15107
Semantic Loss - Mean: 1.75384, Variance: 0.00017

Test Epoch: 73 
task: majority, mean loss: 2.30803, accuracy: 0.08900, task: max, mean loss: 1.85816, accuracy: 0.27400, task: top, mean loss: 2.30055, accuracy: 0.10100, task: multi, mean loss: 0.60072, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76687
Diversity Loss - Mean: -0.14284, Variance: 0.15320
Semantic Loss - Mean: 1.76682, Variance: 0.00008

Train Epoch: 74 
task: majority, mean loss: 2.30007, accuracy: 0.12000, task: max, mean loss: 1.81674, accuracy: 0.26500, task: top, mean loss: 2.30055, accuracy: 0.12600, task: multi, mean loss: 0.60227, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75491, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.14271, Variance: 0.15100
Semantic Loss - Mean: 1.75465, Variance: 0.00016

Test Epoch: 74 
task: majority, mean loss: 2.30873, accuracy: 0.08900, task: max, mean loss: 1.85924, accuracy: 0.27400, task: top, mean loss: 2.30053, accuracy: 0.10100, task: multi, mean loss: 0.60069, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76730
Diversity Loss - Mean: -0.14283, Variance: 0.15309
Semantic Loss - Mean: 1.76749, Variance: 0.00008

Train Epoch: 75 
task: majority, mean loss: 2.30091, accuracy: 0.11900, task: max, mean loss: 1.81421, accuracy: 0.26400, task: top, mean loss: 2.30070, accuracy: 0.12600, task: multi, mean loss: 0.60223, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75451, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.14271, Variance: 0.15093
Semantic Loss - Mean: 1.75359, Variance: 0.00016

Test Epoch: 75 
task: majority, mean loss: 2.30872, accuracy: 0.08900, task: max, mean loss: 1.85848, accuracy: 0.27400, task: top, mean loss: 2.30052, accuracy: 0.10100, task: multi, mean loss: 0.60069, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76710
Diversity Loss - Mean: -0.14284, Variance: 0.15300
Semantic Loss - Mean: 1.76707, Variance: 0.00008

Train Epoch: 76 
task: majority, mean loss: 2.29904, accuracy: 0.12200, task: max, mean loss: 1.81187, accuracy: 0.26600, task: top, mean loss: 2.29874, accuracy: 0.12500, task: multi, mean loss: 0.60250, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75304, lr: 0.0001662692621237503
Diversity Loss - Mean: -0.14271, Variance: 0.15085
Semantic Loss - Mean: 1.75329, Variance: 0.00016

Test Epoch: 76 
task: majority, mean loss: 2.30855, accuracy: 0.08900, task: max, mean loss: 1.85814, accuracy: 0.27400, task: top, mean loss: 2.30110, accuracy: 0.10100, task: multi, mean loss: 0.60064, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76711
Diversity Loss - Mean: -0.14283, Variance: 0.15292
Semantic Loss - Mean: 1.76675, Variance: 0.00008

Train Epoch: 77 
task: majority, mean loss: 2.29887, accuracy: 0.11600, task: max, mean loss: 1.81879, accuracy: 0.26600, task: top, mean loss: 2.30029, accuracy: 0.12600, task: multi, mean loss: 0.60225, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75505, lr: 0.000153518143955731
Diversity Loss - Mean: -0.14270, Variance: 0.15080
Semantic Loss - Mean: 1.75491, Variance: 0.00016

Test Epoch: 77 
task: majority, mean loss: 2.30961, accuracy: 0.08900, task: max, mean loss: 1.85939, accuracy: 0.27400, task: top, mean loss: 2.30133, accuracy: 0.10100, task: multi, mean loss: 0.60078, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76778
Diversity Loss - Mean: -0.14282, Variance: 0.15281
Semantic Loss - Mean: 1.76834, Variance: 0.00008

Train Epoch: 78 
task: majority, mean loss: 2.29977, accuracy: 0.11700, task: max, mean loss: 1.81499, accuracy: 0.26300, task: top, mean loss: 2.29885, accuracy: 0.12600, task: multi, mean loss: 0.60209, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75392, lr: 0.00014118976973084374
Diversity Loss - Mean: -0.14271, Variance: 0.15073
Semantic Loss - Mean: 1.75348, Variance: 0.00016

Test Epoch: 78 
task: majority, mean loss: 2.30865, accuracy: 0.08900, task: max, mean loss: 1.85876, accuracy: 0.27400, task: top, mean loss: 2.30093, accuracy: 0.10100, task: multi, mean loss: 0.60069, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76726
Diversity Loss - Mean: -0.14283, Variance: 0.15271
Semantic Loss - Mean: 1.76765, Variance: 0.00008

Train Epoch: 79 
task: majority, mean loss: 2.30129, accuracy: 0.11500, task: max, mean loss: 1.81083, accuracy: 0.26700, task: top, mean loss: 2.29909, accuracy: 0.12600, task: multi, mean loss: 0.60227, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75337, lr: 0.0001292991596740417
Diversity Loss - Mean: -0.14271, Variance: 0.15067
Semantic Loss - Mean: 1.75352, Variance: 0.00015

Test Epoch: 79 
task: majority, mean loss: 2.30874, accuracy: 0.08900, task: max, mean loss: 1.85839, accuracy: 0.27400, task: top, mean loss: 2.30117, accuracy: 0.10100, task: multi, mean loss: 0.60073, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76726
Diversity Loss - Mean: -0.14284, Variance: 0.15261
Semantic Loss - Mean: 1.76757, Variance: 0.00008

Train Epoch: 80 
task: majority, mean loss: 2.29908, accuracy: 0.11700, task: max, mean loss: 1.81519, accuracy: 0.26500, task: top, mean loss: 2.29822, accuracy: 0.12600, task: multi, mean loss: 0.60201, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75363, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.14271, Variance: 0.15059
Semantic Loss - Mean: 1.75367, Variance: 0.00015

Test Epoch: 80 
task: majority, mean loss: 2.30891, accuracy: 0.08900, task: max, mean loss: 1.85767, accuracy: 0.27400, task: top, mean loss: 2.30094, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76705
Diversity Loss - Mean: -0.14280, Variance: 0.15252
Semantic Loss - Mean: 1.76704, Variance: 0.00007

Train Epoch: 81 
task: majority, mean loss: 2.29966, accuracy: 0.11600, task: max, mean loss: 1.81014, accuracy: 0.26500, task: top, mean loss: 2.29790, accuracy: 0.12600, task: multi, mean loss: 0.60203, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75243, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.14270, Variance: 0.15051
Semantic Loss - Mean: 1.75307, Variance: 0.00015

Test Epoch: 81 
task: majority, mean loss: 2.30966, accuracy: 0.08900, task: max, mean loss: 1.85788, accuracy: 0.27400, task: top, mean loss: 2.30159, accuracy: 0.10100, task: multi, mean loss: 0.60071, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76746
Diversity Loss - Mean: -0.14283, Variance: 0.15243
Semantic Loss - Mean: 1.76744, Variance: 0.00007

Train Epoch: 82 
task: majority, mean loss: 2.29805, accuracy: 0.11600, task: max, mean loss: 1.81451, accuracy: 0.26300, task: top, mean loss: 2.29853, accuracy: 0.12600, task: multi, mean loss: 0.60214, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75331, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.14271, Variance: 0.15044
Semantic Loss - Mean: 1.75340, Variance: 0.00015

Test Epoch: 82 
task: majority, mean loss: 2.30886, accuracy: 0.08900, task: max, mean loss: 1.85851, accuracy: 0.27400, task: top, mean loss: 2.30136, accuracy: 0.10100, task: multi, mean loss: 0.60070, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76736
Diversity Loss - Mean: -0.14284, Variance: 0.15235
Semantic Loss - Mean: 1.76728, Variance: 0.00007

Train Epoch: 83 
task: majority, mean loss: 2.29820, accuracy: 0.11700, task: max, mean loss: 1.81365, accuracy: 0.26400, task: top, mean loss: 2.29957, accuracy: 0.12600, task: multi, mean loss: 0.60183, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75331, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.14271, Variance: 0.15036
Semantic Loss - Mean: 1.75365, Variance: 0.00015

Test Epoch: 83 
task: majority, mean loss: 2.30923, accuracy: 0.08900, task: max, mean loss: 1.85838, accuracy: 0.27400, task: top, mean loss: 2.30087, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14283, Variance: 0.15227
Semantic Loss - Mean: 1.76710, Variance: 0.00007

Train Epoch: 84 
task: majority, mean loss: 2.30066, accuracy: 0.11600, task: max, mean loss: 1.81166, accuracy: 0.26600, task: top, mean loss: 2.29756, accuracy: 0.12600, task: multi, mean loss: 0.60173, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75290, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.14271, Variance: 0.15031
Semantic Loss - Mean: 1.75289, Variance: 0.00015

Test Epoch: 84 
task: majority, mean loss: 2.30906, accuracy: 0.08900, task: max, mean loss: 1.85790, accuracy: 0.27400, task: top, mean loss: 2.30096, accuracy: 0.10100, task: multi, mean loss: 0.60065, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76714
Diversity Loss - Mean: -0.14284, Variance: 0.15218
Semantic Loss - Mean: 1.76729, Variance: 0.00007

Train Epoch: 85 
task: majority, mean loss: 2.30024, accuracy: 0.11800, task: max, mean loss: 1.81297, accuracy: 0.26100, task: top, mean loss: 2.29764, accuracy: 0.12600, task: multi, mean loss: 0.60223, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75327, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.14272, Variance: 0.15023
Semantic Loss - Mean: 1.75325, Variance: 0.00014

Test Epoch: 85 
task: majority, mean loss: 2.30903, accuracy: 0.08900, task: max, mean loss: 1.85867, accuracy: 0.27400, task: top, mean loss: 2.30135, accuracy: 0.10100, task: multi, mean loss: 0.60070, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76744
Diversity Loss - Mean: -0.14284, Variance: 0.15209
Semantic Loss - Mean: 1.76762, Variance: 0.00007

Train Epoch: 86 
task: majority, mean loss: 2.29979, accuracy: 0.11700, task: max, mean loss: 1.81686, accuracy: 0.26300, task: top, mean loss: 2.29765, accuracy: 0.12600, task: multi, mean loss: 0.60197, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75407, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.14271, Variance: 0.15016
Semantic Loss - Mean: 1.75405, Variance: 0.00014

Test Epoch: 86 
task: majority, mean loss: 2.30883, accuracy: 0.08900, task: max, mean loss: 1.85823, accuracy: 0.27400, task: top, mean loss: 2.30126, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76725
Diversity Loss - Mean: -0.14284, Variance: 0.15200
Semantic Loss - Mean: 1.76721, Variance: 0.00007

Train Epoch: 87 
task: majority, mean loss: 2.29929, accuracy: 0.11800, task: max, mean loss: 1.81063, accuracy: 0.26700, task: top, mean loss: 2.29866, accuracy: 0.12600, task: multi, mean loss: 0.60215, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75268, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.14272, Variance: 0.15009
Semantic Loss - Mean: 1.75282, Variance: 0.00014

Test Epoch: 87 
task: majority, mean loss: 2.30888, accuracy: 0.08900, task: max, mean loss: 1.85832, accuracy: 0.27400, task: top, mean loss: 2.30101, accuracy: 0.10100, task: multi, mean loss: 0.60065, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76721
Diversity Loss - Mean: -0.14284, Variance: 0.15192
Semantic Loss - Mean: 1.76712, Variance: 0.00007

Train Epoch: 88 
task: majority, mean loss: 2.29715, accuracy: 0.11900, task: max, mean loss: 1.81702, accuracy: 0.26700, task: top, mean loss: 2.29766, accuracy: 0.12600, task: multi, mean loss: 0.60201, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75346, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.14272, Variance: 0.15003
Semantic Loss - Mean: 1.75371, Variance: 0.00014

Test Epoch: 88 
task: majority, mean loss: 2.30885, accuracy: 0.08900, task: max, mean loss: 1.85864, accuracy: 0.27400, task: top, mean loss: 2.30101, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76730
Diversity Loss - Mean: -0.14284, Variance: 0.15184
Semantic Loss - Mean: 1.76731, Variance: 0.00007

Train Epoch: 89 
task: majority, mean loss: 2.29834, accuracy: 0.11900, task: max, mean loss: 1.81568, accuracy: 0.26400, task: top, mean loss: 2.29593, accuracy: 0.12600, task: multi, mean loss: 0.60191, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75297, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14996
Semantic Loss - Mean: 1.75378, Variance: 0.00014

Test Epoch: 89 
task: majority, mean loss: 2.30887, accuracy: 0.08900, task: max, mean loss: 1.85849, accuracy: 0.27400, task: top, mean loss: 2.30110, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14284, Variance: 0.15176
Semantic Loss - Mean: 1.76715, Variance: 0.00007

Train Epoch: 90 
task: majority, mean loss: 2.29855, accuracy: 0.11800, task: max, mean loss: 1.81637, accuracy: 0.26300, task: top, mean loss: 2.29760, accuracy: 0.12600, task: multi, mean loss: 0.60221, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75368, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14990
Semantic Loss - Mean: 1.75358, Variance: 0.00014

Test Epoch: 90 
task: majority, mean loss: 2.30905, accuracy: 0.08900, task: max, mean loss: 1.85859, accuracy: 0.27400, task: top, mean loss: 2.30115, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76737
Diversity Loss - Mean: -0.14285, Variance: 0.15168
Semantic Loss - Mean: 1.76723, Variance: 0.00007

Train Epoch: 91 
task: majority, mean loss: 2.29853, accuracy: 0.11700, task: max, mean loss: 1.81171, accuracy: 0.26500, task: top, mean loss: 2.29861, accuracy: 0.12600, task: multi, mean loss: 0.60205, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75272, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14984
Semantic Loss - Mean: 1.75288, Variance: 0.00013

Test Epoch: 91 
task: majority, mean loss: 2.30903, accuracy: 0.08900, task: max, mean loss: 1.85839, accuracy: 0.27400, task: top, mean loss: 2.30120, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76733
Diversity Loss - Mean: -0.14285, Variance: 0.15160
Semantic Loss - Mean: 1.76722, Variance: 0.00007

Train Epoch: 92 
task: majority, mean loss: 2.29834, accuracy: 0.11800, task: max, mean loss: 1.81412, accuracy: 0.26400, task: top, mean loss: 2.29840, accuracy: 0.12600, task: multi, mean loss: 0.60205, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75323, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14978
Semantic Loss - Mean: 1.75313, Variance: 0.00013

Test Epoch: 92 
task: majority, mean loss: 2.30894, accuracy: 0.08900, task: max, mean loss: 1.85855, accuracy: 0.27400, task: top, mean loss: 2.30099, accuracy: 0.10100, task: multi, mean loss: 0.60069, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14284, Variance: 0.15153
Semantic Loss - Mean: 1.76727, Variance: 0.00006

Train Epoch: 93 
task: majority, mean loss: 2.29814, accuracy: 0.11700, task: max, mean loss: 1.81514, accuracy: 0.26900, task: top, mean loss: 2.29792, accuracy: 0.12700, task: multi, mean loss: 0.60186, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75326, lr: 1.583728472513976e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14972
Semantic Loss - Mean: 1.75351, Variance: 0.00013

Test Epoch: 93 
task: majority, mean loss: 2.30907, accuracy: 0.08900, task: max, mean loss: 1.85836, accuracy: 0.27400, task: top, mean loss: 2.30106, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14284, Variance: 0.15145
Semantic Loss - Mean: 1.76730, Variance: 0.00006

Train Epoch: 94 
task: majority, mean loss: 2.29836, accuracy: 0.12000, task: max, mean loss: 1.81162, accuracy: 0.26500, task: top, mean loss: 2.29808, accuracy: 0.12600, task: multi, mean loss: 0.60184, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75247, lr: 1.1915273433464114e-05
Diversity Loss - Mean: -0.14272, Variance: 0.14966
Semantic Loss - Mean: 1.75231, Variance: 0.00013

Test Epoch: 94 
task: majority, mean loss: 2.30898, accuracy: 0.08900, task: max, mean loss: 1.85848, accuracy: 0.27400, task: top, mean loss: 2.30114, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76732
Diversity Loss - Mean: -0.14285, Variance: 0.15137
Semantic Loss - Mean: 1.76735, Variance: 0.00006

Train Epoch: 95 
task: majority, mean loss: 2.29831, accuracy: 0.11500, task: max, mean loss: 1.81576, accuracy: 0.26600, task: top, mean loss: 2.29691, accuracy: 0.12600, task: multi, mean loss: 0.60197, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75324, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14960
Semantic Loss - Mean: 1.75354, Variance: 0.00013

Test Epoch: 95 
task: majority, mean loss: 2.30905, accuracy: 0.08900, task: max, mean loss: 1.85842, accuracy: 0.27400, task: top, mean loss: 2.30105, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76730
Diversity Loss - Mean: -0.14285, Variance: 0.15130
Semantic Loss - Mean: 1.76735, Variance: 0.00006

Train Epoch: 96 
task: majority, mean loss: 2.29842, accuracy: 0.11800, task: max, mean loss: 1.81140, accuracy: 0.26300, task: top, mean loss: 2.29847, accuracy: 0.12600, task: multi, mean loss: 0.60206, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75258, lr: 5.861099663585604e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14955
Semantic Loss - Mean: 1.75234, Variance: 0.00013

Test Epoch: 96 
task: majority, mean loss: 2.30902, accuracy: 0.08900, task: max, mean loss: 1.85836, accuracy: 0.27400, task: top, mean loss: 2.30104, accuracy: 0.10100, task: multi, mean loss: 0.60067, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76727
Diversity Loss - Mean: -0.14285, Variance: 0.15123
Semantic Loss - Mean: 1.76732, Variance: 0.00006

Train Epoch: 97 
task: majority, mean loss: 2.29879, accuracy: 0.11600, task: max, mean loss: 1.81103, accuracy: 0.26300, task: top, mean loss: 2.29815, accuracy: 0.12600, task: multi, mean loss: 0.60208, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75251, lr: 3.736313263547436e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14949
Semantic Loss - Mean: 1.75264, Variance: 0.00013

Test Epoch: 97 
task: majority, mean loss: 2.30901, accuracy: 0.08900, task: max, mean loss: 1.85843, accuracy: 0.27400, task: top, mean loss: 2.30105, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14285, Variance: 0.15116
Semantic Loss - Mean: 1.76734, Variance: 0.00006

Train Epoch: 98 
task: majority, mean loss: 2.30023, accuracy: 0.11500, task: max, mean loss: 1.82002, accuracy: 0.26100, task: top, mean loss: 2.29770, accuracy: 0.12600, task: multi, mean loss: 0.60196, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75498, lr: 2.2167568952178134e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14944
Semantic Loss - Mean: 1.75459, Variance: 0.00013

Test Epoch: 98 
task: majority, mean loss: 2.30902, accuracy: 0.08900, task: max, mean loss: 1.85846, accuracy: 0.27400, task: top, mean loss: 2.30105, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76730
Diversity Loss - Mean: -0.14285, Variance: 0.15109
Semantic Loss - Mean: 1.76735, Variance: 0.00006

Train Epoch: 99 
task: majority, mean loss: 2.30084, accuracy: 0.11600, task: max, mean loss: 1.81611, accuracy: 0.26500, task: top, mean loss: 2.29858, accuracy: 0.12700, task: multi, mean loss: 0.60202, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75439, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14938
Semantic Loss - Mean: 1.75367, Variance: 0.00012

Test Epoch: 99 
task: majority, mean loss: 2.30901, accuracy: 0.08900, task: max, mean loss: 1.85843, accuracy: 0.27400, task: top, mean loss: 2.30105, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76729
Diversity Loss - Mean: -0.14285, Variance: 0.15102
Semantic Loss - Mean: 1.76733, Variance: 0.00006

Train Epoch: 100 
task: majority, mean loss: 2.29799, accuracy: 0.11800, task: max, mean loss: 1.81093, accuracy: 0.26200, task: top, mean loss: 2.29912, accuracy: 0.12600, task: multi, mean loss: 0.60211, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75254, lr: 1e-06
Diversity Loss - Mean: -0.14272, Variance: 0.14933
Semantic Loss - Mean: 1.75269, Variance: 0.00012

Test Epoch: 100 
task: majority, mean loss: 2.30901, accuracy: 0.08900, task: max, mean loss: 1.85845, accuracy: 0.27400, task: top, mean loss: 2.30105, accuracy: 0.10100, task: multi, mean loss: 0.60068, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.76730
Diversity Loss - Mean: -0.14285, Variance: 0.15095
Semantic Loss - Mean: 1.76734, Variance: 0.00006

