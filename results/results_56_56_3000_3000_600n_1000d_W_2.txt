Used config:
{'B': 16,
 'B_seq': 16,
 'D': 128,
 'D_inner': 512,
 'D_k': 16,
 'D_v': 16,
 'H': 8,
 'I': 100,
 'M': 100,
 'N': 3600,
 'attn_dropout': 0.1,
 'data_dir': 'data/megapixel_mnist/dsets/megapixel_mnist_1500',
 'dropout': 0.1,
 'eager': True,
 'enc_type': 'resnet18',
 'eps': 1e-06,
 'is_image': True,
 'lr': 0.001,
 'mask_K': 10,
 'mask_p': 0,
 'n_chan_in': 1,
 'n_class': 10,
 'n_epoch': 100,
 'n_epoch_warmup': 10,
 'n_res_blocks': 2,
 'n_token': 4,
 'n_worker': 2,
 'patch_size': [50, 50],
 'patch_stride': [50, 50],
 'pin_memory': True,
 'pretrained': False,
 'seed': 0,
 'semantic_diversity_loss': True,
 'shuffle': True,
 'shuffle_style': 'batch',
 'tasks': {'task0': {'act_fn': 'softmax',
                     'id': 0,
                     'metric': 'accuracy',
                     'name': 'majority'},
           'task1': {'act_fn': 'softmax',
                     'id': 1,
                     'metric': 'accuracy',
                     'name': 'max'},
           'task2': {'act_fn': 'softmax',
                     'id': 2,
                     'metric': 'accuracy',
                     'name': 'top'},
           'task3': {'act_fn': 'sigmoid',
                     'id': 3,
                     'metric': 'multilabel_accuracy',
                     'name': 'multi'}},
 'track_efficiency': False,
 'track_epoch': 0,
 'use_pos': True,
 'wd': 0.1}
Train Epoch: 1 
task: majority, mean loss: 2.35256, accuracy: 0.12800, task: max, mean loss: 2.20372, accuracy: 0.24000, task: top, mean loss: 2.35013, accuracy: 0.09700, task: multi, mean loss: 0.69692, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.90083, lr: 0.0001
Diversity Loss - Mean: -0.10953, Variance: 0.07601
Semantic Loss - Mean: 1.99327, Variance: 0.00820

Test Epoch: 1 
task: majority, mean loss: 2.30845, accuracy: 0.09900, task: max, mean loss: 1.91881, accuracy: 0.25700, task: top, mean loss: 2.31115, accuracy: 0.10500, task: multi, mean loss: 0.63030, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79218
Diversity Loss - Mean: -0.14065, Variance: 0.09525
Semantic Loss - Mean: 1.90846, Variance: 0.00456

Train Epoch: 2 
task: majority, mean loss: 2.32232, accuracy: 0.10400, task: max, mean loss: 1.86484, accuracy: 0.27100, task: top, mean loss: 2.33147, accuracy: 0.08400, task: multi, mean loss: 0.61434, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78324, lr: 0.0002
Diversity Loss - Mean: -0.14162, Variance: 0.09425
Semantic Loss - Mean: 1.83786, Variance: 0.00486

Test Epoch: 2 
task: majority, mean loss: 2.31979, accuracy: 0.10000, task: max, mean loss: 1.89786, accuracy: 0.21300, task: top, mean loss: 2.32066, accuracy: 0.10100, task: multi, mean loss: 0.60238, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78517
Diversity Loss - Mean: -0.14050, Variance: 0.11694
Semantic Loss - Mean: 1.79722, Variance: 0.00243

Train Epoch: 3 
task: majority, mean loss: 2.33357, accuracy: 0.09800, task: max, mean loss: 1.85483, accuracy: 0.24800, task: top, mean loss: 2.32340, accuracy: 0.09500, task: multi, mean loss: 0.60711, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77973, lr: 0.00030000000000000003
Diversity Loss - Mean: -0.14159, Variance: 0.11284
Semantic Loss - Mean: 1.77705, Variance: 0.00331

Test Epoch: 3 
task: majority, mean loss: 2.33131, accuracy: 0.09500, task: max, mean loss: 1.87020, accuracy: 0.26200, task: top, mean loss: 2.32708, accuracy: 0.10900, task: multi, mean loss: 0.60233, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78273
Diversity Loss - Mean: -0.14177, Variance: 0.13103
Semantic Loss - Mean: 1.77707, Variance: 0.00164

Train Epoch: 4 
task: majority, mean loss: 2.33664, accuracy: 0.09400, task: max, mean loss: 1.84601, accuracy: 0.24500, task: top, mean loss: 2.34052, accuracy: 0.09000, task: multi, mean loss: 0.60663, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78245, lr: 0.0004
Diversity Loss - Mean: -0.14160, Variance: 0.12426
Semantic Loss - Mean: 1.77151, Variance: 0.00253

Test Epoch: 4 
task: majority, mean loss: 2.32326, accuracy: 0.10000, task: max, mean loss: 1.86264, accuracy: 0.24000, task: top, mean loss: 2.34535, accuracy: 0.10200, task: multi, mean loss: 0.60312, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.78359
Diversity Loss - Mean: -0.14153, Variance: 0.13658
Semantic Loss - Mean: 1.77675, Variance: 0.00124

Train Epoch: 5 
task: majority, mean loss: 2.33060, accuracy: 0.09700, task: max, mean loss: 1.83529, accuracy: 0.25100, task: top, mean loss: 2.32295, accuracy: 0.10900, task: multi, mean loss: 0.60513, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77349, lr: 0.0005
Diversity Loss - Mean: -0.14159, Variance: 0.13050
Semantic Loss - Mean: 1.76822, Variance: 0.00205

Test Epoch: 5 
task: majority, mean loss: 2.31714, accuracy: 0.09500, task: max, mean loss: 1.86454, accuracy: 0.27400, task: top, mean loss: 2.30741, accuracy: 0.10400, task: multi, mean loss: 0.60221, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77283
Diversity Loss - Mean: -0.14166, Variance: 0.13993
Semantic Loss - Mean: 1.77047, Variance: 0.00099

Train Epoch: 6 
task: majority, mean loss: 2.32773, accuracy: 0.10900, task: max, mean loss: 1.84598, accuracy: 0.24500, task: top, mean loss: 2.33044, accuracy: 0.11100, task: multi, mean loss: 0.60722, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77784, lr: 0.0006000000000000001
Diversity Loss - Mean: -0.14164, Variance: 0.13366
Semantic Loss - Mean: 1.76957, Variance: 0.00174

Test Epoch: 6 
task: majority, mean loss: 2.32796, accuracy: 0.09000, task: max, mean loss: 1.86447, accuracy: 0.23200, task: top, mean loss: 2.31252, accuracy: 0.10600, task: multi, mean loss: 0.60181, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77669
Diversity Loss - Mean: -0.14079, Variance: 0.13949
Semantic Loss - Mean: 1.77009, Variance: 0.00083

Train Epoch: 7 
task: majority, mean loss: 2.30906, accuracy: 0.10900, task: max, mean loss: 1.85457, accuracy: 0.25700, task: top, mean loss: 2.31376, accuracy: 0.11300, task: multi, mean loss: 0.60775, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.77129, lr: 0.0007
Diversity Loss - Mean: -0.14033, Variance: 0.13461
Semantic Loss - Mean: 1.76766, Variance: 0.00151

Test Epoch: 7 
task: majority, mean loss: 2.33432, accuracy: 0.09300, task: max, mean loss: 1.94539, accuracy: 0.16600, task: top, mean loss: 2.33537, accuracy: 0.11400, task: multi, mean loss: 0.60543, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.80513
Diversity Loss - Mean: -0.13822, Variance: 0.14004
Semantic Loss - Mean: 1.78001, Variance: 0.00073

Train Epoch: 8 
task: majority, mean loss: 2.28228, accuracy: 0.14600, task: max, mean loss: 1.82265, accuracy: 0.25300, task: top, mean loss: 2.31391, accuracy: 0.10600, task: multi, mean loss: 0.60594, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75620, lr: 0.0008
Diversity Loss - Mean: -0.13887, Variance: 0.13438
Semantic Loss - Mean: 1.76764, Variance: 0.00134

Test Epoch: 8 
task: majority, mean loss: 2.42322, accuracy: 0.08900, task: max, mean loss: 1.92962, accuracy: 0.21300, task: top, mean loss: 2.35793, accuracy: 0.09300, task: multi, mean loss: 0.60450, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.82882
Diversity Loss - Mean: -0.13468, Variance: 0.13906
Semantic Loss - Mean: 1.78846, Variance: 0.00066

Train Epoch: 9 
task: majority, mean loss: 2.26372, accuracy: 0.14000, task: max, mean loss: 1.83651, accuracy: 0.23700, task: top, mean loss: 2.30097, accuracy: 0.12100, task: multi, mean loss: 0.60065, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.75046, lr: 0.0009000000000000001
Diversity Loss - Mean: -0.13830, Variance: 0.13456
Semantic Loss - Mean: 1.76444, Variance: 0.00122

Test Epoch: 9 
task: majority, mean loss: 2.34117, accuracy: 0.11100, task: max, mean loss: 1.88868, accuracy: 0.27400, task: top, mean loss: 2.34161, accuracy: 0.10400, task: multi, mean loss: 0.60394, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.79385
Diversity Loss - Mean: -0.13632, Variance: 0.14015
Semantic Loss - Mean: 1.77708, Variance: 0.00060

Train Epoch: 10 
task: majority, mean loss: 2.22311, accuracy: 0.15800, task: max, mean loss: 1.82114, accuracy: 0.24700, task: top, mean loss: 2.27757, accuracy: 0.15100, task: multi, mean loss: 0.59639, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.72955, lr: 0.001
Diversity Loss - Mean: -0.13778, Variance: 0.13419
Semantic Loss - Mean: 1.75295, Variance: 0.00117

Test Epoch: 10 
task: majority, mean loss: 2.26045, accuracy: 0.13600, task: max, mean loss: 1.82474, accuracy: 0.29100, task: top, mean loss: 2.30314, accuracy: 0.10800, task: multi, mean loss: 0.59366, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.74550
Diversity Loss - Mean: -0.13880, Variance: 0.14003
Semantic Loss - Mean: 1.76571, Variance: 0.00060

Train Epoch: 11 
task: majority, mean loss: 2.20556, accuracy: 0.16900, task: max, mean loss: 1.81632, accuracy: 0.26100, task: top, mean loss: 2.26786, accuracy: 0.13700, task: multi, mean loss: 0.59106, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.72020, lr: 0.0009996957180960382
Diversity Loss - Mean: -0.13274, Variance: 0.13367
Semantic Loss - Mean: 1.73098, Variance: 0.00117

Test Epoch: 11 
task: majority, mean loss: 2.20390, accuracy: 0.15700, task: max, mean loss: 1.87379, accuracy: 0.21700, task: top, mean loss: 2.30388, accuracy: 0.11500, task: multi, mean loss: 0.59776, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.74483
Diversity Loss - Mean: -0.14036, Variance: 0.13988
Semantic Loss - Mean: 1.75283, Variance: 0.00065

Train Epoch: 12 
task: majority, mean loss: 2.16857, accuracy: 0.16800, task: max, mean loss: 1.79183, accuracy: 0.25600, task: top, mean loss: 2.20865, accuracy: 0.15900, task: multi, mean loss: 0.58591, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.68874, lr: 0.0009987832431047822
Diversity Loss - Mean: -0.13492, Variance: 0.13328
Semantic Loss - Mean: 1.70008, Variance: 0.00114

Test Epoch: 12 
task: majority, mean loss: 2.16728, accuracy: 0.18900, task: max, mean loss: 1.83420, accuracy: 0.21300, task: top, mean loss: 2.22375, accuracy: 0.13600, task: multi, mean loss: 0.58205, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.70182
Diversity Loss - Mean: -0.13950, Variance: 0.13931
Semantic Loss - Mean: 1.72336, Variance: 0.00067

Train Epoch: 13 
task: majority, mean loss: 2.15541, accuracy: 0.16300, task: max, mean loss: 1.77611, accuracy: 0.26100, task: top, mean loss: 2.20454, accuracy: 0.17500, task: multi, mean loss: 0.58521, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68032, lr: 0.0009972636867364526
Diversity Loss - Mean: -0.13518, Variance: 0.13273
Semantic Loss - Mean: 1.69713, Variance: 0.00115

Test Epoch: 13 
task: majority, mean loss: 3.22229, accuracy: 0.08900, task: max, mean loss: 2.13218, accuracy: 0.14100, task: top, mean loss: 2.90912, accuracy: 0.09300, task: multi, mean loss: 0.69874, multilabel_accuracy: 0.00100, avg. loss over tasks: 2.24058
Diversity Loss - Mean: -0.11971, Variance: 0.13833
Semantic Loss - Mean: 2.18596, Variance: 0.00080

Train Epoch: 14 
task: majority, mean loss: 2.10918, accuracy: 0.19000, task: max, mean loss: 1.78239, accuracy: 0.27000, task: top, mean loss: 2.19704, accuracy: 0.16700, task: multi, mean loss: 0.58431, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.66823, lr: 0.0009951389003364144
Diversity Loss - Mean: -0.13799, Variance: 0.13228
Semantic Loss - Mean: 1.68569, Variance: 0.00112

Test Epoch: 14 
task: majority, mean loss: 2.24504, accuracy: 0.16000, task: max, mean loss: 1.80910, accuracy: 0.31000, task: top, mean loss: 2.28071, accuracy: 0.14000, task: multi, mean loss: 0.58765, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.73062
Diversity Loss - Mean: -0.14099, Variance: 0.13760
Semantic Loss - Mean: 1.72710, Variance: 0.00076

Train Epoch: 15 
task: majority, mean loss: 2.08594, accuracy: 0.18800, task: max, mean loss: 1.77796, accuracy: 0.25800, task: top, mean loss: 2.17209, accuracy: 0.15800, task: multi, mean loss: 0.58080, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65420, lr: 0.000992411472629598
Diversity Loss - Mean: -0.13837, Variance: 0.13191
Semantic Loss - Mean: 1.67327, Variance: 0.00109

Test Epoch: 15 
task: majority, mean loss: 2.96264, accuracy: 0.09400, task: max, mean loss: 2.06218, accuracy: 0.27400, task: top, mean loss: 2.79960, accuracy: 0.09600, task: multi, mean loss: 0.68422, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.12716
Diversity Loss - Mean: -0.14134, Variance: 0.13665
Semantic Loss - Mean: 1.90982, Variance: 0.00081

Train Epoch: 16 
task: majority, mean loss: 2.09498, accuracy: 0.20000, task: max, mean loss: 1.76455, accuracy: 0.28600, task: top, mean loss: 2.19784, accuracy: 0.14400, task: multi, mean loss: 0.58113, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65962, lr: 0.000989084726566536
Diversity Loss - Mean: -0.13858, Variance: 0.13153
Semantic Loss - Mean: 1.67253, Variance: 0.00107

Test Epoch: 16 
task: majority, mean loss: 2.56524, accuracy: 0.11400, task: max, mean loss: 1.85748, accuracy: 0.28400, task: top, mean loss: 2.46775, accuracy: 0.10600, task: multi, mean loss: 0.62128, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.87794
Diversity Loss - Mean: -0.14168, Variance: 0.13631
Semantic Loss - Mean: 1.88706, Variance: 0.00079

Train Epoch: 17 
task: majority, mean loss: 2.06154, accuracy: 0.21500, task: max, mean loss: 1.75773, accuracy: 0.29200, task: top, mean loss: 2.15830, accuracy: 0.16500, task: multi, mean loss: 0.57803, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.63890, lr: 0.00098516271527486
Diversity Loss - Mean: -0.13911, Variance: 0.13120
Semantic Loss - Mean: 1.65844, Variance: 0.00104

Test Epoch: 17 
task: majority, mean loss: 2.21699, accuracy: 0.18100, task: max, mean loss: 1.77536, accuracy: 0.30500, task: top, mean loss: 2.22168, accuracy: 0.16700, task: multi, mean loss: 0.58165, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.69892
Diversity Loss - Mean: -0.14163, Variance: 0.13553
Semantic Loss - Mean: 1.72305, Variance: 0.00076

Train Epoch: 18 
task: majority, mean loss: 2.01476, accuracy: 0.23200, task: max, mean loss: 1.74441, accuracy: 0.28700, task: top, mean loss: 2.09503, accuracy: 0.18500, task: multi, mean loss: 0.57399, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.60704, lr: 0.0009806502171211902
Diversity Loss - Mean: -0.13945, Variance: 0.13069
Semantic Loss - Mean: 1.63000, Variance: 0.00102

Test Epoch: 18 
task: majority, mean loss: 3.06664, accuracy: 0.11100, task: max, mean loss: 2.19339, accuracy: 0.17000, task: top, mean loss: 2.61952, accuracy: 0.10800, task: multi, mean loss: 0.67959, multilabel_accuracy: 0.00100, avg. loss over tasks: 2.13978
Diversity Loss - Mean: -0.14121, Variance: 0.13479
Semantic Loss - Mean: 1.97266, Variance: 0.00076

Train Epoch: 19 
task: majority, mean loss: 2.05434, accuracy: 0.21500, task: max, mean loss: 1.76281, accuracy: 0.26500, task: top, mean loss: 2.12367, accuracy: 0.19100, task: multi, mean loss: 0.57707, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.62947, lr: 0.0009755527298894293
Diversity Loss - Mean: -0.13894, Variance: 0.13018
Semantic Loss - Mean: 1.65055, Variance: 0.00102

Test Epoch: 19 
task: majority, mean loss: 2.08263, accuracy: 0.19200, task: max, mean loss: 1.79655, accuracy: 0.26700, task: top, mean loss: 2.19668, accuracy: 0.18300, task: multi, mean loss: 0.57344, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.66233
Diversity Loss - Mean: -0.14158, Variance: 0.13460
Semantic Loss - Mean: 1.67307, Variance: 0.00073

Train Epoch: 20 
task: majority, mean loss: 2.03822, accuracy: 0.20400, task: max, mean loss: 1.75579, accuracy: 0.27300, task: top, mean loss: 2.10961, accuracy: 0.17000, task: multi, mean loss: 0.57348, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.61927, lr: 0.0009698764640825613
Diversity Loss - Mean: -0.13949, Variance: 0.12993
Semantic Loss - Mean: 1.63792, Variance: 0.00100

Test Epoch: 20 
task: majority, mean loss: 2.91805, accuracy: 0.09000, task: max, mean loss: 2.02716, accuracy: 0.17000, task: top, mean loss: 2.67809, accuracy: 0.10100, task: multi, mean loss: 0.64973, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.06826
Diversity Loss - Mean: -0.14062, Variance: 0.13470
Semantic Loss - Mean: 2.03434, Variance: 0.00073

Train Epoch: 21 
task: majority, mean loss: 2.04563, accuracy: 0.21700, task: max, mean loss: 1.74415, accuracy: 0.29300, task: top, mean loss: 2.12210, accuracy: 0.17200, task: multi, mean loss: 0.57174, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.62091, lr: 0.0009636283353561103
Diversity Loss - Mean: -0.13825, Variance: 0.12942
Semantic Loss - Mean: 1.64043, Variance: 0.00099

Test Epoch: 21 
task: majority, mean loss: 2.40909, accuracy: 0.14800, task: max, mean loss: 1.83745, accuracy: 0.28900, task: top, mean loss: 2.35693, accuracy: 0.10600, task: multi, mean loss: 0.61359, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.80427
Diversity Loss - Mean: -0.14212, Variance: 0.13451
Semantic Loss - Mean: 1.79381, Variance: 0.00073

Train Epoch: 22 
task: majority, mean loss: 1.98584, accuracy: 0.22100, task: max, mean loss: 1.72570, accuracy: 0.30300, task: top, mean loss: 2.09652, accuracy: 0.19600, task: multi, mean loss: 0.57137, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59486, lr: 0.0009568159560924791
Diversity Loss - Mean: -0.13941, Variance: 0.12907
Semantic Loss - Mean: 1.61607, Variance: 0.00099

Test Epoch: 22 
task: majority, mean loss: 2.14515, accuracy: 0.18000, task: max, mean loss: 1.81592, accuracy: 0.29600, task: top, mean loss: 2.22457, accuracy: 0.17400, task: multi, mean loss: 0.57971, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.69134
Diversity Loss - Mean: -0.14229, Variance: 0.13425
Semantic Loss - Mean: 1.67731, Variance: 0.00071

Train Epoch: 23 
task: majority, mean loss: 2.01095, accuracy: 0.23900, task: max, mean loss: 1.72287, accuracy: 0.29600, task: top, mean loss: 2.09355, accuracy: 0.19600, task: multi, mean loss: 0.57141, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.59970, lr: 0.000949447626126434
Diversity Loss - Mean: -0.13934, Variance: 0.12873
Semantic Loss - Mean: 1.62108, Variance: 0.00098

Test Epoch: 23 
task: majority, mean loss: 2.11318, accuracy: 0.21500, task: max, mean loss: 1.75805, accuracy: 0.32000, task: top, mean loss: 2.19407, accuracy: 0.17100, task: multi, mean loss: 0.57102, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.65908
Diversity Loss - Mean: -0.14207, Variance: 0.13375
Semantic Loss - Mean: 1.67232, Variance: 0.00069

Train Epoch: 24 
task: majority, mean loss: 1.95700, accuracy: 0.25900, task: max, mean loss: 1.72291, accuracy: 0.29600, task: top, mean loss: 2.06700, accuracy: 0.21200, task: multi, mean loss: 0.56716, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.57852, lr: 0.000941532322633034
Diversity Loss - Mean: -0.13907, Variance: 0.12832
Semantic Loss - Mean: 1.60147, Variance: 0.00098

Test Epoch: 24 
task: majority, mean loss: 2.01756, accuracy: 0.25300, task: max, mean loss: 1.76073, accuracy: 0.31100, task: top, mean loss: 2.19807, accuracy: 0.20600, task: multi, mean loss: 0.56097, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.63433
Diversity Loss - Mean: -0.14206, Variance: 0.13350
Semantic Loss - Mean: 1.64495, Variance: 0.00067

Train Epoch: 25 
task: majority, mean loss: 2.00802, accuracy: 0.23300, task: max, mean loss: 1.72919, accuracy: 0.27300, task: top, mean loss: 2.08864, accuracy: 0.21300, task: multi, mean loss: 0.57039, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59906, lr: 0.0009330796891903273
Diversity Loss - Mean: -0.13895, Variance: 0.12803
Semantic Loss - Mean: 1.62943, Variance: 0.00099

Test Epoch: 25 
task: majority, mean loss: 2.09181, accuracy: 0.19000, task: max, mean loss: 1.76758, accuracy: 0.31400, task: top, mean loss: 2.21591, accuracy: 0.14400, task: multi, mean loss: 0.57740, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.66317
Diversity Loss - Mean: -0.14144, Variance: 0.13352
Semantic Loss - Mean: 1.65945, Variance: 0.00066

Train Epoch: 26 
task: majority, mean loss: 1.93251, accuracy: 0.25600, task: max, mean loss: 1.70854, accuracy: 0.29400, task: top, mean loss: 2.06818, accuracy: 0.21600, task: multi, mean loss: 0.56486, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.56852, lr: 0.0009241000240301347
Diversity Loss - Mean: -0.13866, Variance: 0.12759
Semantic Loss - Mean: 1.59179, Variance: 0.00099

Test Epoch: 26 
task: majority, mean loss: 2.09055, accuracy: 0.22700, task: max, mean loss: 1.78630, accuracy: 0.27800, task: top, mean loss: 2.20664, accuracy: 0.18400, task: multi, mean loss: 0.57784, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.66533
Diversity Loss - Mean: -0.14171, Variance: 0.13282
Semantic Loss - Mean: 1.66248, Variance: 0.00064

Train Epoch: 27 
task: majority, mean loss: 1.91833, accuracy: 0.28200, task: max, mean loss: 1.72301, accuracy: 0.29900, task: top, mean loss: 2.03459, accuracy: 0.23700, task: multi, mean loss: 0.56556, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.56037, lr: 0.0009146042674912433
Diversity Loss - Mean: -0.13863, Variance: 0.12714
Semantic Loss - Mean: 1.59434, Variance: 0.00100

Test Epoch: 27 
task: majority, mean loss: 2.31739, accuracy: 0.16200, task: max, mean loss: 1.80481, accuracy: 0.31500, task: top, mean loss: 2.27007, accuracy: 0.15200, task: multi, mean loss: 0.58976, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.74551
Diversity Loss - Mean: -0.14208, Variance: 0.13255
Semantic Loss - Mean: 1.75711, Variance: 0.00064

Train Epoch: 28 
task: majority, mean loss: 1.85654, accuracy: 0.29900, task: max, mean loss: 1.69693, accuracy: 0.29900, task: top, mean loss: 1.97851, accuracy: 0.26500, task: multi, mean loss: 0.56118, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.52329, lr: 0.0009046039886902862
Diversity Loss - Mean: -0.13914, Variance: 0.12678
Semantic Loss - Mean: 1.55845, Variance: 0.00100

Test Epoch: 28 
task: majority, mean loss: 2.23055, accuracy: 0.19800, task: max, mean loss: 1.78729, accuracy: 0.31800, task: top, mean loss: 2.15038, accuracy: 0.21100, task: multi, mean loss: 0.58330, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.68788
Diversity Loss - Mean: -0.14195, Variance: 0.13215
Semantic Loss - Mean: 1.68848, Variance: 0.00064

Train Epoch: 29 
task: majority, mean loss: 1.88850, accuracy: 0.29800, task: max, mean loss: 1.69497, accuracy: 0.30600, task: top, mean loss: 1.99321, accuracy: 0.24200, task: multi, mean loss: 0.56147, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.53454, lr: 0.0008941113714265576
Diversity Loss - Mean: -0.13841, Variance: 0.12628
Semantic Loss - Mean: 1.57793, Variance: 0.00103

Test Epoch: 29 
task: majority, mean loss: 3.54073, accuracy: 0.12000, task: max, mean loss: 2.01210, accuracy: 0.19500, task: top, mean loss: 2.83551, accuracy: 0.10800, task: multi, mean loss: 0.68658, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.26873
Diversity Loss - Mean: -0.13651, Variance: 0.13108
Semantic Loss - Mean: 2.15491, Variance: 0.00086

Train Epoch: 30 
task: majority, mean loss: 1.87142, accuracy: 0.29500, task: max, mean loss: 1.69933, accuracy: 0.29900, task: top, mean loss: 1.95981, accuracy: 0.28000, task: multi, mean loss: 0.56117, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.52293, lr: 0.0008831391993379295
Diversity Loss - Mean: -0.13813, Variance: 0.12578
Semantic Loss - Mean: 1.57122, Variance: 0.00104

Test Epoch: 30 
task: majority, mean loss: 1.97462, accuracy: 0.26300, task: max, mean loss: 1.76910, accuracy: 0.30100, task: top, mean loss: 2.07559, accuracy: 0.23500, task: multi, mean loss: 0.55853, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.59446
Diversity Loss - Mean: -0.14192, Variance: 0.13068
Semantic Loss - Mean: 1.61425, Variance: 0.00084

Train Epoch: 31 
task: majority, mean loss: 1.83091, accuracy: 0.31600, task: max, mean loss: 1.70473, accuracy: 0.29400, task: top, mean loss: 1.93857, accuracy: 0.28300, task: multi, mean loss: 0.55917, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.50834, lr: 0.0008717008403259585
Diversity Loss - Mean: -0.13804, Variance: 0.12517
Semantic Loss - Mean: 1.55920, Variance: 0.00105

Test Epoch: 31 
task: majority, mean loss: 2.11891, accuracy: 0.23600, task: max, mean loss: 1.75779, accuracy: 0.28900, task: top, mean loss: 2.19487, accuracy: 0.21300, task: multi, mean loss: 0.56480, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.65909
Diversity Loss - Mean: -0.14066, Variance: 0.12992
Semantic Loss - Mean: 1.65838, Variance: 0.00084

Train Epoch: 32 
task: majority, mean loss: 1.78292, accuracy: 0.34000, task: max, mean loss: 1.69457, accuracy: 0.31100, task: top, mean loss: 1.91304, accuracy: 0.28800, task: multi, mean loss: 0.55357, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.48603, lr: 0.0008598102302691562
Diversity Loss - Mean: -0.13836, Variance: 0.12457
Semantic Loss - Mean: 1.54392, Variance: 0.00107

Test Epoch: 32 
task: majority, mean loss: 2.21078, accuracy: 0.19500, task: max, mean loss: 1.74314, accuracy: 0.31700, task: top, mean loss: 2.20410, accuracy: 0.21300, task: multi, mean loss: 0.56927, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.68182
Diversity Loss - Mean: -0.14178, Variance: 0.12943
Semantic Loss - Mean: 1.68171, Variance: 0.00083

Train Epoch: 33 
task: majority, mean loss: 1.73441, accuracy: 0.34100, task: max, mean loss: 1.66645, accuracy: 0.30300, task: top, mean loss: 1.85009, accuracy: 0.29200, task: multi, mean loss: 0.54990, multilabel_accuracy: 0.00000, avg. loss over tasks: 1.45021, lr: 0.0008474818560442692
Diversity Loss - Mean: -0.13813, Variance: 0.12405
Semantic Loss - Mean: 1.51171, Variance: 0.00109

Test Epoch: 33 
task: majority, mean loss: 2.89310, accuracy: 0.18200, task: max, mean loss: 1.87393, accuracy: 0.20800, task: top, mean loss: 2.64588, accuracy: 0.17100, task: multi, mean loss: 0.63183, multilabel_accuracy: 0.00200, avg. loss over tasks: 2.01118
Diversity Loss - Mean: -0.13760, Variance: 0.12893
Semantic Loss - Mean: 1.99505, Variance: 0.00098

Train Epoch: 34 
task: majority, mean loss: 1.73466, accuracy: 0.34100, task: max, mean loss: 1.69345, accuracy: 0.29700, task: top, mean loss: 1.87483, accuracy: 0.29800, task: multi, mean loss: 0.54962, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.46314, lr: 0.0008347307378762497
Diversity Loss - Mean: -0.13762, Variance: 0.12349
Semantic Loss - Mean: 1.51904, Variance: 0.00111

Test Epoch: 34 
task: majority, mean loss: 2.33459, accuracy: 0.21400, task: max, mean loss: 1.80032, accuracy: 0.23700, task: top, mean loss: 2.32291, accuracy: 0.20500, task: multi, mean loss: 0.59101, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.76221
Diversity Loss - Mean: -0.14096, Variance: 0.12828
Semantic Loss - Mean: 1.77629, Variance: 0.00103

Train Epoch: 35 
task: majority, mean loss: 1.67271, accuracy: 0.36000, task: max, mean loss: 1.66133, accuracy: 0.32400, task: top, mean loss: 1.83938, accuracy: 0.30700, task: multi, mean loss: 0.54576, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.42979, lr: 0.0008215724110384264
Diversity Loss - Mean: -0.13792, Variance: 0.12295
Semantic Loss - Mean: 1.50305, Variance: 0.00113

Test Epoch: 35 
task: majority, mean loss: 2.45442, accuracy: 0.24100, task: max, mean loss: 1.75733, accuracy: 0.32400, task: top, mean loss: 2.25856, accuracy: 0.22300, task: multi, mean loss: 0.58199, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.76308
Diversity Loss - Mean: -0.14154, Variance: 0.12790
Semantic Loss - Mean: 1.74318, Variance: 0.00102

Train Epoch: 36 
task: majority, mean loss: 1.67668, accuracy: 0.35800, task: max, mean loss: 1.66601, accuracy: 0.31700, task: top, mean loss: 1.80699, accuracy: 0.29100, task: multi, mean loss: 0.54718, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.42421, lr: 0.0008080229069251663
Diversity Loss - Mean: -0.13778, Variance: 0.12243
Semantic Loss - Mean: 1.50180, Variance: 0.00116

Test Epoch: 36 
task: majority, mean loss: 1.78584, accuracy: 0.33500, task: max, mean loss: 1.71245, accuracy: 0.31900, task: top, mean loss: 1.99715, accuracy: 0.25200, task: multi, mean loss: 0.54330, multilabel_accuracy: 0.00100, avg. loss over tasks: 1.50969
Diversity Loss - Mean: -0.14121, Variance: 0.12746
Semantic Loss - Mean: 1.56736, Variance: 0.00102

Train Epoch: 37 
task: majority, mean loss: 1.62436, accuracy: 0.38100, task: max, mean loss: 1.64893, accuracy: 0.31400, task: top, mean loss: 1.78328, accuracy: 0.31900, task: multi, mean loss: 0.54265, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.39981, lr: 0.0007940987335200903
Diversity Loss - Mean: -0.13797, Variance: 0.12204
Semantic Loss - Mean: 1.47479, Variance: 0.00118

Test Epoch: 37 
task: majority, mean loss: 2.27521, accuracy: 0.25000, task: max, mean loss: 1.79686, accuracy: 0.32100, task: top, mean loss: 2.31787, accuracy: 0.25000, task: multi, mean loss: 0.58170, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.74291
Diversity Loss - Mean: -0.14105, Variance: 0.12705
Semantic Loss - Mean: 1.68855, Variance: 0.00101

Train Epoch: 38 
task: majority, mean loss: 1.72413, accuracy: 0.34400, task: max, mean loss: 1.66012, accuracy: 0.30500, task: top, mean loss: 1.85905, accuracy: 0.31100, task: multi, mean loss: 0.54694, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.44756, lr: 0.0007798168552836382
Diversity Loss - Mean: -0.13691, Variance: 0.12173
Semantic Loss - Mean: 1.51311, Variance: 0.00120

Test Epoch: 38 
task: majority, mean loss: 2.39137, accuracy: 0.24800, task: max, mean loss: 1.86090, accuracy: 0.29600, task: top, mean loss: 2.33220, accuracy: 0.21700, task: multi, mean loss: 0.59195, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.79411
Diversity Loss - Mean: -0.14086, Variance: 0.12701
Semantic Loss - Mean: 1.72191, Variance: 0.00102

Train Epoch: 39 
task: majority, mean loss: 1.60894, accuracy: 0.39500, task: max, mean loss: 1.62491, accuracy: 0.32800, task: top, mean loss: 1.72245, accuracy: 0.36700, task: multi, mean loss: 0.53906, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.37384, lr: 0.000765194672484486
Diversity Loss - Mean: -0.13735, Variance: 0.12135
Semantic Loss - Mean: 1.45963, Variance: 0.00122

Test Epoch: 39 
task: majority, mean loss: 1.87522, accuracy: 0.31200, task: max, mean loss: 1.78155, accuracy: 0.30300, task: top, mean loss: 1.98210, accuracy: 0.31300, task: multi, mean loss: 0.55240, multilabel_accuracy: 0.01100, avg. loss over tasks: 1.54782
Diversity Loss - Mean: -0.14111, Variance: 0.12666
Semantic Loss - Mean: 1.56965, Variance: 0.00101

Train Epoch: 40 
task: majority, mean loss: 1.58312, accuracy: 0.37800, task: max, mean loss: 1.64241, accuracy: 0.32000, task: top, mean loss: 1.71730, accuracy: 0.36400, task: multi, mean loss: 0.54046, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.37082, lr: 0.00075025
Diversity Loss - Mean: -0.13691, Variance: 0.12097
Semantic Loss - Mean: 1.47268, Variance: 0.00124

Test Epoch: 40 
task: majority, mean loss: 2.91888, accuracy: 0.14600, task: max, mean loss: 1.85458, accuracy: 0.23100, task: top, mean loss: 2.55011, accuracy: 0.14800, task: multi, mean loss: 0.61437, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.98449
Diversity Loss - Mean: -0.14031, Variance: 0.12624
Semantic Loss - Mean: 1.91155, Variance: 0.00110

Train Epoch: 41 
task: majority, mean loss: 1.51977, accuracy: 0.41500, task: max, mean loss: 1.62116, accuracy: 0.30500, task: top, mean loss: 1.65832, accuracy: 0.38100, task: multi, mean loss: 0.53345, multilabel_accuracy: 0.01100, avg. loss over tasks: 1.33317, lr: 0.0007350010456115524
Diversity Loss - Mean: -0.13738, Variance: 0.12063
Semantic Loss - Mean: 1.43696, Variance: 0.00127

Test Epoch: 41 
task: majority, mean loss: 1.85678, accuracy: 0.33300, task: max, mean loss: 1.69145, accuracy: 0.32000, task: top, mean loss: 1.99907, accuracy: 0.31600, task: multi, mean loss: 0.53804, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.52133
Diversity Loss - Mean: -0.14128, Variance: 0.12609
Semantic Loss - Mean: 1.55445, Variance: 0.00110

Train Epoch: 42 
task: majority, mean loss: 1.51843, accuracy: 0.41500, task: max, mean loss: 1.60044, accuracy: 0.33300, task: top, mean loss: 1.66834, accuracy: 0.37800, task: multi, mean loss: 0.53092, multilabel_accuracy: 0.00700, avg. loss over tasks: 1.32953, lr: 0.0007194663878211441
Diversity Loss - Mean: -0.13730, Variance: 0.12027
Semantic Loss - Mean: 1.42852, Variance: 0.00129

Test Epoch: 42 
task: majority, mean loss: 3.58379, accuracy: 0.14700, task: max, mean loss: 2.06640, accuracy: 0.26800, task: top, mean loss: 2.97410, accuracy: 0.17900, task: multi, mean loss: 0.73889, multilabel_accuracy: 0.00000, avg. loss over tasks: 2.34080
Diversity Loss - Mean: -0.14070, Variance: 0.12586
Semantic Loss - Mean: 2.14043, Variance: 0.00114

Train Epoch: 43 
task: majority, mean loss: 1.55333, accuracy: 0.41100, task: max, mean loss: 1.61371, accuracy: 0.33600, task: top, mean loss: 1.69321, accuracy: 0.37200, task: multi, mean loss: 0.53656, multilabel_accuracy: 0.00400, avg. loss over tasks: 1.34920, lr: 0.0007036649532163622
Diversity Loss - Mean: -0.13594, Variance: 0.11986
Semantic Loss - Mean: 1.44192, Variance: 0.00132

Test Epoch: 43 
task: majority, mean loss: 2.82937, accuracy: 0.18200, task: max, mean loss: 1.81452, accuracy: 0.24500, task: top, mean loss: 2.50650, accuracy: 0.16900, task: multi, mean loss: 0.60138, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.93794
Diversity Loss - Mean: -0.13963, Variance: 0.12576
Semantic Loss - Mean: 1.94259, Variance: 0.00123

Train Epoch: 44 
task: majority, mean loss: 1.44665, accuracy: 0.42900, task: max, mean loss: 1.58576, accuracy: 0.32900, task: top, mean loss: 1.64493, accuracy: 0.40200, task: multi, mean loss: 0.52967, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.30175, lr: 0.000687615993411248
Diversity Loss - Mean: -0.13606, Variance: 0.11944
Semantic Loss - Mean: 1.40890, Variance: 0.00135

Test Epoch: 44 
task: majority, mean loss: 1.88179, accuracy: 0.30400, task: max, mean loss: 1.69263, accuracy: 0.31900, task: top, mean loss: 2.07155, accuracy: 0.29400, task: multi, mean loss: 0.53905, multilabel_accuracy: 0.01100, avg. loss over tasks: 1.54626
Diversity Loss - Mean: -0.13684, Variance: 0.12553
Semantic Loss - Mean: 1.54074, Variance: 0.00122

Train Epoch: 45 
task: majority, mean loss: 1.43618, accuracy: 0.45000, task: max, mean loss: 1.57755, accuracy: 0.36200, task: top, mean loss: 1.58262, accuracy: 0.41600, task: multi, mean loss: 0.52728, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.28091, lr: 0.0006713390615911716
Diversity Loss - Mean: -0.13642, Variance: 0.11904
Semantic Loss - Mean: 1.38328, Variance: 0.00138

Test Epoch: 45 
task: majority, mean loss: 2.36640, accuracy: 0.23600, task: max, mean loss: 1.77386, accuracy: 0.32900, task: top, mean loss: 2.34779, accuracy: 0.23900, task: multi, mean loss: 0.57687, multilabel_accuracy: 0.00200, avg. loss over tasks: 1.76623
Diversity Loss - Mean: -0.13930, Variance: 0.12513
Semantic Loss - Mean: 1.78255, Variance: 0.00124

Train Epoch: 46 
task: majority, mean loss: 1.36002, accuracy: 0.47900, task: max, mean loss: 1.55478, accuracy: 0.35200, task: top, mean loss: 1.51250, accuracy: 0.43500, task: multi, mean loss: 0.52026, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.23689, lr: 0.0006548539886902863
Diversity Loss - Mean: -0.13580, Variance: 0.11862
Semantic Loss - Mean: 1.34155, Variance: 0.00141

Test Epoch: 46 
task: majority, mean loss: 1.77181, accuracy: 0.36700, task: max, mean loss: 1.70241, accuracy: 0.32700, task: top, mean loss: 1.97876, accuracy: 0.31800, task: multi, mean loss: 0.53666, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.49741
Diversity Loss - Mean: -0.14002, Variance: 0.12480
Semantic Loss - Mean: 1.50886, Variance: 0.00124

Train Epoch: 47 
task: majority, mean loss: 1.32659, accuracy: 0.49500, task: max, mean loss: 1.54037, accuracy: 0.34800, task: top, mean loss: 1.45443, accuracy: 0.45700, task: multi, mean loss: 0.51503, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.20910, lr: 0.0006381808592305911
Diversity Loss - Mean: -0.13499, Variance: 0.11824
Semantic Loss - Mean: 1.31417, Variance: 0.00144

Test Epoch: 47 
task: majority, mean loss: 1.95040, accuracy: 0.30200, task: max, mean loss: 1.72509, accuracy: 0.30300, task: top, mean loss: 2.08161, accuracy: 0.29900, task: multi, mean loss: 0.54031, multilabel_accuracy: 0.00300, avg. loss over tasks: 1.57435
Diversity Loss - Mean: -0.13896, Variance: 0.12449
Semantic Loss - Mean: 1.55725, Variance: 0.00125

Train Epoch: 48 
task: majority, mean loss: 1.36530, accuracy: 0.46900, task: max, mean loss: 1.56073, accuracy: 0.35900, task: top, mean loss: 1.48906, accuracy: 0.43900, task: multi, mean loss: 0.51724, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.23308, lr: 0.0006213399868520341
Diversity Loss - Mean: -0.13353, Variance: 0.11784
Semantic Loss - Mean: 1.33680, Variance: 0.00147

Test Epoch: 48 
task: majority, mean loss: 2.34623, accuracy: 0.27000, task: max, mean loss: 1.78809, accuracy: 0.26900, task: top, mean loss: 2.12264, accuracy: 0.31400, task: multi, mean loss: 0.55823, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.70379
Diversity Loss - Mean: -0.13871, Variance: 0.12443
Semantic Loss - Mean: 1.71521, Variance: 0.00127

Train Epoch: 49 
task: majority, mean loss: 1.30283, accuracy: 0.49800, task: max, mean loss: 1.53458, accuracy: 0.37200, task: top, mean loss: 1.44110, accuracy: 0.47800, task: multi, mean loss: 0.51541, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.19848, lr: 0.0006043518895634709
Diversity Loss - Mean: -0.13357, Variance: 0.11743
Semantic Loss - Mean: 1.31028, Variance: 0.00150

Test Epoch: 49 
task: majority, mean loss: 2.27767, accuracy: 0.28100, task: max, mean loss: 1.77226, accuracy: 0.29800, task: top, mean loss: 2.17422, accuracy: 0.28000, task: multi, mean loss: 0.55661, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.69519
Diversity Loss - Mean: -0.13729, Variance: 0.12413
Semantic Loss - Mean: 1.67337, Variance: 0.00130

Train Epoch: 50 
task: majority, mean loss: 1.20755, accuracy: 0.53500, task: max, mean loss: 1.53631, accuracy: 0.35900, task: top, mean loss: 1.35988, accuracy: 0.49400, task: multi, mean loss: 0.51078, multilabel_accuracy: 0.01100, avg. loss over tasks: 1.15363, lr: 0.0005872372647446318
Diversity Loss - Mean: -0.13274, Variance: 0.11701
Semantic Loss - Mean: 1.26226, Variance: 0.00153

Test Epoch: 50 
task: majority, mean loss: 1.87261, accuracy: 0.37600, task: max, mean loss: 1.67882, accuracy: 0.32500, task: top, mean loss: 2.02732, accuracy: 0.36900, task: multi, mean loss: 0.52572, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.52612
Diversity Loss - Mean: -0.13797, Variance: 0.12393
Semantic Loss - Mean: 1.50533, Variance: 0.00130

Train Epoch: 51 
task: majority, mean loss: 1.24216, accuracy: 0.51000, task: max, mean loss: 1.54446, accuracy: 0.35700, task: top, mean loss: 1.34499, accuracy: 0.51100, task: multi, mean loss: 0.51164, multilabel_accuracy: 0.00500, avg. loss over tasks: 1.16081, lr: 0.0005700169639295527
Diversity Loss - Mean: -0.13248, Variance: 0.11671
Semantic Loss - Mean: 1.26665, Variance: 0.00157

Test Epoch: 51 
task: majority, mean loss: 2.90070, accuracy: 0.22300, task: max, mean loss: 2.02537, accuracy: 0.27800, task: top, mean loss: 2.28062, accuracy: 0.26300, task: multi, mean loss: 0.62266, multilabel_accuracy: 0.00900, avg. loss over tasks: 1.95734
Diversity Loss - Mean: -0.13784, Variance: 0.12354
Semantic Loss - Mean: 1.89971, Variance: 0.00134

Train Epoch: 52 
task: majority, mean loss: 1.22689, accuracy: 0.54300, task: max, mean loss: 1.53953, accuracy: 0.36700, task: top, mean loss: 1.31892, accuracy: 0.51400, task: multi, mean loss: 0.50745, multilabel_accuracy: 0.01300, avg. loss over tasks: 1.14820, lr: 0.0005527119674021931
Diversity Loss - Mean: -0.13264, Variance: 0.11637
Semantic Loss - Mean: 1.25653, Variance: 0.00160

Test Epoch: 52 
task: majority, mean loss: 1.97939, accuracy: 0.33400, task: max, mean loss: 1.66679, accuracy: 0.33500, task: top, mean loss: 2.02617, accuracy: 0.35900, task: multi, mean loss: 0.53669, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.55226
Diversity Loss - Mean: -0.13501, Variance: 0.12331
Semantic Loss - Mean: 1.55383, Variance: 0.00136

Train Epoch: 53 
task: majority, mean loss: 1.08682, accuracy: 0.58400, task: max, mean loss: 1.48694, accuracy: 0.38600, task: top, mean loss: 1.21730, accuracy: 0.56000, task: multi, mean loss: 0.50332, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.07359, lr: 0.0005353433586351905
Diversity Loss - Mean: -0.13273, Variance: 0.11607
Semantic Loss - Mean: 1.18699, Variance: 0.00163

Test Epoch: 53 
task: majority, mean loss: 2.06382, accuracy: 0.36400, task: max, mean loss: 1.74795, accuracy: 0.33600, task: top, mean loss: 1.99436, accuracy: 0.36500, task: multi, mean loss: 0.55470, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.59021
Diversity Loss - Mean: -0.13426, Variance: 0.12307
Semantic Loss - Mean: 1.57747, Variance: 0.00138

Train Epoch: 54 
task: majority, mean loss: 1.14156, accuracy: 0.56700, task: max, mean loss: 1.48645, accuracy: 0.39500, task: top, mean loss: 1.24317, accuracy: 0.55500, task: multi, mean loss: 0.50222, multilabel_accuracy: 0.00800, avg. loss over tasks: 1.09335, lr: 0.0005179322986028993
Diversity Loss - Mean: -0.13279, Variance: 0.11583
Semantic Loss - Mean: 1.21800, Variance: 0.00167

Test Epoch: 54 
task: majority, mean loss: 1.60751, accuracy: 0.41700, task: max, mean loss: 1.74241, accuracy: 0.32200, task: top, mean loss: 1.84420, accuracy: 0.36900, task: multi, mean loss: 0.51641, multilabel_accuracy: 0.00600, avg. loss over tasks: 1.42763
Diversity Loss - Mean: -0.13828, Variance: 0.12285
Semantic Loss - Mean: 1.43465, Variance: 0.00137

Train Epoch: 55 
task: majority, mean loss: 1.11729, accuracy: 0.57800, task: max, mean loss: 1.47447, accuracy: 0.40800, task: top, mean loss: 1.15146, accuracy: 0.56700, task: multi, mean loss: 0.50360, multilabel_accuracy: 0.01500, avg. loss over tasks: 1.06170, lr: 0.0005005
Diversity Loss - Mean: -0.13249, Variance: 0.11561
Semantic Loss - Mean: 1.18419, Variance: 0.00171

Test Epoch: 55 
task: majority, mean loss: 1.51697, accuracy: 0.47000, task: max, mean loss: 1.62866, accuracy: 0.37000, task: top, mean loss: 1.81960, accuracy: 0.42300, task: multi, mean loss: 0.51730, multilabel_accuracy: 0.01000, avg. loss over tasks: 1.37063
Diversity Loss - Mean: -0.13615, Variance: 0.12265
Semantic Loss - Mean: 1.38584, Variance: 0.00138

Train Epoch: 56 
task: majority, mean loss: 0.99674, accuracy: 0.61900, task: max, mean loss: 1.42135, accuracy: 0.43500, task: top, mean loss: 1.07296, accuracy: 0.59200, task: multi, mean loss: 0.49639, multilabel_accuracy: 0.01500, avg. loss over tasks: 0.99686, lr: 0.00048306770139710083
Diversity Loss - Mean: -0.13231, Variance: 0.11537
Semantic Loss - Mean: 1.13043, Variance: 0.00175

Test Epoch: 56 
task: majority, mean loss: 1.43528, accuracy: 0.50700, task: max, mean loss: 1.60265, accuracy: 0.37300, task: top, mean loss: 1.79293, accuracy: 0.42400, task: multi, mean loss: 0.50061, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.33287
Diversity Loss - Mean: -0.13727, Variance: 0.12242
Semantic Loss - Mean: 1.33989, Variance: 0.00139

Train Epoch: 57 
task: majority, mean loss: 0.92226, accuracy: 0.64900, task: max, mean loss: 1.39720, accuracy: 0.46300, task: top, mean loss: 0.98832, accuracy: 0.65000, task: multi, mean loss: 0.49042, multilabel_accuracy: 0.02000, avg. loss over tasks: 0.94955, lr: 0.0004656566413648095
Diversity Loss - Mean: -0.13216, Variance: 0.11516
Semantic Loss - Mean: 1.08425, Variance: 0.00178

Test Epoch: 57 
task: majority, mean loss: 1.47316, accuracy: 0.48900, task: max, mean loss: 1.59794, accuracy: 0.40300, task: top, mean loss: 1.78167, accuracy: 0.43600, task: multi, mean loss: 0.50761, multilabel_accuracy: 0.01600, avg. loss over tasks: 1.34010
Diversity Loss - Mean: -0.13831, Variance: 0.12225
Semantic Loss - Mean: 1.33872, Variance: 0.00139

Train Epoch: 58 
task: majority, mean loss: 0.92756, accuracy: 0.64200, task: max, mean loss: 1.38954, accuracy: 0.47700, task: top, mean loss: 1.03279, accuracy: 0.60600, task: multi, mean loss: 0.48986, multilabel_accuracy: 0.02000, avg. loss over tasks: 0.95994, lr: 0.0004482880325978071
Diversity Loss - Mean: -0.13202, Variance: 0.11495
Semantic Loss - Mean: 1.08901, Variance: 0.00182

Test Epoch: 58 
task: majority, mean loss: 2.31317, accuracy: 0.30600, task: max, mean loss: 1.95991, accuracy: 0.29800, task: top, mean loss: 2.02908, accuracy: 0.39300, task: multi, mean loss: 0.56427, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.71661
Diversity Loss - Mean: -0.13438, Variance: 0.12208
Semantic Loss - Mean: 1.72237, Variance: 0.00142

Train Epoch: 59 
task: majority, mean loss: 0.85533, accuracy: 0.68400, task: max, mean loss: 1.34989, accuracy: 0.48300, task: top, mean loss: 0.88341, accuracy: 0.69200, task: multi, mean loss: 0.48618, multilabel_accuracy: 0.02100, avg. loss over tasks: 0.89370, lr: 0.0004309830360704473
Diversity Loss - Mean: -0.13242, Variance: 0.11477
Semantic Loss - Mean: 1.03974, Variance: 0.00186

Test Epoch: 59 
task: majority, mean loss: 1.67251, accuracy: 0.45900, task: max, mean loss: 1.57737, accuracy: 0.42200, task: top, mean loss: 1.83112, accuracy: 0.45300, task: multi, mean loss: 0.50153, multilabel_accuracy: 0.01800, avg. loss over tasks: 1.39563
Diversity Loss - Mean: -0.13731, Variance: 0.12203
Semantic Loss - Mean: 1.40391, Variance: 0.00143

Train Epoch: 60 
task: majority, mean loss: 0.86699, accuracy: 0.68000, task: max, mean loss: 1.32016, accuracy: 0.49000, task: top, mean loss: 0.92432, accuracy: 0.65500, task: multi, mean loss: 0.48811, multilabel_accuracy: 0.02800, avg. loss over tasks: 0.89989, lr: 0.00041376273525536834
Diversity Loss - Mean: -0.13146, Variance: 0.11458
Semantic Loss - Mean: 1.06042, Variance: 0.00191

Test Epoch: 60 
task: majority, mean loss: 1.92969, accuracy: 0.40400, task: max, mean loss: 1.62851, accuracy: 0.41000, task: top, mean loss: 2.00517, accuracy: 0.43600, task: multi, mean loss: 0.53314, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.52413
Diversity Loss - Mean: -0.13694, Variance: 0.12206
Semantic Loss - Mean: 1.48114, Variance: 0.00145

Train Epoch: 61 
task: majority, mean loss: 0.81990, accuracy: 0.71800, task: max, mean loss: 1.27414, accuracy: 0.52600, task: top, mean loss: 0.86610, accuracy: 0.69300, task: multi, mean loss: 0.48531, multilabel_accuracy: 0.02700, avg. loss over tasks: 0.86136, lr: 0.00039664811043652927
Diversity Loss - Mean: -0.13107, Variance: 0.11441
Semantic Loss - Mean: 1.00402, Variance: 0.00196

Test Epoch: 61 
task: majority, mean loss: 1.90726, accuracy: 0.42600, task: max, mean loss: 1.72002, accuracy: 0.35400, task: top, mean loss: 1.93721, accuracy: 0.41900, task: multi, mean loss: 0.54406, multilabel_accuracy: 0.01200, avg. loss over tasks: 1.52714
Diversity Loss - Mean: -0.13320, Variance: 0.12194
Semantic Loss - Mean: 1.53057, Variance: 0.00148

Train Epoch: 62 
task: majority, mean loss: 0.73434, accuracy: 0.74600, task: max, mean loss: 1.22237, accuracy: 0.54500, task: top, mean loss: 0.76835, accuracy: 0.72700, task: multi, mean loss: 0.48006, multilabel_accuracy: 0.01900, avg. loss over tasks: 0.80128, lr: 0.00037966001314796593
Diversity Loss - Mean: -0.13030, Variance: 0.11423
Semantic Loss - Mean: 0.95693, Variance: 0.00202

Test Epoch: 62 
task: majority, mean loss: 1.64866, accuracy: 0.45400, task: max, mean loss: 1.53451, accuracy: 0.42700, task: top, mean loss: 1.80912, accuracy: 0.48300, task: multi, mean loss: 0.51940, multilabel_accuracy: 0.01900, avg. loss over tasks: 1.37793
Diversity Loss - Mean: -0.13438, Variance: 0.12190
Semantic Loss - Mean: 1.38858, Variance: 0.00150

Train Epoch: 63 
task: majority, mean loss: 0.70143, accuracy: 0.73700, task: max, mean loss: 1.14609, accuracy: 0.59700, task: top, mean loss: 0.67287, accuracy: 0.75700, task: multi, mean loss: 0.48030, multilabel_accuracy: 0.03400, avg. loss over tasks: 0.75017, lr: 0.00036281914076940884
Diversity Loss - Mean: -0.12958, Variance: 0.11407
Semantic Loss - Mean: 0.91929, Variance: 0.00207

Test Epoch: 63 
task: majority, mean loss: 1.37643, accuracy: 0.56900, task: max, mean loss: 1.38847, accuracy: 0.50500, task: top, mean loss: 1.68554, accuracy: 0.52500, task: multi, mean loss: 0.48293, multilabel_accuracy: 0.03200, avg. loss over tasks: 1.23334
Diversity Loss - Mean: -0.13209, Variance: 0.12179
Semantic Loss - Mean: 1.23954, Variance: 0.00152

Train Epoch: 64 
task: majority, mean loss: 0.68699, accuracy: 0.76100, task: max, mean loss: 1.09617, accuracy: 0.60900, task: top, mean loss: 0.63511, accuracy: 0.78300, task: multi, mean loss: 0.47679, multilabel_accuracy: 0.03400, avg. loss over tasks: 0.72377, lr: 0.00034614601130971383
Diversity Loss - Mean: -0.12870, Variance: 0.11391
Semantic Loss - Mean: 0.88868, Variance: 0.00214

Test Epoch: 64 
task: majority, mean loss: 1.64882, accuracy: 0.51300, task: max, mean loss: 1.34754, accuracy: 0.54200, task: top, mean loss: 1.76210, accuracy: 0.50200, task: multi, mean loss: 0.48593, multilabel_accuracy: 0.03500, avg. loss over tasks: 1.31110
Diversity Loss - Mean: -0.13348, Variance: 0.12167
Semantic Loss - Mean: 1.29444, Variance: 0.00153

Train Epoch: 65 
task: majority, mean loss: 0.61731, accuracy: 0.78700, task: max, mean loss: 1.01761, accuracy: 0.65800, task: top, mean loss: 0.52509, accuracy: 0.83300, task: multi, mean loss: 0.47190, multilabel_accuracy: 0.03400, avg. loss over tasks: 0.65798, lr: 0.0003296609384088285
Diversity Loss - Mean: -0.12857, Variance: 0.11379
Semantic Loss - Mean: 0.83002, Variance: 0.00218

Test Epoch: 65 
task: majority, mean loss: 1.44086, accuracy: 0.56100, task: max, mean loss: 1.39892, accuracy: 0.53400, task: top, mean loss: 1.76665, accuracy: 0.53000, task: multi, mean loss: 0.48414, multilabel_accuracy: 0.03000, avg. loss over tasks: 1.27264
Diversity Loss - Mean: -0.13645, Variance: 0.12162
Semantic Loss - Mean: 1.26264, Variance: 0.00156

Train Epoch: 66 
task: majority, mean loss: 0.59372, accuracy: 0.79200, task: max, mean loss: 0.91858, accuracy: 0.69000, task: top, mean loss: 0.46108, accuracy: 0.85300, task: multi, mean loss: 0.46862, multilabel_accuracy: 0.03500, avg. loss over tasks: 0.61050, lr: 0.00031338400658875205
Diversity Loss - Mean: -0.12873, Variance: 0.11369
Semantic Loss - Mean: 0.80369, Variance: 0.00224

Test Epoch: 66 
task: majority, mean loss: 1.82923, accuracy: 0.46500, task: max, mean loss: 1.41844, accuracy: 0.54600, task: top, mean loss: 1.77522, accuracy: 0.52800, task: multi, mean loss: 0.50006, multilabel_accuracy: 0.03200, avg. loss over tasks: 1.38074
Diversity Loss - Mean: -0.13440, Variance: 0.12157
Semantic Loss - Mean: 1.36176, Variance: 0.00158

Train Epoch: 67 
task: majority, mean loss: 0.59261, accuracy: 0.78800, task: max, mean loss: 0.91309, accuracy: 0.68600, task: top, mean loss: 0.42726, accuracy: 0.87700, task: multi, mean loss: 0.46693, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.59997, lr: 0.00029733504678363775
Diversity Loss - Mean: -0.12863, Variance: 0.11360
Semantic Loss - Mean: 0.78364, Variance: 0.00230

Test Epoch: 67 
task: majority, mean loss: 1.33970, accuracy: 0.59700, task: max, mean loss: 1.31419, accuracy: 0.57400, task: top, mean loss: 1.70835, accuracy: 0.55800, task: multi, mean loss: 0.47827, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.21013
Diversity Loss - Mean: -0.13400, Variance: 0.12154
Semantic Loss - Mean: 1.22937, Variance: 0.00160

Train Epoch: 68 
task: majority, mean loss: 0.50363, accuracy: 0.82900, task: max, mean loss: 0.86284, accuracy: 0.70500, task: top, mean loss: 0.35111, accuracy: 0.90100, task: multi, mean loss: 0.46112, multilabel_accuracy: 0.04100, avg. loss over tasks: 0.54468, lr: 0.00028153361217885594
Diversity Loss - Mean: -0.12823, Variance: 0.11352
Semantic Loss - Mean: 0.74160, Variance: 0.00236

Test Epoch: 68 
task: majority, mean loss: 1.30731, accuracy: 0.59600, task: max, mean loss: 1.35316, accuracy: 0.57200, task: top, mean loss: 1.69161, accuracy: 0.57600, task: multi, mean loss: 0.47913, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.20780
Diversity Loss - Mean: -0.13558, Variance: 0.12155
Semantic Loss - Mean: 1.18711, Variance: 0.00163

Train Epoch: 69 
task: majority, mean loss: 0.48352, accuracy: 0.83100, task: max, mean loss: 0.81039, accuracy: 0.72400, task: top, mean loss: 0.34516, accuracy: 0.89400, task: multi, mean loss: 0.45922, multilabel_accuracy: 0.04000, avg. loss over tasks: 0.52457, lr: 0.0002659989543884475
Diversity Loss - Mean: -0.12865, Variance: 0.11347
Semantic Loss - Mean: 0.70609, Variance: 0.00241

Test Epoch: 69 
task: majority, mean loss: 2.10100, accuracy: 0.43600, task: max, mean loss: 1.55795, accuracy: 0.52700, task: top, mean loss: 2.04011, accuracy: 0.50400, task: multi, mean loss: 0.52796, multilabel_accuracy: 0.03100, avg. loss over tasks: 1.55675
Diversity Loss - Mean: -0.13538, Variance: 0.12164
Semantic Loss - Mean: 1.53434, Variance: 0.00165

Train Epoch: 70 
task: majority, mean loss: 0.39462, accuracy: 0.87300, task: max, mean loss: 0.76761, accuracy: 0.75700, task: top, mean loss: 0.28090, accuracy: 0.92900, task: multi, mean loss: 0.46033, multilabel_accuracy: 0.04500, avg. loss over tasks: 0.47586, lr: 0.0002507500000000001
Diversity Loss - Mean: -0.12916, Variance: 0.11345
Semantic Loss - Mean: 0.67611, Variance: 0.00247

Test Epoch: 70 
task: majority, mean loss: 1.37026, accuracy: 0.57500, task: max, mean loss: 1.34257, accuracy: 0.59100, task: top, mean loss: 1.76704, accuracy: 0.59700, task: multi, mean loss: 0.47286, multilabel_accuracy: 0.04200, avg. loss over tasks: 1.23818
Diversity Loss - Mean: -0.13430, Variance: 0.12172
Semantic Loss - Mean: 1.23907, Variance: 0.00167

Train Epoch: 71 
task: majority, mean loss: 0.42567, accuracy: 0.85700, task: max, mean loss: 0.72989, accuracy: 0.75700, task: top, mean loss: 0.25260, accuracy: 0.93600, task: multi, mean loss: 0.45660, multilabel_accuracy: 0.04200, avg. loss over tasks: 0.46619, lr: 0.0002358053275155142
Diversity Loss - Mean: -0.12928, Variance: 0.11346
Semantic Loss - Mean: 0.66013, Variance: 0.00252

Test Epoch: 71 
task: majority, mean loss: 1.40770, accuracy: 0.59800, task: max, mean loss: 1.34262, accuracy: 0.59100, task: top, mean loss: 1.78673, accuracy: 0.57500, task: multi, mean loss: 0.47515, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.25305
Diversity Loss - Mean: -0.13641, Variance: 0.12179
Semantic Loss - Mean: 1.22565, Variance: 0.00170

Train Epoch: 72 
task: majority, mean loss: 0.36563, accuracy: 0.88200, task: max, mean loss: 0.66877, accuracy: 0.77100, task: top, mean loss: 0.22122, accuracy: 0.95100, task: multi, mean loss: 0.45266, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.42707, lr: 0.00022118314471636204
Diversity Loss - Mean: -0.12906, Variance: 0.11346
Semantic Loss - Mean: 0.62695, Variance: 0.00258

Test Epoch: 72 
task: majority, mean loss: 1.60160, accuracy: 0.52600, task: max, mean loss: 1.43353, accuracy: 0.56600, task: top, mean loss: 1.87842, accuracy: 0.56300, task: multi, mean loss: 0.49164, multilabel_accuracy: 0.04000, avg. loss over tasks: 1.35130
Diversity Loss - Mean: -0.13678, Variance: 0.12188
Semantic Loss - Mean: 1.30687, Variance: 0.00173

Train Epoch: 73 
task: majority, mean loss: 0.33109, accuracy: 0.88700, task: max, mean loss: 0.63579, accuracy: 0.79700, task: top, mean loss: 0.20069, accuracy: 0.95300, task: multi, mean loss: 0.45335, multilabel_accuracy: 0.04500, avg. loss over tasks: 0.40523, lr: 0.00020690126647990973
Diversity Loss - Mean: -0.12927, Variance: 0.11349
Semantic Loss - Mean: 0.60656, Variance: 0.00262

Test Epoch: 73 
task: majority, mean loss: 1.42586, accuracy: 0.60500, task: max, mean loss: 1.31469, accuracy: 0.60200, task: top, mean loss: 1.87938, accuracy: 0.57000, task: multi, mean loss: 0.47013, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.27252
Diversity Loss - Mean: -0.13703, Variance: 0.12198
Semantic Loss - Mean: 1.23646, Variance: 0.00176

Train Epoch: 74 
task: majority, mean loss: 0.30808, accuracy: 0.89400, task: max, mean loss: 0.59287, accuracy: 0.81600, task: top, mean loss: 0.15842, accuracy: 0.96400, task: multi, mean loss: 0.45113, multilabel_accuracy: 0.05400, avg. loss over tasks: 0.37762, lr: 0.00019297709307483367
Diversity Loss - Mean: -0.12920, Variance: 0.11352
Semantic Loss - Mean: 0.57856, Variance: 0.00268

Test Epoch: 74 
task: majority, mean loss: 1.68908, accuracy: 0.54500, task: max, mean loss: 1.34017, accuracy: 0.60400, task: top, mean loss: 1.92479, accuracy: 0.57000, task: multi, mean loss: 0.48615, multilabel_accuracy: 0.04100, avg. loss over tasks: 1.36005
Diversity Loss - Mean: -0.13692, Variance: 0.12207
Semantic Loss - Mean: 1.30038, Variance: 0.00178

Train Epoch: 75 
task: majority, mean loss: 0.28807, accuracy: 0.90000, task: max, mean loss: 0.54491, accuracy: 0.83300, task: top, mean loss: 0.15458, accuracy: 0.96400, task: multi, mean loss: 0.44801, multilabel_accuracy: 0.05800, avg. loss over tasks: 0.35889, lr: 0.0001794275889615736
Diversity Loss - Mean: -0.12889, Variance: 0.11356
Semantic Loss - Mean: 0.55499, Variance: 0.00274

Test Epoch: 75 
task: majority, mean loss: 1.49378, accuracy: 0.59300, task: max, mean loss: 1.43371, accuracy: 0.58800, task: top, mean loss: 1.99345, accuracy: 0.57300, task: multi, mean loss: 0.47920, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.35004
Diversity Loss - Mean: -0.13712, Variance: 0.12223
Semantic Loss - Mean: 1.30334, Variance: 0.00181

Train Epoch: 76 
task: majority, mean loss: 0.25807, accuracy: 0.91400, task: max, mean loss: 0.52500, accuracy: 0.84100, task: top, mean loss: 0.11418, accuracy: 0.97500, task: multi, mean loss: 0.44293, multilabel_accuracy: 0.05000, avg. loss over tasks: 0.33504, lr: 0.0001662692621237503
Diversity Loss - Mean: -0.12955, Variance: 0.11362
Semantic Loss - Mean: 0.53316, Variance: 0.00278

Test Epoch: 76 
task: majority, mean loss: 1.50938, accuracy: 0.58800, task: max, mean loss: 1.32857, accuracy: 0.61100, task: top, mean loss: 1.89345, accuracy: 0.59200, task: multi, mean loss: 0.47635, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.30194
Diversity Loss - Mean: -0.13661, Variance: 0.12243
Semantic Loss - Mean: 1.24305, Variance: 0.00184

Train Epoch: 77 
task: majority, mean loss: 0.23781, accuracy: 0.92500, task: max, mean loss: 0.49510, accuracy: 0.84600, task: top, mean loss: 0.12048, accuracy: 0.97300, task: multi, mean loss: 0.44493, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.32458, lr: 0.000153518143955731
Diversity Loss - Mean: -0.12932, Variance: 0.11368
Semantic Loss - Mean: 0.52511, Variance: 0.00283

Test Epoch: 77 
task: majority, mean loss: 1.42220, accuracy: 0.62000, task: max, mean loss: 1.33730, accuracy: 0.62600, task: top, mean loss: 1.91542, accuracy: 0.59200, task: multi, mean loss: 0.47147, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.28660
Diversity Loss - Mean: -0.13716, Variance: 0.12262
Semantic Loss - Mean: 1.22867, Variance: 0.00187

Train Epoch: 78 
task: majority, mean loss: 0.20818, accuracy: 0.93800, task: max, mean loss: 0.46352, accuracy: 0.85000, task: top, mean loss: 0.10433, accuracy: 0.98000, task: multi, mean loss: 0.43830, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.30358, lr: 0.00014118976973084374
Diversity Loss - Mean: -0.12970, Variance: 0.11376
Semantic Loss - Mean: 0.49713, Variance: 0.00288

Test Epoch: 78 
task: majority, mean loss: 1.46913, accuracy: 0.60700, task: max, mean loss: 1.34623, accuracy: 0.61200, task: top, mean loss: 1.90430, accuracy: 0.59000, task: multi, mean loss: 0.47293, multilabel_accuracy: 0.04900, avg. loss over tasks: 1.29815
Diversity Loss - Mean: -0.13722, Variance: 0.12283
Semantic Loss - Mean: 1.23631, Variance: 0.00189

Train Epoch: 79 
task: majority, mean loss: 0.18670, accuracy: 0.95500, task: max, mean loss: 0.42579, accuracy: 0.86800, task: top, mean loss: 0.08296, accuracy: 0.98500, task: multi, mean loss: 0.43757, multilabel_accuracy: 0.04200, avg. loss over tasks: 0.28326, lr: 0.0001292991596740417
Diversity Loss - Mean: -0.13003, Variance: 0.11386
Semantic Loss - Mean: 0.47540, Variance: 0.00291

Test Epoch: 79 
task: majority, mean loss: 1.49702, accuracy: 0.60600, task: max, mean loss: 1.36752, accuracy: 0.62000, task: top, mean loss: 1.88846, accuracy: 0.60600, task: multi, mean loss: 0.47183, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.30621
Diversity Loss - Mean: -0.13720, Variance: 0.12305
Semantic Loss - Mean: 1.25161, Variance: 0.00192

Train Epoch: 80 
task: majority, mean loss: 0.16861, accuracy: 0.95700, task: max, mean loss: 0.39669, accuracy: 0.88500, task: top, mean loss: 0.07393, accuracy: 0.98900, task: multi, mean loss: 0.43720, multilabel_accuracy: 0.05200, avg. loss over tasks: 0.26911, lr: 0.00011786080066207054
Diversity Loss - Mean: -0.12989, Variance: 0.11397
Semantic Loss - Mean: 0.45778, Variance: 0.00295

Test Epoch: 80 
task: majority, mean loss: 1.54516, accuracy: 0.59100, task: max, mean loss: 1.42096, accuracy: 0.61400, task: top, mean loss: 1.92889, accuracy: 0.60100, task: multi, mean loss: 0.47773, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.34318
Diversity Loss - Mean: -0.13753, Variance: 0.12328
Semantic Loss - Mean: 1.27308, Variance: 0.00195

Train Epoch: 81 
task: majority, mean loss: 0.17192, accuracy: 0.95300, task: max, mean loss: 0.38286, accuracy: 0.88800, task: top, mean loss: 0.07512, accuracy: 0.98900, task: multi, mean loss: 0.43733, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.26681, lr: 0.00010688862857344241
Diversity Loss - Mean: -0.12984, Variance: 0.11409
Semantic Loss - Mean: 0.45382, Variance: 0.00299

Test Epoch: 81 
task: majority, mean loss: 1.62104, accuracy: 0.59800, task: max, mean loss: 1.47296, accuracy: 0.60200, task: top, mean loss: 1.97268, accuracy: 0.59500, task: multi, mean loss: 0.48069, multilabel_accuracy: 0.03900, avg. loss over tasks: 1.38684
Diversity Loss - Mean: -0.13761, Variance: 0.12351
Semantic Loss - Mean: 1.32688, Variance: 0.00199

Train Epoch: 82 
task: majority, mean loss: 0.14585, accuracy: 0.96400, task: max, mean loss: 0.36041, accuracy: 0.89500, task: top, mean loss: 0.06280, accuracy: 0.99200, task: multi, mean loss: 0.43679, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.25146, lr: 9.63960113097138e-05
Diversity Loss - Mean: -0.12992, Variance: 0.11420
Semantic Loss - Mean: 0.43385, Variance: 0.00302

Test Epoch: 82 
task: majority, mean loss: 1.56116, accuracy: 0.60900, task: max, mean loss: 1.40994, accuracy: 0.61100, task: top, mean loss: 1.93232, accuracy: 0.59900, task: multi, mean loss: 0.47005, multilabel_accuracy: 0.05100, avg. loss over tasks: 1.34337
Diversity Loss - Mean: -0.13749, Variance: 0.12375
Semantic Loss - Mean: 1.28090, Variance: 0.00202

Train Epoch: 83 
task: majority, mean loss: 0.14105, accuracy: 0.96600, task: max, mean loss: 0.34198, accuracy: 0.89900, task: top, mean loss: 0.06574, accuracy: 0.99200, task: multi, mean loss: 0.43405, multilabel_accuracy: 0.05000, avg. loss over tasks: 0.24570, lr: 8.639573250875671e-05
Diversity Loss - Mean: -0.12982, Variance: 0.11432
Semantic Loss - Mean: 0.42969, Variance: 0.00306

Test Epoch: 83 
task: majority, mean loss: 1.54034, accuracy: 0.62300, task: max, mean loss: 1.42318, accuracy: 0.61600, task: top, mean loss: 1.94138, accuracy: 0.58900, task: multi, mean loss: 0.46916, multilabel_accuracy: 0.05100, avg. loss over tasks: 1.34352
Diversity Loss - Mean: -0.13756, Variance: 0.12398
Semantic Loss - Mean: 1.27423, Variance: 0.00204

Train Epoch: 84 
task: majority, mean loss: 0.12986, accuracy: 0.97100, task: max, mean loss: 0.32704, accuracy: 0.90600, task: top, mean loss: 0.05657, accuracy: 0.99700, task: multi, mean loss: 0.42949, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.23574, lr: 7.689997596986524e-05
Diversity Loss - Mean: -0.13040, Variance: 0.11446
Semantic Loss - Mean: 0.41181, Variance: 0.00308

Test Epoch: 84 
task: majority, mean loss: 1.51785, accuracy: 0.60900, task: max, mean loss: 1.47315, accuracy: 0.61400, task: top, mean loss: 1.95579, accuracy: 0.59600, task: multi, mean loss: 0.47379, multilabel_accuracy: 0.04400, avg. loss over tasks: 1.35515
Diversity Loss - Mean: -0.13775, Variance: 0.12422
Semantic Loss - Mean: 1.29008, Variance: 0.00207

Train Epoch: 85 
task: majority, mean loss: 0.13219, accuracy: 0.96900, task: max, mean loss: 0.32556, accuracy: 0.90600, task: top, mean loss: 0.05364, accuracy: 0.99500, task: multi, mean loss: 0.43180, multilabel_accuracy: 0.04500, avg. loss over tasks: 0.23580, lr: 6.792031080967287e-05
Diversity Loss - Mean: -0.13025, Variance: 0.11460
Semantic Loss - Mean: 0.41964, Variance: 0.00311

Test Epoch: 85 
task: majority, mean loss: 1.54142, accuracy: 0.59700, task: max, mean loss: 1.50570, accuracy: 0.61800, task: top, mean loss: 1.97087, accuracy: 0.60000, task: multi, mean loss: 0.47705, multilabel_accuracy: 0.04400, avg. loss over tasks: 1.37376
Diversity Loss - Mean: -0.13794, Variance: 0.12444
Semantic Loss - Mean: 1.30237, Variance: 0.00211

Train Epoch: 86 
task: majority, mean loss: 0.10604, accuracy: 0.97400, task: max, mean loss: 0.30719, accuracy: 0.91200, task: top, mean loss: 0.05231, accuracy: 0.99600, task: multi, mean loss: 0.43029, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.22396, lr: 5.946767736696608e-05
Diversity Loss - Mean: -0.13065, Variance: 0.11474
Semantic Loss - Mean: 0.39647, Variance: 0.00314

Test Epoch: 86 
task: majority, mean loss: 1.51853, accuracy: 0.60700, task: max, mean loss: 1.53473, accuracy: 0.60000, task: top, mean loss: 1.99337, accuracy: 0.60200, task: multi, mean loss: 0.47934, multilabel_accuracy: 0.03900, avg. loss over tasks: 1.38149
Diversity Loss - Mean: -0.13794, Variance: 0.12467
Semantic Loss - Mean: 1.30806, Variance: 0.00214

Train Epoch: 87 
task: majority, mean loss: 0.12016, accuracy: 0.96700, task: max, mean loss: 0.29717, accuracy: 0.91100, task: top, mean loss: 0.05116, accuracy: 0.99700, task: multi, mean loss: 0.42909, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.22440, lr: 5.155237387356607e-05
Diversity Loss - Mean: -0.13053, Variance: 0.11488
Semantic Loss - Mean: 0.40220, Variance: 0.00318

Test Epoch: 87 
task: majority, mean loss: 1.54661, accuracy: 0.61000, task: max, mean loss: 1.49979, accuracy: 0.61400, task: top, mean loss: 2.01179, accuracy: 0.59600, task: multi, mean loss: 0.47394, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.38303
Diversity Loss - Mean: -0.13794, Variance: 0.12493
Semantic Loss - Mean: 1.30458, Variance: 0.00217

Train Epoch: 88 
task: majority, mean loss: 0.11359, accuracy: 0.96900, task: max, mean loss: 0.28319, accuracy: 0.92600, task: top, mean loss: 0.04896, accuracy: 0.99800, task: multi, mean loss: 0.42829, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.21851, lr: 4.4184043907520925e-05
Diversity Loss - Mean: -0.13038, Variance: 0.11503
Semantic Loss - Mean: 0.39204, Variance: 0.00321

Test Epoch: 88 
task: majority, mean loss: 1.54278, accuracy: 0.60100, task: max, mean loss: 1.54695, accuracy: 0.60700, task: top, mean loss: 1.98280, accuracy: 0.60300, task: multi, mean loss: 0.47912, multilabel_accuracy: 0.04800, avg. loss over tasks: 1.38791
Diversity Loss - Mean: -0.13817, Variance: 0.12516
Semantic Loss - Mean: 1.31285, Variance: 0.00220

Train Epoch: 89 
task: majority, mean loss: 0.09785, accuracy: 0.98200, task: max, mean loss: 0.26936, accuracy: 0.93200, task: top, mean loss: 0.04379, accuracy: 0.99700, task: multi, mean loss: 0.42521, multilabel_accuracy: 0.05700, avg. loss over tasks: 0.20905, lr: 3.7371664643889735e-05
Diversity Loss - Mean: -0.13038, Variance: 0.11517
Semantic Loss - Mean: 0.38803, Variance: 0.00323

Test Epoch: 89 
task: majority, mean loss: 1.59815, accuracy: 0.60700, task: max, mean loss: 1.50104, accuracy: 0.60900, task: top, mean loss: 2.00107, accuracy: 0.59500, task: multi, mean loss: 0.47237, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.39315
Diversity Loss - Mean: -0.13802, Variance: 0.12541
Semantic Loss - Mean: 1.31618, Variance: 0.00223

Train Epoch: 90 
task: majority, mean loss: 0.09242, accuracy: 0.98500, task: max, mean loss: 0.26905, accuracy: 0.92400, task: top, mean loss: 0.04362, accuracy: 0.99800, task: multi, mean loss: 0.42478, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.20747, lr: 3.11235359174388e-05
Diversity Loss - Mean: -0.13077, Variance: 0.11532
Semantic Loss - Mean: 0.38131, Variance: 0.00326

Test Epoch: 90 
task: majority, mean loss: 1.57932, accuracy: 0.61200, task: max, mean loss: 1.51597, accuracy: 0.60900, task: top, mean loss: 2.00310, accuracy: 0.59400, task: multi, mean loss: 0.47285, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.39281
Diversity Loss - Mean: -0.13787, Variance: 0.12565
Semantic Loss - Mean: 1.31275, Variance: 0.00226

Train Epoch: 91 
task: majority, mean loss: 0.09412, accuracy: 0.98500, task: max, mean loss: 0.26723, accuracy: 0.92300, task: top, mean loss: 0.04375, accuracy: 0.99600, task: multi, mean loss: 0.42950, multilabel_accuracy: 0.04900, avg. loss over tasks: 0.20865, lr: 2.544727011057081e-05
Diversity Loss - Mean: -0.13006, Variance: 0.11546
Semantic Loss - Mean: 0.38444, Variance: 0.00329

Test Epoch: 91 
task: majority, mean loss: 1.60732, accuracy: 0.60300, task: max, mean loss: 1.53713, accuracy: 0.60400, task: top, mean loss: 1.98765, accuracy: 0.59400, task: multi, mean loss: 0.47399, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.40152
Diversity Loss - Mean: -0.13813, Variance: 0.12589
Semantic Loss - Mean: 1.32511, Variance: 0.00229

Train Epoch: 92 
task: majority, mean loss: 0.09124, accuracy: 0.98500, task: max, mean loss: 0.25859, accuracy: 0.92000, task: top, mean loss: 0.04878, accuracy: 0.99500, task: multi, mean loss: 0.42796, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.20664, lr: 2.0349782878809714e-05
Diversity Loss - Mean: -0.13079, Variance: 0.11561
Semantic Loss - Mean: 0.37695, Variance: 0.00331

Test Epoch: 92 
task: majority, mean loss: 1.61335, accuracy: 0.59700, task: max, mean loss: 1.54202, accuracy: 0.60800, task: top, mean loss: 2.00135, accuracy: 0.59400, task: multi, mean loss: 0.47406, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.40770
Diversity Loss - Mean: -0.13814, Variance: 0.12613
Semantic Loss - Mean: 1.32780, Variance: 0.00232

Train Epoch: 93 
task: majority, mean loss: 0.08658, accuracy: 0.98700, task: max, mean loss: 0.25324, accuracy: 0.93300, task: top, mean loss: 0.04452, accuracy: 0.99500, task: multi, mean loss: 0.42429, multilabel_accuracy: 0.03600, avg. loss over tasks: 0.20216, lr: 1.583728472513976e-05
Diversity Loss - Mean: -0.13044, Variance: 0.11574
Semantic Loss - Mean: 0.37808, Variance: 0.00333

Test Epoch: 93 
task: majority, mean loss: 1.65726, accuracy: 0.60000, task: max, mean loss: 1.53295, accuracy: 0.61400, task: top, mean loss: 2.02957, accuracy: 0.59500, task: multi, mean loss: 0.47259, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.42309
Diversity Loss - Mean: -0.13815, Variance: 0.12637
Semantic Loss - Mean: 1.34030, Variance: 0.00235

Train Epoch: 94 
task: majority, mean loss: 0.09039, accuracy: 0.98500, task: max, mean loss: 0.25366, accuracy: 0.92900, task: top, mean loss: 0.03901, accuracy: 0.99700, task: multi, mean loss: 0.42500, multilabel_accuracy: 0.04200, avg. loss over tasks: 0.20201, lr: 1.1915273433464114e-05
Diversity Loss - Mean: -0.13054, Variance: 0.11588
Semantic Loss - Mean: 0.37221, Variance: 0.00336

Test Epoch: 94 
task: majority, mean loss: 1.63289, accuracy: 0.59600, task: max, mean loss: 1.55597, accuracy: 0.60300, task: top, mean loss: 2.02359, accuracy: 0.59000, task: multi, mean loss: 0.47343, multilabel_accuracy: 0.04700, avg. loss over tasks: 1.42147
Diversity Loss - Mean: -0.13817, Variance: 0.12660
Semantic Loss - Mean: 1.34027, Variance: 0.00238

Train Epoch: 95 
task: majority, mean loss: 0.08226, accuracy: 0.98900, task: max, mean loss: 0.25661, accuracy: 0.93200, task: top, mean loss: 0.03639, accuracy: 0.99700, task: multi, mean loss: 0.42337, multilabel_accuracy: 0.04400, avg. loss over tasks: 0.19966, lr: 8.588527370402095e-06
Diversity Loss - Mean: -0.13031, Variance: 0.11602
Semantic Loss - Mean: 0.37048, Variance: 0.00338

Test Epoch: 95 
task: majority, mean loss: 1.60821, accuracy: 0.60500, task: max, mean loss: 1.55254, accuracy: 0.60400, task: top, mean loss: 2.00871, accuracy: 0.59500, task: multi, mean loss: 0.47401, multilabel_accuracy: 0.04400, avg. loss over tasks: 1.41087
Diversity Loss - Mean: -0.13819, Variance: 0.12682
Semantic Loss - Mean: 1.32890, Variance: 0.00240

Train Epoch: 96 
task: majority, mean loss: 0.08616, accuracy: 0.98300, task: max, mean loss: 0.25249, accuracy: 0.92700, task: top, mean loss: 0.04259, accuracy: 0.99500, task: multi, mean loss: 0.42567, multilabel_accuracy: 0.04800, avg. loss over tasks: 0.20173, lr: 5.861099663585604e-06
Diversity Loss - Mean: -0.13087, Variance: 0.11616
Semantic Loss - Mean: 0.36991, Variance: 0.00340

Test Epoch: 96 
task: majority, mean loss: 1.62071, accuracy: 0.60500, task: max, mean loss: 1.56797, accuracy: 0.60700, task: top, mean loss: 2.01906, accuracy: 0.59600, task: multi, mean loss: 0.47545, multilabel_accuracy: 0.04300, avg. loss over tasks: 1.42080
Diversity Loss - Mean: -0.13823, Variance: 0.12705
Semantic Loss - Mean: 1.33866, Variance: 0.00243

Train Epoch: 97 
task: majority, mean loss: 0.07909, accuracy: 0.98900, task: max, mean loss: 0.24712, accuracy: 0.93300, task: top, mean loss: 0.04019, accuracy: 0.99700, task: multi, mean loss: 0.42414, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.19764, lr: 3.736313263547436e-06
Diversity Loss - Mean: -0.13044, Variance: 0.11629
Semantic Loss - Mean: 0.37420, Variance: 0.00342

Test Epoch: 97 
task: majority, mean loss: 1.62201, accuracy: 0.60000, task: max, mean loss: 1.56025, accuracy: 0.60300, task: top, mean loss: 2.01336, accuracy: 0.59200, task: multi, mean loss: 0.47408, multilabel_accuracy: 0.04300, avg. loss over tasks: 1.41743
Diversity Loss - Mean: -0.13819, Variance: 0.12726
Semantic Loss - Mean: 1.33634, Variance: 0.00246

Train Epoch: 98 
task: majority, mean loss: 0.08766, accuracy: 0.98100, task: max, mean loss: 0.24342, accuracy: 0.93000, task: top, mean loss: 0.03894, accuracy: 0.99700, task: multi, mean loss: 0.42165, multilabel_accuracy: 0.04700, avg. loss over tasks: 0.19791, lr: 2.2167568952178134e-06
Diversity Loss - Mean: -0.13065, Variance: 0.11642
Semantic Loss - Mean: 0.36874, Variance: 0.00344

Test Epoch: 98 
task: majority, mean loss: 1.62266, accuracy: 0.60100, task: max, mean loss: 1.55447, accuracy: 0.60100, task: top, mean loss: 2.01942, accuracy: 0.59400, task: multi, mean loss: 0.47373, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.41757
Diversity Loss - Mean: -0.13816, Variance: 0.12748
Semantic Loss - Mean: 1.33536, Variance: 0.00248

Train Epoch: 99 
task: majority, mean loss: 0.08826, accuracy: 0.98500, task: max, mean loss: 0.24709, accuracy: 0.93100, task: top, mean loss: 0.03969, accuracy: 0.99700, task: multi, mean loss: 0.42354, multilabel_accuracy: 0.04300, avg. loss over tasks: 0.19965, lr: 1.3042819039616668e-06
Diversity Loss - Mean: -0.13044, Variance: 0.11655
Semantic Loss - Mean: 0.36822, Variance: 0.00346

Test Epoch: 99 
task: majority, mean loss: 1.63099, accuracy: 0.59600, task: max, mean loss: 1.55237, accuracy: 0.60500, task: top, mean loss: 2.01968, accuracy: 0.59500, task: multi, mean loss: 0.47328, multilabel_accuracy: 0.04500, avg. loss over tasks: 1.41908
Diversity Loss - Mean: -0.13819, Variance: 0.12769
Semantic Loss - Mean: 1.33728, Variance: 0.00251

Train Epoch: 100 
task: majority, mean loss: 0.08984, accuracy: 0.98300, task: max, mean loss: 0.23662, accuracy: 0.93300, task: top, mean loss: 0.04008, accuracy: 0.99700, task: multi, mean loss: 0.42383, multilabel_accuracy: 0.04600, avg. loss over tasks: 0.19759, lr: 1e-06
Diversity Loss - Mean: -0.13079, Variance: 0.11667
Semantic Loss - Mean: 0.36951, Variance: 0.00348

Test Epoch: 100 
task: majority, mean loss: 1.63256, accuracy: 0.59900, task: max, mean loss: 1.56205, accuracy: 0.60400, task: top, mean loss: 2.01756, accuracy: 0.59100, task: multi, mean loss: 0.47413, multilabel_accuracy: 0.04600, avg. loss over tasks: 1.42157
Diversity Loss - Mean: -0.13819, Variance: 0.12790
Semantic Loss - Mean: 1.34077, Variance: 0.00253

